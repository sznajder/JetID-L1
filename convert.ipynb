{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import setGPU\n",
    "# edit depending on where Vivado is installed:\n",
    "# os.environ['PATH'] = '/<Xilinx installation directory>/Vivado/<version>/bin:' + os.environ['PATH']\n",
    "os.environ['PATH'] = '/xilinx/Vivado/2019.1/bin:' + os.environ['PATH']\n",
    "import tensorflow as tf\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "import hls4ml\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yaml_load(config):\n",
    "    with open(config) as stream:\n",
    "        param = yaml.safe_load(stream)\n",
    "        \n",
    "\n",
    "def print_dict(d, indent=0):\n",
    "    align=20\n",
    "    for key, value in d.items():\n",
    "        print('  ' * indent + str(key), end='')\n",
    "        if isinstance(value, dict):\n",
    "            print()\n",
    "            print_dict(value, indent+1)\n",
    "        else:\n",
    "            print(':' + ' ' * (20 - len(key) - 2 * indent) + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file_path = 'model_QInteractionNetwork_nconst_8_nbits_8.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)    \n",
    "\n",
    "model = load_model(model_file_path, custom_objects=co)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-buffer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "config['Model'] = {}\n",
    "config['Model']['ReuseFactor'] = 1\n",
    "config['Model']['Strategy'] = 'Latency'\n",
    "config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "config['SkipOptimizers'] = ['optimize_pointwise_conv']\n",
    "for layer in config['LayerName'].keys():\n",
    "    config['LayerName'][layer]['Trace'] = True\n",
    "config['LayerName']['q_activation_3']['Precision']['result'] = 'ap_fixed<8,3,AP_RND,AP_SAT>'\n",
    "config['LayerName']['q_activation_6']['Precision']['result'] = 'ap_fixed<8,3,AP_RND,AP_SAT>'\n",
    "#hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "#hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "#hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "cfg = hls4ml.converters.create_vivado_config(fpga_part='xc7z020clg400-1')\n",
    "cfg['HLSConfig'] = config\n",
    "cfg['IOType'] = 'io_parallel'\n",
    "cfg['Backend'] = 'Vivado'\n",
    "cfg['ClockPeriod'] = 10\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir'] = 'hls_output'\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print_dict(cfg)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "#Data PATH\n",
    "TEST_PATH = '/xilinx/scratch/hls4ml_LHCjet_150p_val/'\n",
    "\n",
    "first=True\n",
    "for file in os.listdir(TEST_PATH):\n",
    "  print(\"Appending %s\" %file)\n",
    "\n",
    "  with h5py.File(TEST_PATH+file, 'r') as data:\n",
    "    if first : \n",
    "        first=False\n",
    "        jetConstituent = data['jetConstituentList'][:,:,[5,8,11]]\n",
    "        target = data['jets'][:,-6:-1]\n",
    "        featurenames = data.get('jetFeatureNames')\n",
    "        featurenames = data.get('particleFeatureNames')\n",
    "        images = data.get('jetImage')\n",
    "\n",
    "    else:\n",
    "        jetConstituent = np.concatenate( [ jetConstituent, data['jetConstituentList'][:,:,[5,8,11]] ] , axis=0 )\n",
    "        target   = np.concatenate( [ target, data['jets'][:,-6:-1] ] , axis=0 )\n",
    "                                    \n",
    "print(\"Target shape =\", target.shape)\n",
    "print(\"Jet Constituents shape =\", jetConstituent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# The dataset is N_jets x N_constituents x N_features\n",
    "njet     = jetConstituent.shape[0]\n",
    "nconstit = jetConstituent.shape[1]\n",
    "nfeat    = jetConstituent.shape[2]\n",
    "\n",
    "# Filter out constituents with Pt<2GeV\n",
    "Ptmin = 2. \n",
    "constituents = np.zeros((njet, nconstit, nfeat) , dtype=np.float32) \n",
    "ij=0\n",
    "max_constit=0\n",
    "for j in range(njet):\n",
    "    ic=0\n",
    "    for c in range(nconstit):\n",
    "        if ( jetConstituent[j,c,0] < Ptmin ):\n",
    "            continue\n",
    "        constituents[ij,ic,:] = jetConstituent[j,c,:] \n",
    "        ic+=1\n",
    "    if (ic > 0):\n",
    "        if ic > max_constit: max_constit=ic\n",
    "        target[ij,:]=target[j,:] # assosicate the correct target a given graph \n",
    "        ij+=1\n",
    "\n",
    "# Resizes the jets constituents and target arrays        \n",
    "jetConstituent = constituents[0:ij,0:max_constit,:]\n",
    "target = target[0:ij,:]\n",
    "\n",
    "# Restric the number of constituents to a maximum of NMAX\n",
    "nmax = 8\n",
    "jetConstituent = jetConstituent[:,0:nmax,:]\n",
    "\n",
    "# The dataset is N_jets x N_constituents x N_features\n",
    "njet     = jetConstituent.shape[0]\n",
    "nconstit = jetConstituent.shape[1]\n",
    "nfeat    = jetConstituent.shape[2]\n",
    "\n",
    "\n",
    "print('Number of jets =',njet)\n",
    "print('Number of constituents =',nconstit)\n",
    "print('Number of features =',nfeat)\n",
    "\n",
    "\n",
    "# Shuffles Jet Constituents because L1 constituents are not Pt ordered to begin with\n",
    "print(\"Before --->> jetConstituent[0,0:4,0] = \",jetConstituent[0,0:4,0])\n",
    "jetConstituent = jetConstituent[ : , np.random.permutation(nconstit), : ]\n",
    "print(\"After --->> jetConstituent[0,0:4,0] = \",jetConstituent[0,0:4,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "njet = 10000\n",
    "X_test = np.ascontiguousarray(jetConstituent)[:njet]\n",
    "Y_test = target[:njet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-secret",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict(X_test)\n",
    "Y_hls = hls_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, hls_trace = hls_model.trace(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_trace = hls4ml.model.profiling.get_ymodel_keras(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#%matplotlib inline\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "for i, layer in enumerate(hls_trace.keys()):\n",
    "    plt.figure()\n",
    "    min_x = min(np.amin(hls_trace[layer]), np.amin(keras_trace[layer]))\n",
    "    max_x = max(np.amax(hls_trace[layer]), np.amax(keras_trace[layer]))\n",
    "    plt.plot([min_x, max_x], [min_x, max_x], c='gray')\n",
    "    plt.scatter(hls_trace[layer].flatten(), keras_trace[layer].flatten(), s=0.2)\n",
    "    plt.xlabel('hls4ml {}'.format(layer))\n",
    "    plt.ylabel('QKeras {}'.format(layer))\n",
    "    plt.show()\n",
    "    plt.savefig('profiling_{:02d}_{}.png'.format(i, layer), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "\n",
    "# Plot the ROC curves\n",
    "labels = ['gluon', 'quark', 'W', 'Z', 'top']\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "auc1 = {}\n",
    "fpr_hls = {}\n",
    "tpr_hls = {}\n",
    "auc1_hls = {}\n",
    "for i, label in enumerate(labels):\n",
    "        fpr[label], tpr[label], threshold = roc_curve(Y_test[:,i], Y_predict[:,i])\n",
    "        fpr_hls[label], tpr_hls[label], threshold_hls = roc_curve(Y_test[:,i], Y_hls[:,i])\n",
    "        auc1[label] = auc(fpr[label], tpr[label])\n",
    "        auc1_hls[label] = auc(fpr_hls[label], tpr_hls[label])\n",
    "        ax.plot(tpr[label],fpr[label],label='%s tagger, auc = %.1f%%'%(label,auc1[label]*100.))\n",
    "        ax.plot(tpr_hls[label],fpr_hls[label],label='%s tagger (hls4ml), auc = %.1f%%'%(label,auc1_hls[label]*100.),linestyle='dashed')\n",
    "ax.semilogy()\n",
    "ax.set_xlabel(\"sig. efficiency\")\n",
    "ax.set_ylabel(\"bkg. mistag rate\")\n",
    "ax.set_ylim(0.001,1)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "\n",
    "# Plot DNN output \n",
    "ax = plt.subplot(1, 2, 2)\n",
    "X = np.linspace(0.0, 1.0, 20)\n",
    "hist={}\n",
    "hist_hls={}\n",
    "for i, name in enumerate(labels):\n",
    "    hist[name] = ax.hist(Y_predict, bins=X, label=name ,histtype='step')\n",
    "    hist_hls[name] = ax.hist(Y_hls, bins=X, label=name ,histtype='step', linestyle='dashed')\n",
    "ax.semilogy()\n",
    "ax.set_xlabel('DNN Output')\n",
    "ax.legend(prop={'size': 10})\n",
    "ax.legend(loc='lower left')\n",
    "# Display plots\n",
    "plt.show()\n",
    "plt.savefig('results_hls4ml.pdf', dpi=300)\n",
    "plt.savefig('results_hls4ml.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-toilet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
