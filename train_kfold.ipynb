{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ec338e-f232-4e3f-88fb-d75bdcdc409f",
   "metadata": {},
   "source": [
    "# Notebook for KFOLD training based on Walkie's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9849ca14-7e27-4830-a4a8-14b887ae8a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow {tf.__version__}\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    print(f\"Number of available GPUs : {len(gpus)}\")\n",
    "    tf.config.set_visible_devices(gpus[0],\"GPU\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0],True)\n",
    "else:\n",
    "    print(\"No GPU available, using CPU !!!\")    \n",
    "'''    \n",
    "# To disable GPU use\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "# with tf.device('CPU: 0'):\n",
    "# with tf.device('GPU: 0'): \n",
    "\n",
    "#tf.device('CPU: 0')\n",
    "\n",
    "\n",
    "# Define model hyperparameters \n",
    "seed = 175   # random seed\n",
    "kfolds = 5   # number o folds\n",
    "nfeat = 3      # number of constituents features\n",
    "nepochs = 200   # number of epochs\n",
    "PATIEN = 20  # patience \n",
    "MTR='val_accuracy' # Metric\n",
    "#PRUNE_RATE = 0.01 # Pruning percentage\n",
    "PRUNE_RATE = 0.5 # Pruning percentage\n",
    "\n",
    "# Set number of constituents and bitwidth\n",
    "nconstit=16   # number of constituents\n",
    "nbits=8      # QKeras bitwidth\n",
    "\n",
    "# Define architecture name\n",
    "arch = \"QMLP\"\n",
    "#arch = \"QMLPBN\"\n",
    "#arch = \"QGCN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72ca86-8b55-41cb-9a77-ef4d6b56b43a",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a754499-767d-46e3-ab69-de0be8bcc79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NINPUT =  48\n",
      "NOUTPUT =  5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'REGL1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 53\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#############################################################################\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Load the model definition\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (arch\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQMLP\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[43mexecfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlp.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (arch\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQMLPBN\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     55\u001b[0m     execfile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp_bottleneck.py\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mglobals\u001b[39m(),\u001b[38;5;28mlocals\u001b[39m())\n",
      "File \u001b[0;32m~/WorkM1/miniforge3/envs/tf28/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/_pydev_execfile.py:14\u001b[0m, in \u001b[0;36mexecfile\u001b[0;34m(file, glob, loc)\u001b[0m\n\u001b[1;32m     11\u001b[0m     contents \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# execute the script (note: it's important to compile first to have the filename set in debug mode)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/WorkM1/workdir/Notebooks/JetID_Kfold/mlp.py:79\u001b[0m\n\u001b[1;32m     77\u001b[0m model\u001b[38;5;241m.\u001b[39madd( Input(shape\u001b[38;5;241m=\u001b[39m(NINPUT), name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minp\u001b[39m\u001b[38;5;124m'\u001b[39m) )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,nhidden \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layers):\n\u001b[0;32m---> 79\u001b[0m     model\u001b[38;5;241m.\u001b[39madd( QDense(nhidden, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m , kernel_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mL1(\u001b[43mREGL1\u001b[49m), bias_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mL1(REGL1) ) ) \n\u001b[1;32m     80\u001b[0m     model\u001b[38;5;241m.\u001b[39madd( QActivation( activation \u001b[38;5;241m=\u001b[39m qact, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactiv_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     81\u001b[0m model\u001b[38;5;241m.\u001b[39madd( QDense(\u001b[38;5;241m5\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdense_out\u001b[39m\u001b[38;5;124m'\u001b[39m  , kernel_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mL1(REGL1), bias_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mL1(REGL1) ) )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'REGL1' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Concatenate,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    GlobalAveragePooling1D,\n",
    "    AveragePooling1D,\n",
    "    Reshape,\n",
    "    UpSampling1D,\n",
    "    Add,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from qkeras import QActivation, QDense, QConv1D, QConv2D, quantized_bits\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from tensorflow.keras import utils, regularizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "# Quantized bits\n",
    "\n",
    "#qbits = quantized_bits(nbits,integ,alpha=1.0)\n",
    "#qact = 'quantized_relu('+str(nbits)+',0)'\n",
    "\n",
    "# Set QKeras quantizer and activation \n",
    "if nbits == 1:\n",
    "    qbits = 'binary(alpha=1)'\n",
    "elif nbits == 2:\n",
    "    qbits = 'ternary(alpha=1)'\n",
    "else:\n",
    "    qbits = 'quantized_bits({},0,alpha=1)'.format(nbits)\n",
    "\n",
    "qact = 'quantized_relu({},0)'.format(nbits)\n",
    "\n",
    "# Set QKeras linear activation quantization for CONV1D layers to avoid AveragePooling overflow\n",
    "conv_qbits = 'quantized_bits(15,6)'\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# Load the model definition\n",
    "if (arch==\"QMLP\"):\n",
    "    execfile('mlp.py',globals(),locals())\n",
    "elif (arch==\"QMLPBN\"):\n",
    "    execfile('mlp_bottleneck.py',globals(),locals())\n",
    "elif (arch==\"QGCN\"):\n",
    "    execfile('gcn.py',globals(),locals())\n",
    "else:\n",
    "    print(\"UNKNOWN ARCH !!! \",arch)\n",
    "    stop\n",
    "      \n",
    "#############################################################################\n",
    "\n",
    "\n",
    "# Print\n",
    "print(\"Trainign with max # of contituents = \", nconstit)\n",
    "print(\"Number of node features = \", nfeat)\n",
    "print(\"Quantization with nbits=\",nbits)\n",
    "\n",
    "\n",
    "\n",
    "# create the model\n",
    "#model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "# Define the optimizer ( minimization algorithm )\n",
    "optim = Adam(learning_rate=lr)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy','categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Save model random weights before training to re-initialize weights in each folding\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1583d90-4ea1-4cc1-ac53-f3d837fec0fd",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b83b5f-492a-48cf-94d3-a65aaa24ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "    \n",
    "#NSTEPS = int (( int(len(X_train_val) * 0.3))/batch)\n",
    "#NSTEPS =   int(len(X_train))  // batch\n",
    "NSTEPS =   480840  // batch\n",
    "\n",
    "    \n",
    "def pruneFunction(layer):\n",
    "    pruning_params = {'pruning_schedule': sparsity.PolynomialDecay( initial_sparsity=0.0, final_sparsity=PRUNE_RATE, begin_step=NSTEPS * 2, end_step=NSTEPS * 10, frequency=NSTEPS ) }\n",
    "            #pruning_params_mlp_e = {\n",
    "            #    'pruning_schedule': sparsity.PolynomialDecay(\n",
    "            #        initial_sparsity=0.0, final_sparsity=0.5, begin_step=NSTEPS * 2, end_step=NSTEPS * 10, frequency=NSTEPS\n",
    "            #    )\n",
    "            #}\n",
    "            \n",
    "    if isinstance(layer, tf.keras.layers.Conv1D): \n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "\n",
    "            #if isinstance(layer, tf.keras.layers.Conv1D) and layer.name != 'conv1D_e3':   \n",
    "            #    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "            #if isinstance(layer, tf.keras.layers.Conv1D) and layer.name == 'conv1D_e3':\n",
    "            #    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params_mlp_e)\n",
    "\n",
    "    if isinstance(layer, tf.keras.layers.Dense) and layer.name != 'dense_out': # exclude output_dense\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "\n",
    "    return layer\n",
    "    \n",
    "\n",
    "def shuffle_constituents(data: np.ndarray, const_seed: int) -> np.ndarray:\n",
    "    \"\"\"Shuffles the constituents based on an array of seeds.\n",
    "    Note that each jet's constituents is shuffled with respect to a seed that is fixed.\n",
    "    This seed is different for each jet.\n",
    "    \"\"\"\n",
    "    print(\"Shuffling constituents...\")\n",
    "\n",
    "    rng = np.random.default_rng(const_seed)\n",
    "    seeds = rng.integers(low=0, high=10000, size=data.shape[0])\n",
    "\n",
    "    for jet_idx, seed in enumerate(seeds):\n",
    "        shuffling = np.random.RandomState(seed=seed).permutation(data.shape[1])\n",
    "        data[jet_idx, :] = data[jet_idx, shuffling]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed719dc8-1b92-4a04-8c82-cfb7eabdb0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.data\n",
    "import util.plots\n",
    "import util.util\n",
    "from util.terminal_colors import tcols\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "nmax = nconstit\n",
    "accuracy_keras = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop of training folds\n",
    "with tf.device('CPU: 0'):   # disable M1 metal GPU \n",
    "  for i in range (kfolds):\n",
    "  \n",
    "    # Load random weights initialization before any training to reset weights. Otherwise Keras starts from last trained model weights ...\n",
    "    model.load_weights('model.h5')\n",
    "    \n",
    "    print(\"train kfold num:\", i)\n",
    "    val_kfold = i \n",
    "\n",
    "    #test_kfold = args.TK\n",
    "    train_kfolds = [kfold for kfold in range(kfolds) if kfold != val_kfold]\n",
    "\n",
    "    \n",
    "    fpath = f'./data_kfold/jets_{nmax}constituents_ptetaphi_nonorm'\n",
    "    fnames_train = [f'jet_images_c{nmax}_minpt2.0_ptetaphi_nonorm_{train_kfold}'\n",
    "                     for train_kfold in train_kfolds]\n",
    "    fname_val = f'jet_images_c{nmax}_minpt2.0_ptetaphi_nonorm_{val_kfold}'\n",
    "\n",
    "    data = util.data.Data.load_kfolds(fpath, fnames_train, fname_val)\n",
    "    print (data.train_data.shape)\n",
    "\n",
    "\n",
    "    data.test_data = shuffle_constituents(data.test_data, seed)\n",
    "    \n",
    "    X_train = data.train_data\n",
    "    X_val = data.test_data\n",
    "    X_test = data.test_data\n",
    "\n",
    "    Y_train = data.train_target\n",
    "    Y_val = data.test_target\n",
    "    Y_test = data.test_target    \n",
    "  \n",
    "\n",
    "    # Nomalization\n",
    "    interquantile_range_32 = [120, 0.27, 0.27]\n",
    "    interquantile_range_16 = [166, 0.24, 0.24]\n",
    "    interquantile_range_8  = [219, 0.20, 0.20]\n",
    "    \n",
    "    if nmax == 8:\n",
    "        X_train = X_train / interquantile_range_8\n",
    "        X_val   = X_val   / interquantile_range_8\n",
    "        X_test  = X_test  / interquantile_range_8\n",
    "    elif nmax == 16:\n",
    "        X_train = X_train / interquantile_range_16\n",
    "        X_val   = X_val   / interquantile_range_16\n",
    "        X_test  = X_test  / interquantile_range_16\n",
    "    elif nmax == 32:\n",
    "        X_train = X_train / interquantile_range_32\n",
    "        X_val   = X_val   / interquantile_range_32\n",
    "        X_test  = X_test  / interquantile_range_32\n",
    "\n",
    "    # Flatten data for MLP input\n",
    "    if (arch!='QGCN'):        \n",
    "        X_train = X_train.reshape(-1, NINPUT)\n",
    "        X_val   = X_val.reshape(-1, NINPUT)\n",
    "        X_test  = X_test.reshape(-1, NINPUT)\n",
    "    \n",
    "    \n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "    print( f\"number of G jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 0)}/{np.sum(np.argmax(Y_val, axis=1) == 0)}\")\n",
    "    print( f\"number of Q jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 1)}/{np.sum(np.argmax(Y_val, axis=1) == 1)}\")\n",
    "    print( f\"number of W jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 2)}/{np.sum(np.argmax(Y_val, axis=1) == 2)}\")\n",
    "    print( f\"number of Z jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 3)}/{np.sum(np.argmax(Y_val, axis=1) == 3)}\")\n",
    "    print( f\"number of T jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 4)}/{np.sum(np.argmax(Y_val, axis=1) == 4)}\")\n",
    "\n",
    "    \n",
    "    print(\"number of G jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 0))\n",
    "    print(\"number of Q jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 1))\n",
    "    print(\"number of W jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 2))\n",
    "    print(\"number of Z jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 3))\n",
    "    print(\"number of T jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 4))\n",
    "    \n",
    "#######################################################################################\n",
    "\n",
    "    mname = \"model_{}_nconst_{}_nbits_{}_kfold_{}\".format(arch,nmax,nbits,val_kfold)\n",
    "\n",
    "    if(i==0):\n",
    "        outputdir = \"model_{}_nconst{}_nbits{}_Seed{}_Kfold_{}\".format(\n",
    "            arch,\n",
    "            nconstit,\n",
    "            nbits,\n",
    "            seed,\n",
    "            time.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "        )\n",
    "        print(\"output dir: \", outputdir)\n",
    "        os.mkdir(outputdir)\n",
    "\n",
    "        # early stopping callback\n",
    "        es = EarlyStopping(monitor=MTR, patience=PATIEN)\n",
    "        # Learning rate scheduler\n",
    "        ls = ReduceLROnPlateau(monitor=MTR, factor=0.8, patience=PATIEN, min_lr=0.00001)        \n",
    "        # Model weights pruning \n",
    "        pr = pruning_callbacks.UpdatePruningStep() \n",
    "\n",
    "        \n",
    "    \n",
    "    # Define model checkpoint ( mname changes with folding number !!! ) \n",
    "    chkp = ModelCheckpoint(outputdir+\"/\"+mname+\".h5\", monitor=MTR, verbose=1, save_best_only=True, save_weights_only=False, mode=\"auto\", save_freq=\"epoch\")\n",
    "\n",
    "    # Train classifier\n",
    "    history = model.fit(\n",
    "                        X_train,\n",
    "                        Y_train,\n",
    "                        epochs=nepochs,\n",
    "                        batch_size=batch,  # small batch\n",
    "                        verbose=2,\n",
    "                        callbacks=[es, ls, chkp],\n",
    "#                        callbacks=[es, ls, chkp, pr],\n",
    "                        #validation_split=0.2,\n",
    "                        validation_data=(X_val, Y_val),\n",
    "                        shuffle=True\n",
    "                        )\n",
    "\n",
    "\n",
    "    # Plot loss vs epoch\n",
    "    plt.figure(figsize=(15,10))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    ax.plot(history.history['loss'], label='loss')\n",
    "    ax.plot(history.history['val_loss'], label='val loss')\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "\n",
    "    # Plot training accuracy vs epoch\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    #ax.plot(history.history['accuracy'], label='accuracy')\n",
    "    #ax.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "    ax.plot(history.history['categorical_accuracy'], label='categorical_accuracy')\n",
    "    ax.plot(history.history['val_categorical_accuracy'], label='val categorical accuracy')\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('acc')\n",
    "\n",
    "    # Display plots\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "#    fig.savefig(fname+'.pdf')\n",
    "\n",
    "\n",
    "    \n",
    "    # Retrieve the best model\n",
    "    model = tf.keras.models.load_model(\n",
    "        \"{}/{}.h5\".format(outputdir, mname),\n",
    "        custom_objects={\n",
    "            \"QDense\": QDense,\n",
    "            \"QActivation\": QActivation,\n",
    "            \"QConv1D\": QConv1D,\n",
    "            \"QConv2D\": QConv2D,\n",
    "            \"quantized_bits\": quantized_bits,\n",
    "#            \"NodeEdgeProjection\": NodeEdgeProjection,\n",
    "            \"PruneLowMagnitude\": pruning_wrapper.PruneLowMagnitude,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    '''\n",
    "    # Get predictions for the best model\n",
    "    y_keras = model.predict(X_test)    \n",
    "    # Store best model predictions\n",
    "    accuracy_keras.append(float( accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "    '''\n",
    "    \n",
    "    # Store the accuracy for a given fold\n",
    "    Y_pred = model.predict(X_test)\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    accuracy.update_state(Y_test, Y_pred)\n",
    "    accuracy_keras.append( accuracy.result().numpy() )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c3e32-6edc-4c67-b4b7-f8a043d83c4c",
   "metadata": {},
   "source": [
    "## Saves accuracy and errors for paper plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a15a8a-fa81-440d-a6b0-4494796d5b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#        kfold_metrics = {\n",
    "#            \"fprs\": [],\n",
    "#            \"aucs\": [],\n",
    "#            \"fats\": [],\n",
    "#            \"accs\": [],\n",
    "#            \"loss\": []\n",
    "#        }\n",
    "\n",
    "#plots_dir = outputdir\n",
    "#\n",
    "#roc_metrics = util.plots.roc_curves(plots_dir, y_keras, data.test_target)\n",
    "#util.plots.dnn_output(plots_dir, y_keras)\n",
    "\n",
    "accuracy_average = np.mean(np.array(accuracy_keras))\n",
    "accuracy_errs = np.std(np.array(accuracy_keras))\n",
    "\n",
    "\n",
    "accs = np.zeros(3)\n",
    "accs[0] = accuracy_average\n",
    "accs[2] = accuracy_errs\n",
    "\n",
    "np.savetxt(\"{}/acc.txt\".format(outputdir), accs, fmt=\"%.6f\")\n",
    "print(\"Keras:\\n\", accuracy_keras)\n",
    "\n",
    "print(\"output dir: \", outputdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9e41c-d3c3-4758-811d-0d67e186b48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7833c9-cc89-4cff-a563-822075bbdd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52061e4a-562d-44f3-8a4b-9f85c7be6ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be774cea-7ff6-456f-8fa1-a8410b6d806d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0810dc-b01c-4a98-9699-24c3a017bcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d668a31-8a5f-4cf9-85f5-09f0667f344a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
