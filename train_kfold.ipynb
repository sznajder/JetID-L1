{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ec338e-f232-4e3f-88fb-d75bdcdc409f",
   "metadata": {},
   "source": [
    "# Notebook for KFOLD training based on Walkie's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9849ca14-7e27-4830-a4a8-14b887ae8a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow {tf.__version__}\")\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    print(f\"Number of available GPUs : {len(gpus)}\")\n",
    "    tf.config.set_visible_devices(gpus[0],\"GPU\")\n",
    "    tf.config.experimental.set_memory_growth(gpus[0],True)\n",
    "else:\n",
    "    print(\"No GPU available, using CPU !!!\")    \n",
    "'''    \n",
    "# To disable GPU use\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "    \n",
    "# with tf.device('CPU: 0'):\n",
    "# with tf.device('GPU: 0'): \n",
    "\n",
    "#tf.device('CPU: 0')\n",
    "\n",
    "\n",
    "# Define model hyperparameters \n",
    "seed = 175   # random seed\n",
    "kfolds = 5   # number o folds\n",
    "nfeat=3      # number of constituents features\n",
    "nepochs=200   # number of epochs\n",
    "#lr=0.0005    # learning rate\n",
    "patience=20  # patience \n",
    "MTR='val_accuracy' # Metric\n",
    "#PRUNE_RATE = 0.01 # Pruning percentage\n",
    "PRUNE_RATE = 0.5 # Pruning percentage\n",
    "\n",
    "# Set numer of constituents and bitwidth\n",
    "nconstit=32   # number of constituents\n",
    "nbits=8      # QKeras bitwidth\n",
    "\n",
    "# Define architecture name\n",
    "arch = \"QMLP\"\n",
    "#arch = \"QMLPBN\"\n",
    "#arch = \"QGCN\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72ca86-8b55-41cb-9a77-ef4d6b56b43a",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a754499-767d-46e3-ab69-de0be8bcc79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NINPUT =  96\n",
      "NOUTPUT =  5\n",
      "Trainign with max # of contituents =  32\n",
      "Number of node features =  3\n",
      "Quantization with nbits= 8\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inp (InputLayer)            [(None, 96)]              0         \n",
      "                                                                 \n",
      " dense_1 (QDense)            (None, 128)               12416     \n",
      "                                                                 \n",
      " activ_1 (QActivation)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (QDense)            (None, 59)                7611      \n",
      "                                                                 \n",
      " activ_2 (QActivation)       (None, 59)                0         \n",
      "                                                                 \n",
      " dense_3 (QDense)            (None, 76)                4560      \n",
      "                                                                 \n",
      " activ_3 (QActivation)       (None, 76)                0         \n",
      "                                                                 \n",
      " dense_out (QDense)          (None, 5)                 385       \n",
      "                                                                 \n",
      " activ_out (Activation)      (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,972\n",
      "Trainable params: 24,972\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Concatenate,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    Activation,\n",
    "    GlobalAveragePooling1D,\n",
    "    AveragePooling1D,\n",
    "    Reshape,\n",
    "    UpSampling1D,\n",
    "    Add,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from qkeras import QActivation, QDense, QConv1D, QConv2D, quantized_bits\n",
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "from tensorflow.keras import utils, regularizers\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "# Quantized bits\n",
    "\n",
    "#qbits = quantized_bits(nbits,integ,alpha=1.0)\n",
    "#qact = 'quantized_relu('+str(nbits)+',0)'\n",
    "\n",
    "# Set QKeras quantizer and activation \n",
    "if nbits == 1:\n",
    "    qbits = 'binary(alpha=1)'\n",
    "elif nbits == 2:\n",
    "    qbits = 'ternary(alpha=1)'\n",
    "else:\n",
    "    qbits = 'quantized_bits({},0,alpha=1)'.format(nbits)\n",
    "\n",
    "qact = 'quantized_relu({},0)'.format(nbits)\n",
    "\n",
    "# Set QKeras linear activation quantization for CONV1D layers to avoid AveragePooling overflow\n",
    "conv_qbits = 'quantized_bits(15,6)'\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# Load the model definition\n",
    "if (arch==\"QMLP\"):\n",
    "    execfile('mlp.py',globals(),locals())\n",
    "elif (arch==\"QMLPBN\"):\n",
    "    execfile('mlp_bottleneck.py',globals(),locals())\n",
    "elif (arch==\"QGCN\"):\n",
    "    execfile('gcn.py',globals(),locals())\n",
    "else:\n",
    "    print(\"UNKNOWN ARCH !!! \",arch)\n",
    "    stop\n",
    "      \n",
    "#############################################################################\n",
    "\n",
    "\n",
    "# Print\n",
    "print(\"Trainign with max # of contituents = \", nconstit)\n",
    "print(\"Number of node features = \", nfeat)\n",
    "print(\"Quantization with nbits=\",nbits)\n",
    "\n",
    "\n",
    "\n",
    "# create the model\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "# Define the optimizer ( minimization algorithm )\n",
    "optim = Adam(learning_rate=lr)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['accuracy','categorical_accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Save model random weights before training to re-initialize weights in each folding\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1583d90-4ea1-4cc1-ac53-f3d837fec0fd",
   "metadata": {},
   "source": [
    "## Define Prunnning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b83b5f-492a-48cf-94d3-a65aaa24ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "    \n",
    "#NSTEPS = int (( int(len(X_train_val) * 0.3))/batch)\n",
    "#NSTEPS =   int(len(X_train))  // batch\n",
    "NSTEPS =   480840  // batch\n",
    "\n",
    "    \n",
    "def pruneFunction(layer):\n",
    "    pruning_params = {'pruning_schedule': sparsity.PolynomialDecay( initial_sparsity=0.0, final_sparsity=PRUNE_RATE, begin_step=NSTEPS * 2, end_step=NSTEPS * 10, frequency=NSTEPS ) }\n",
    "            #pruning_params_mlp_e = {\n",
    "            #    'pruning_schedule': sparsity.PolynomialDecay(\n",
    "            #        initial_sparsity=0.0, final_sparsity=0.5, begin_step=NSTEPS * 2, end_step=NSTEPS * 10, frequency=NSTEPS\n",
    "            #    )\n",
    "            #}\n",
    "            \n",
    "    if isinstance(layer, tf.keras.layers.Conv1D): \n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "\n",
    "            #if isinstance(layer, tf.keras.layers.Conv1D) and layer.name != 'conv1D_e3':   \n",
    "            #    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "            #if isinstance(layer, tf.keras.layers.Conv1D) and layer.name == 'conv1D_e3':\n",
    "            #    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params_mlp_e)\n",
    "\n",
    "    if isinstance(layer, tf.keras.layers.Dense) and layer.name != 'dense_out': # exclude output_dense\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "\n",
    "    return layer\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed719dc8-1b92-4a04-8c82-cfb7eabdb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kfold num: 0\n",
      "\n",
      "----------------\n",
      "Data loading complete:\n",
      "File name: None\n",
      "Training data size: 480,840\n",
      "Test data size: 120,210\n",
      "Number of constituents: 32\n",
      "Number of features: 3\n",
      "----------------\n",
      "\n",
      "(480840, 32, 3)\n",
      "(480840, 96) (120210, 96) (480840, 5) (120210, 5)\n",
      "number of G jets for training/validation: 96168/24042\n",
      "number of Q jets for training/validation: 96168/24042\n",
      "number of W jets for training/validation: 96168/24042\n",
      "number of Z jets for training/validation: 96168/24042\n",
      "number of T jets for training/validation: 96168/24042\n",
      "number of G jets for testing: 24042\n",
      "number of Q jets for testing: 24042\n",
      "number of W jets for testing: 24042\n",
      "number of Z jets for testing: 24042\n",
      "number of T jets for testing: 24042\n",
      "output dir:  model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 22:05:09.718731: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.4830 - accuracy: 0.4533 - categorical_accuracy: 0.4533\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50324, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 1.4827 - accuracy: 0.4534 - categorical_accuracy: 0.4534 - val_loss: 1.3370 - val_accuracy: 0.5032 - val_categorical_accuracy: 0.5032 - lr: 4.3297e-04\n",
      "Epoch 2/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 1.2700 - accuracy: 0.5276 - categorical_accuracy: 0.5276\n",
      "Epoch 2: val_accuracy improved from 0.50324 to 0.54487, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 884us/step - loss: 1.2698 - accuracy: 0.5276 - categorical_accuracy: 0.5276 - val_loss: 1.2275 - val_accuracy: 0.5449 - val_categorical_accuracy: 0.5449 - lr: 4.3297e-04\n",
      "Epoch 3/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 1.1895 - accuracy: 0.5566 - categorical_accuracy: 0.5566\n",
      "Epoch 3: val_accuracy improved from 0.54487 to 0.55644, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 1.1894 - accuracy: 0.5566 - categorical_accuracy: 0.5566 - val_loss: 1.1822 - val_accuracy: 0.5564 - val_categorical_accuracy: 0.5564 - lr: 4.3297e-04\n",
      "Epoch 4/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.1438 - accuracy: 0.5727 - categorical_accuracy: 0.5727\n",
      "Epoch 4: val_accuracy improved from 0.55644 to 0.57553, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 920us/step - loss: 1.1438 - accuracy: 0.5727 - categorical_accuracy: 0.5727 - val_loss: 1.1294 - val_accuracy: 0.5755 - val_categorical_accuracy: 0.5755 - lr: 4.3297e-04\n",
      "Epoch 5/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.1119 - accuracy: 0.5850 - categorical_accuracy: 0.5850\n",
      "Epoch 5: val_accuracy improved from 0.57553 to 0.58735, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 1.1118 - accuracy: 0.5850 - categorical_accuracy: 0.5850 - val_loss: 1.1059 - val_accuracy: 0.5873 - val_categorical_accuracy: 0.5873 - lr: 4.3297e-04\n",
      "Epoch 6/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 1.0901 - accuracy: 0.5945 - categorical_accuracy: 0.5945\n",
      "Epoch 6: val_accuracy improved from 0.58735 to 0.59592, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0900 - accuracy: 0.5945 - categorical_accuracy: 0.5945 - val_loss: 1.0870 - val_accuracy: 0.5959 - val_categorical_accuracy: 0.5959 - lr: 4.3297e-04\n",
      "Epoch 7/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.0760 - accuracy: 0.6008 - categorical_accuracy: 0.6008\n",
      "Epoch 7: val_accuracy improved from 0.59592 to 0.60264, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0760 - accuracy: 0.6008 - categorical_accuracy: 0.6008 - val_loss: 1.0726 - val_accuracy: 0.6026 - val_categorical_accuracy: 0.6026 - lr: 4.3297e-04\n",
      "Epoch 8/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 1.0659 - accuracy: 0.6050 - categorical_accuracy: 0.6050\n",
      "Epoch 8: val_accuracy improved from 0.60264 to 0.60616, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 1.0659 - accuracy: 0.6050 - categorical_accuracy: 0.6050 - val_loss: 1.0629 - val_accuracy: 0.6062 - val_categorical_accuracy: 0.6062 - lr: 4.3297e-04\n",
      "Epoch 9/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 1.0582 - accuracy: 0.6090 - categorical_accuracy: 0.6090\n",
      "Epoch 9: val_accuracy improved from 0.60616 to 0.60892, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 922us/step - loss: 1.0581 - accuracy: 0.6091 - categorical_accuracy: 0.6091 - val_loss: 1.0584 - val_accuracy: 0.6089 - val_categorical_accuracy: 0.6089 - lr: 4.3297e-04\n",
      "Epoch 10/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0518 - accuracy: 0.6117 - categorical_accuracy: 0.6117\n",
      "Epoch 10: val_accuracy improved from 0.60892 to 0.61227, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0519 - accuracy: 0.6117 - categorical_accuracy: 0.6117 - val_loss: 1.0516 - val_accuracy: 0.6123 - val_categorical_accuracy: 0.6123 - lr: 4.3297e-04\n",
      "Epoch 11/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 1.0470 - accuracy: 0.6137 - categorical_accuracy: 0.6137\n",
      "Epoch 11: val_accuracy improved from 0.61227 to 0.61306, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0469 - accuracy: 0.6137 - categorical_accuracy: 0.6137 - val_loss: 1.0458 - val_accuracy: 0.6131 - val_categorical_accuracy: 0.6131 - lr: 4.3297e-04\n",
      "Epoch 12/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 1.0432 - accuracy: 0.6158 - categorical_accuracy: 0.6158\n",
      "Epoch 12: val_accuracy did not improve from 0.61306\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0432 - accuracy: 0.6158 - categorical_accuracy: 0.6158 - val_loss: 1.0474 - val_accuracy: 0.6128 - val_categorical_accuracy: 0.6128 - lr: 4.3297e-04\n",
      "Epoch 13/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 1.0392 - accuracy: 0.6181 - categorical_accuracy: 0.6181\n",
      "Epoch 13: val_accuracy improved from 0.61306 to 0.61744, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 1.0393 - accuracy: 0.6181 - categorical_accuracy: 0.6181 - val_loss: 1.0416 - val_accuracy: 0.6174 - val_categorical_accuracy: 0.6174 - lr: 4.3297e-04\n",
      "Epoch 14/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0369 - accuracy: 0.6193 - categorical_accuracy: 0.6193\n",
      "Epoch 14: val_accuracy did not improve from 0.61744\n",
      "7514/7514 [==============================] - 7s 899us/step - loss: 1.0369 - accuracy: 0.6194 - categorical_accuracy: 0.6194 - val_loss: 1.0483 - val_accuracy: 0.6129 - val_categorical_accuracy: 0.6129 - lr: 4.3297e-04\n",
      "Epoch 15/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.6202 - categorical_accuracy: 0.6202\n",
      "Epoch 15: val_accuracy improved from 0.61744 to 0.61939, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 914us/step - loss: 1.0344 - accuracy: 0.6202 - categorical_accuracy: 0.6202 - val_loss: 1.0364 - val_accuracy: 0.6194 - val_categorical_accuracy: 0.6194 - lr: 4.3297e-04\n",
      "Epoch 16/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0324 - accuracy: 0.6215 - categorical_accuracy: 0.6215\n",
      "Epoch 16: val_accuracy did not improve from 0.61939\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 1.0324 - accuracy: 0.6215 - categorical_accuracy: 0.6215 - val_loss: 1.0360 - val_accuracy: 0.6189 - val_categorical_accuracy: 0.6189 - lr: 4.3297e-04\n",
      "Epoch 17/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 1.0314 - accuracy: 0.6215 - categorical_accuracy: 0.6215\n",
      "Epoch 17: val_accuracy improved from 0.61939 to 0.61952, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 918us/step - loss: 1.0313 - accuracy: 0.6215 - categorical_accuracy: 0.6215 - val_loss: 1.0355 - val_accuracy: 0.6195 - val_categorical_accuracy: 0.6195 - lr: 4.3297e-04\n",
      "Epoch 18/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 1.0298 - accuracy: 0.6223 - categorical_accuracy: 0.6223\n",
      "Epoch 18: val_accuracy did not improve from 0.61952\n",
      "7514/7514 [==============================] - 7s 925us/step - loss: 1.0299 - accuracy: 0.6223 - categorical_accuracy: 0.6223 - val_loss: 1.0342 - val_accuracy: 0.6192 - val_categorical_accuracy: 0.6192 - lr: 4.3297e-04\n",
      "Epoch 19/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 1.0287 - accuracy: 0.6229 - categorical_accuracy: 0.6229\n",
      "Epoch 19: val_accuracy did not improve from 0.61952\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 1.0287 - accuracy: 0.6229 - categorical_accuracy: 0.6229 - val_loss: 1.0372 - val_accuracy: 0.6186 - val_categorical_accuracy: 0.6186 - lr: 4.3297e-04\n",
      "Epoch 20/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 1.0277 - accuracy: 0.6228 - categorical_accuracy: 0.6228\n",
      "Epoch 20: val_accuracy improved from 0.61952 to 0.62232, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0277 - accuracy: 0.6229 - categorical_accuracy: 0.6229 - val_loss: 1.0291 - val_accuracy: 0.6223 - val_categorical_accuracy: 0.6223 - lr: 4.3297e-04\n",
      "Epoch 21/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0265 - accuracy: 0.6238 - categorical_accuracy: 0.6238\n",
      "Epoch 21: val_accuracy did not improve from 0.62232\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0265 - accuracy: 0.6237 - categorical_accuracy: 0.6237 - val_loss: 1.0296 - val_accuracy: 0.6213 - val_categorical_accuracy: 0.6213 - lr: 4.3297e-04\n",
      "Epoch 22/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0257 - accuracy: 0.6240 - categorical_accuracy: 0.6240\n",
      "Epoch 22: val_accuracy did not improve from 0.62232\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0257 - accuracy: 0.6240 - categorical_accuracy: 0.6240 - val_loss: 1.0279 - val_accuracy: 0.6218 - val_categorical_accuracy: 0.6218 - lr: 4.3297e-04\n",
      "Epoch 23/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 1.0251 - accuracy: 0.6234 - categorical_accuracy: 0.6234\n",
      "Epoch 23: val_accuracy did not improve from 0.62232\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0251 - accuracy: 0.6234 - categorical_accuracy: 0.6234 - val_loss: 1.0289 - val_accuracy: 0.6197 - val_categorical_accuracy: 0.6197 - lr: 4.3297e-04\n",
      "Epoch 24/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 1.0240 - accuracy: 0.6247 - categorical_accuracy: 0.6247\n",
      "Epoch 24: val_accuracy did not improve from 0.62232\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0239 - accuracy: 0.6247 - categorical_accuracy: 0.6247 - val_loss: 1.0288 - val_accuracy: 0.6215 - val_categorical_accuracy: 0.6215 - lr: 4.3297e-04\n",
      "Epoch 25/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 1.0235 - accuracy: 0.6247 - categorical_accuracy: 0.6247\n",
      "Epoch 25: val_accuracy did not improve from 0.62232\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 1.0235 - accuracy: 0.6248 - categorical_accuracy: 0.6248 - val_loss: 1.0297 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222 - lr: 4.3297e-04\n",
      "Epoch 26/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 1.0230 - accuracy: 0.6252 - categorical_accuracy: 0.6252\n",
      "Epoch 26: val_accuracy improved from 0.62232 to 0.62253, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 1.0229 - accuracy: 0.6252 - categorical_accuracy: 0.6252 - val_loss: 1.0278 - val_accuracy: 0.6225 - val_categorical_accuracy: 0.6225 - lr: 4.3297e-04\n",
      "Epoch 27/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0220 - accuracy: 0.6251 - categorical_accuracy: 0.6251\n",
      "Epoch 27: val_accuracy improved from 0.62253 to 0.62264, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0219 - accuracy: 0.6250 - categorical_accuracy: 0.6250 - val_loss: 1.0251 - val_accuracy: 0.6226 - val_categorical_accuracy: 0.6226 - lr: 4.3297e-04\n",
      "Epoch 28/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 1.0216 - accuracy: 0.6259 - categorical_accuracy: 0.6259\n",
      "Epoch 28: val_accuracy improved from 0.62264 to 0.62348, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0216 - accuracy: 0.6259 - categorical_accuracy: 0.6259 - val_loss: 1.0258 - val_accuracy: 0.6235 - val_categorical_accuracy: 0.6235 - lr: 4.3297e-04\n",
      "Epoch 29/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 1.0201 - accuracy: 0.6261 - categorical_accuracy: 0.6261\n",
      "Epoch 29: val_accuracy did not improve from 0.62348\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0201 - accuracy: 0.6261 - categorical_accuracy: 0.6261 - val_loss: 1.0251 - val_accuracy: 0.6229 - val_categorical_accuracy: 0.6229 - lr: 4.3297e-04\n",
      "Epoch 30/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 1.0200 - accuracy: 0.6259 - categorical_accuracy: 0.6259\n",
      "Epoch 30: val_accuracy did not improve from 0.62348\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 1.0200 - accuracy: 0.6259 - categorical_accuracy: 0.6259 - val_loss: 1.0279 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222 - lr: 4.3297e-04\n",
      "Epoch 31/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.0188 - accuracy: 0.6267 - categorical_accuracy: 0.6267\n",
      "Epoch 31: val_accuracy improved from 0.62348 to 0.62461, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0188 - accuracy: 0.6267 - categorical_accuracy: 0.6267 - val_loss: 1.0216 - val_accuracy: 0.6246 - val_categorical_accuracy: 0.6246 - lr: 4.3297e-04\n",
      "Epoch 32/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 1.0182 - accuracy: 0.6274 - categorical_accuracy: 0.6274\n",
      "Epoch 32: val_accuracy did not improve from 0.62461\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0182 - accuracy: 0.6274 - categorical_accuracy: 0.6274 - val_loss: 1.0241 - val_accuracy: 0.6231 - val_categorical_accuracy: 0.6231 - lr: 4.3297e-04\n",
      "Epoch 33/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0179 - accuracy: 0.6269 - categorical_accuracy: 0.6269\n",
      "Epoch 33: val_accuracy improved from 0.62461 to 0.62605, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0179 - accuracy: 0.6269 - categorical_accuracy: 0.6269 - val_loss: 1.0226 - val_accuracy: 0.6260 - val_categorical_accuracy: 0.6260 - lr: 4.3297e-04\n",
      "Epoch 34/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.0174 - accuracy: 0.6269 - categorical_accuracy: 0.6269\n",
      "Epoch 34: val_accuracy improved from 0.62605 to 0.62696, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0173 - accuracy: 0.6270 - categorical_accuracy: 0.6270 - val_loss: 1.0181 - val_accuracy: 0.6270 - val_categorical_accuracy: 0.6270 - lr: 4.3297e-04\n",
      "Epoch 35/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 1.0167 - accuracy: 0.6275 - categorical_accuracy: 0.6275\n",
      "Epoch 35: val_accuracy did not improve from 0.62696\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0167 - accuracy: 0.6275 - categorical_accuracy: 0.6275 - val_loss: 1.0197 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256 - lr: 4.3297e-04\n",
      "Epoch 36/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 1.0164 - accuracy: 0.6273 - categorical_accuracy: 0.6273\n",
      "Epoch 36: val_accuracy did not improve from 0.62696\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0164 - accuracy: 0.6273 - categorical_accuracy: 0.6273 - val_loss: 1.0197 - val_accuracy: 0.6267 - val_categorical_accuracy: 0.6267 - lr: 4.3297e-04\n",
      "Epoch 37/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0148 - accuracy: 0.6287 - categorical_accuracy: 0.6287\n",
      "Epoch 37: val_accuracy improved from 0.62696 to 0.62814, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0148 - accuracy: 0.6287 - categorical_accuracy: 0.6287 - val_loss: 1.0175 - val_accuracy: 0.6281 - val_categorical_accuracy: 0.6281 - lr: 4.3297e-04\n",
      "Epoch 38/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0145 - accuracy: 0.6286 - categorical_accuracy: 0.6286\n",
      "Epoch 38: val_accuracy did not improve from 0.62814\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 1.0146 - accuracy: 0.6286 - categorical_accuracy: 0.6286 - val_loss: 1.0181 - val_accuracy: 0.6275 - val_categorical_accuracy: 0.6275 - lr: 4.3297e-04\n",
      "Epoch 39/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 1.0133 - accuracy: 0.6290 - categorical_accuracy: 0.6290\n",
      "Epoch 39: val_accuracy did not improve from 0.62814\n",
      "7514/7514 [==============================] - 7s 969us/step - loss: 1.0133 - accuracy: 0.6290 - categorical_accuracy: 0.6290 - val_loss: 1.0180 - val_accuracy: 0.6281 - val_categorical_accuracy: 0.6281 - lr: 4.3297e-04\n",
      "Epoch 40/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 1.0128 - accuracy: 0.6293 - categorical_accuracy: 0.6293\n",
      "Epoch 40: val_accuracy did not improve from 0.62814\n",
      "7514/7514 [==============================] - 7s 994us/step - loss: 1.0127 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0171 - val_accuracy: 0.6279 - val_categorical_accuracy: 0.6279 - lr: 4.3297e-04\n",
      "Epoch 41/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 1.0127 - accuracy: 0.6292 - categorical_accuracy: 0.6292\n",
      "Epoch 41: val_accuracy did not improve from 0.62814\n",
      "7514/7514 [==============================] - 7s 964us/step - loss: 1.0127 - accuracy: 0.6292 - categorical_accuracy: 0.6292 - val_loss: 1.0198 - val_accuracy: 0.6264 - val_categorical_accuracy: 0.6264 - lr: 4.3297e-04\n",
      "Epoch 42/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 1.0121 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 42: val_accuracy improved from 0.62814 to 0.62892, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 983us/step - loss: 1.0122 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0148 - val_accuracy: 0.6289 - val_categorical_accuracy: 0.6289 - lr: 4.3297e-04\n",
      "Epoch 43/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 1.0123 - accuracy: 0.6296 - categorical_accuracy: 0.6296\n",
      "Epoch 43: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 8s 1ms/step - loss: 1.0122 - accuracy: 0.6296 - categorical_accuracy: 0.6296 - val_loss: 1.0140 - val_accuracy: 0.6286 - val_categorical_accuracy: 0.6286 - lr: 4.3297e-04\n",
      "Epoch 44/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 1.0122 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 44: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 974us/step - loss: 1.0120 - accuracy: 0.6295 - categorical_accuracy: 0.6295 - val_loss: 1.0159 - val_accuracy: 0.6280 - val_categorical_accuracy: 0.6280 - lr: 4.3297e-04\n",
      "Epoch 45/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 1.0114 - accuracy: 0.6304 - categorical_accuracy: 0.6304\n",
      "Epoch 45: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 1.0115 - accuracy: 0.6304 - categorical_accuracy: 0.6304 - val_loss: 1.0229 - val_accuracy: 0.6228 - val_categorical_accuracy: 0.6228 - lr: 4.3297e-04\n",
      "Epoch 46/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 1.0116 - accuracy: 0.6299 - categorical_accuracy: 0.6299\n",
      "Epoch 46: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 922us/step - loss: 1.0116 - accuracy: 0.6299 - categorical_accuracy: 0.6299 - val_loss: 1.0166 - val_accuracy: 0.6271 - val_categorical_accuracy: 0.6271 - lr: 4.3297e-04\n",
      "Epoch 47/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 1.0107 - accuracy: 0.6303 - categorical_accuracy: 0.6303\n",
      "Epoch 47: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0107 - accuracy: 0.6302 - categorical_accuracy: 0.6302 - val_loss: 1.0168 - val_accuracy: 0.6263 - val_categorical_accuracy: 0.6263 - lr: 4.3297e-04\n",
      "Epoch 48/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 1.0107 - accuracy: 0.6306 - categorical_accuracy: 0.6306\n",
      "Epoch 48: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0107 - accuracy: 0.6306 - categorical_accuracy: 0.6306 - val_loss: 1.0150 - val_accuracy: 0.6278 - val_categorical_accuracy: 0.6278 - lr: 4.3297e-04\n",
      "Epoch 49/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 1.0103 - accuracy: 0.6306 - categorical_accuracy: 0.6306\n",
      "Epoch 49: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0103 - accuracy: 0.6306 - categorical_accuracy: 0.6306 - val_loss: 1.0168 - val_accuracy: 0.6278 - val_categorical_accuracy: 0.6278 - lr: 4.3297e-04\n",
      "Epoch 50/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 1.0100 - accuracy: 0.6302 - categorical_accuracy: 0.6302\n",
      "Epoch 50: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 917us/step - loss: 1.0101 - accuracy: 0.6302 - categorical_accuracy: 0.6302 - val_loss: 1.0164 - val_accuracy: 0.6279 - val_categorical_accuracy: 0.6279 - lr: 4.3297e-04\n",
      "Epoch 51/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.0103 - accuracy: 0.6312 - categorical_accuracy: 0.6312\n",
      "Epoch 51: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 1.0103 - accuracy: 0.6311 - categorical_accuracy: 0.6311 - val_loss: 1.0173 - val_accuracy: 0.6260 - val_categorical_accuracy: 0.6260 - lr: 4.3297e-04\n",
      "Epoch 52/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 1.0093 - accuracy: 0.6310 - categorical_accuracy: 0.6310\n",
      "Epoch 52: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0094 - accuracy: 0.6309 - categorical_accuracy: 0.6309 - val_loss: 1.0131 - val_accuracy: 0.6281 - val_categorical_accuracy: 0.6281 - lr: 4.3297e-04\n",
      "Epoch 53/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 1.0096 - accuracy: 0.6303 - categorical_accuracy: 0.6303\n",
      "Epoch 53: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0095 - accuracy: 0.6303 - categorical_accuracy: 0.6303 - val_loss: 1.0220 - val_accuracy: 0.6243 - val_categorical_accuracy: 0.6243 - lr: 4.3297e-04\n",
      "Epoch 54/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.0095 - accuracy: 0.6300 - categorical_accuracy: 0.6300\n",
      "Epoch 54: val_accuracy did not improve from 0.62892\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 1.0095 - accuracy: 0.6301 - categorical_accuracy: 0.6301 - val_loss: 1.0150 - val_accuracy: 0.6266 - val_categorical_accuracy: 0.6266 - lr: 4.3297e-04\n",
      "Epoch 55/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 1.0091 - accuracy: 0.6310 - categorical_accuracy: 0.6310\n",
      "Epoch 55: val_accuracy improved from 0.62892 to 0.63126, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0091 - accuracy: 0.6310 - categorical_accuracy: 0.6310 - val_loss: 1.0100 - val_accuracy: 0.6313 - val_categorical_accuracy: 0.6313 - lr: 4.3297e-04\n",
      "Epoch 56/200\n",
      "7459/7514 [============================>.] - ETA: 0s - loss: 1.0091 - accuracy: 0.6310 - categorical_accuracy: 0.6310\n",
      "Epoch 56: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0092 - accuracy: 0.6310 - categorical_accuracy: 0.6310 - val_loss: 1.0159 - val_accuracy: 0.6278 - val_categorical_accuracy: 0.6278 - lr: 4.3297e-04\n",
      "Epoch 57/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0086 - accuracy: 0.6312 - categorical_accuracy: 0.6312\n",
      "Epoch 57: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 927us/step - loss: 1.0086 - accuracy: 0.6312 - categorical_accuracy: 0.6312 - val_loss: 1.0117 - val_accuracy: 0.6301 - val_categorical_accuracy: 0.6301 - lr: 4.3297e-04\n",
      "Epoch 58/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 1.0082 - accuracy: 0.6312 - categorical_accuracy: 0.6312\n",
      "Epoch 58: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0082 - accuracy: 0.6312 - categorical_accuracy: 0.6312 - val_loss: 1.0153 - val_accuracy: 0.6271 - val_categorical_accuracy: 0.6271 - lr: 4.3297e-04\n",
      "Epoch 59/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 1.0085 - accuracy: 0.6307 - categorical_accuracy: 0.6307\n",
      "Epoch 59: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 1.0084 - accuracy: 0.6307 - categorical_accuracy: 0.6307 - val_loss: 1.0161 - val_accuracy: 0.6268 - val_categorical_accuracy: 0.6268 - lr: 4.3297e-04\n",
      "Epoch 60/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 1.0086 - accuracy: 0.6310 - categorical_accuracy: 0.6310\n",
      "Epoch 60: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 961us/step - loss: 1.0085 - accuracy: 0.6311 - categorical_accuracy: 0.6311 - val_loss: 1.0133 - val_accuracy: 0.6284 - val_categorical_accuracy: 0.6284 - lr: 4.3297e-04\n",
      "Epoch 61/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 1.0082 - accuracy: 0.6316 - categorical_accuracy: 0.6316\n",
      "Epoch 61: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 1.0082 - accuracy: 0.6317 - categorical_accuracy: 0.6317 - val_loss: 1.0128 - val_accuracy: 0.6277 - val_categorical_accuracy: 0.6277 - lr: 4.3297e-04\n",
      "Epoch 62/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 1.0084 - accuracy: 0.6314 - categorical_accuracy: 0.6314\n",
      "Epoch 62: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0085 - accuracy: 0.6314 - categorical_accuracy: 0.6314 - val_loss: 1.0093 - val_accuracy: 0.6309 - val_categorical_accuracy: 0.6309 - lr: 4.3297e-04\n",
      "Epoch 63/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0081 - accuracy: 0.6309 - categorical_accuracy: 0.6309\n",
      "Epoch 63: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0081 - accuracy: 0.6309 - categorical_accuracy: 0.6309 - val_loss: 1.0137 - val_accuracy: 0.6278 - val_categorical_accuracy: 0.6278 - lr: 4.3297e-04\n",
      "Epoch 64/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 1.0076 - accuracy: 0.6309 - categorical_accuracy: 0.6309\n",
      "Epoch 64: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 1.0077 - accuracy: 0.6308 - categorical_accuracy: 0.6308 - val_loss: 1.0132 - val_accuracy: 0.6283 - val_categorical_accuracy: 0.6283 - lr: 4.3297e-04\n",
      "Epoch 65/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 1.0078 - accuracy: 0.6318 - categorical_accuracy: 0.6318\n",
      "Epoch 65: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0079 - accuracy: 0.6318 - categorical_accuracy: 0.6318 - val_loss: 1.0168 - val_accuracy: 0.6266 - val_categorical_accuracy: 0.6266 - lr: 4.3297e-04\n",
      "Epoch 66/200\n",
      "7503/7514 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.6319 - categorical_accuracy: 0.6319\n",
      "Epoch 66: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.0076 - accuracy: 0.6318 - categorical_accuracy: 0.6318 - val_loss: 1.0120 - val_accuracy: 0.6280 - val_categorical_accuracy: 0.6280 - lr: 4.3297e-04\n",
      "Epoch 67/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.0073 - accuracy: 0.6314 - categorical_accuracy: 0.6314\n",
      "Epoch 67: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0072 - accuracy: 0.6315 - categorical_accuracy: 0.6315 - val_loss: 1.0113 - val_accuracy: 0.6292 - val_categorical_accuracy: 0.6292 - lr: 4.3297e-04\n",
      "Epoch 68/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0070 - accuracy: 0.6319 - categorical_accuracy: 0.6319\n",
      "Epoch 68: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 1.0069 - accuracy: 0.6320 - categorical_accuracy: 0.6320 - val_loss: 1.0137 - val_accuracy: 0.6282 - val_categorical_accuracy: 0.6282 - lr: 4.3297e-04\n",
      "Epoch 69/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0073 - accuracy: 0.6311 - categorical_accuracy: 0.6311\n",
      "Epoch 69: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.0074 - accuracy: 0.6311 - categorical_accuracy: 0.6311 - val_loss: 1.0097 - val_accuracy: 0.6300 - val_categorical_accuracy: 0.6300 - lr: 4.3297e-04\n",
      "Epoch 70/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0070 - accuracy: 0.6315 - categorical_accuracy: 0.6315\n",
      "Epoch 70: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.0070 - accuracy: 0.6315 - categorical_accuracy: 0.6315 - val_loss: 1.0124 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.6299 - lr: 4.3297e-04\n",
      "Epoch 71/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.0067 - accuracy: 0.6317 - categorical_accuracy: 0.6317\n",
      "Epoch 71: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 1.0068 - accuracy: 0.6317 - categorical_accuracy: 0.6317 - val_loss: 1.0100 - val_accuracy: 0.6302 - val_categorical_accuracy: 0.6302 - lr: 4.3297e-04\n",
      "Epoch 72/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.0070 - accuracy: 0.6318 - categorical_accuracy: 0.6318\n",
      "Epoch 72: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 1.0070 - accuracy: 0.6318 - categorical_accuracy: 0.6318 - val_loss: 1.0083 - val_accuracy: 0.6304 - val_categorical_accuracy: 0.6304 - lr: 4.3297e-04\n",
      "Epoch 73/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 1.0065 - accuracy: 0.6325 - categorical_accuracy: 0.6325\n",
      "Epoch 73: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 953us/step - loss: 1.0064 - accuracy: 0.6325 - categorical_accuracy: 0.6325 - val_loss: 1.0119 - val_accuracy: 0.6284 - val_categorical_accuracy: 0.6284 - lr: 4.3297e-04\n",
      "Epoch 74/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0065 - accuracy: 0.6318 - categorical_accuracy: 0.6318\n",
      "Epoch 74: val_accuracy did not improve from 0.63126\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 1.0065 - accuracy: 0.6318 - categorical_accuracy: 0.6318 - val_loss: 1.0118 - val_accuracy: 0.6291 - val_categorical_accuracy: 0.6291 - lr: 4.3297e-04\n",
      "Epoch 75/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 1.0063 - accuracy: 0.6327 - categorical_accuracy: 0.6327\n",
      "Epoch 75: val_accuracy improved from 0.63126 to 0.63167, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.0062 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0070 - val_accuracy: 0.6317 - val_categorical_accuracy: 0.6317 - lr: 4.3297e-04\n",
      "Epoch 76/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 1.0062 - accuracy: 0.6318 - categorical_accuracy: 0.6318\n",
      "Epoch 76: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 1.0062 - accuracy: 0.6318 - categorical_accuracy: 0.6318 - val_loss: 1.0098 - val_accuracy: 0.6296 - val_categorical_accuracy: 0.6296 - lr: 4.3297e-04\n",
      "Epoch 77/200\n",
      "7509/7514 [============================>.] - ETA: 0s - loss: 1.0059 - accuracy: 0.6319 - categorical_accuracy: 0.6319\n",
      "Epoch 77: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 1.0058 - accuracy: 0.6319 - categorical_accuracy: 0.6319 - val_loss: 1.0111 - val_accuracy: 0.6299 - val_categorical_accuracy: 0.6299 - lr: 4.3297e-04\n",
      "Epoch 78/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0064 - accuracy: 0.6315 - categorical_accuracy: 0.6315\n",
      "Epoch 78: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 1.0063 - accuracy: 0.6316 - categorical_accuracy: 0.6316 - val_loss: 1.0090 - val_accuracy: 0.6301 - val_categorical_accuracy: 0.6301 - lr: 4.3297e-04\n",
      "Epoch 79/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 1.0064 - accuracy: 0.6319 - categorical_accuracy: 0.6319\n",
      "Epoch 79: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0064 - accuracy: 0.6319 - categorical_accuracy: 0.6319 - val_loss: 1.0137 - val_accuracy: 0.6279 - val_categorical_accuracy: 0.6279 - lr: 4.3297e-04\n",
      "Epoch 80/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 1.0062 - accuracy: 0.6322 - categorical_accuracy: 0.6322\n",
      "Epoch 80: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 1.0062 - accuracy: 0.6321 - categorical_accuracy: 0.6321 - val_loss: 1.0110 - val_accuracy: 0.6294 - val_categorical_accuracy: 0.6294 - lr: 4.3297e-04\n",
      "Epoch 81/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.0056 - accuracy: 0.6324 - categorical_accuracy: 0.6324\n",
      "Epoch 81: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 1.0056 - accuracy: 0.6323 - categorical_accuracy: 0.6323 - val_loss: 1.0216 - val_accuracy: 0.6246 - val_categorical_accuracy: 0.6246 - lr: 4.3297e-04\n",
      "Epoch 82/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 1.0058 - accuracy: 0.6318 - categorical_accuracy: 0.6318\n",
      "Epoch 82: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 951us/step - loss: 1.0059 - accuracy: 0.6318 - categorical_accuracy: 0.6318 - val_loss: 1.0167 - val_accuracy: 0.6268 - val_categorical_accuracy: 0.6268 - lr: 4.3297e-04\n",
      "Epoch 83/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0055 - accuracy: 0.6324 - categorical_accuracy: 0.6324\n",
      "Epoch 83: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.0054 - accuracy: 0.6324 - categorical_accuracy: 0.6324 - val_loss: 1.0115 - val_accuracy: 0.6300 - val_categorical_accuracy: 0.6300 - lr: 4.3297e-04\n",
      "Epoch 84/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 1.0055 - accuracy: 0.6318 - categorical_accuracy: 0.6318\n",
      "Epoch 84: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0055 - accuracy: 0.6318 - categorical_accuracy: 0.6318 - val_loss: 1.0091 - val_accuracy: 0.6296 - val_categorical_accuracy: 0.6296 - lr: 4.3297e-04\n",
      "Epoch 85/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0055 - accuracy: 0.6318 - categorical_accuracy: 0.6318\n",
      "Epoch 85: val_accuracy did not improve from 0.63167\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0055 - accuracy: 0.6317 - categorical_accuracy: 0.6317 - val_loss: 1.0081 - val_accuracy: 0.6305 - val_categorical_accuracy: 0.6305 - lr: 4.3297e-04\n",
      "Epoch 86/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0055 - accuracy: 0.6319 - categorical_accuracy: 0.6319\n",
      "Epoch 86: val_accuracy improved from 0.63167 to 0.63219, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_0.h5\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0056 - accuracy: 0.6319 - categorical_accuracy: 0.6319 - val_loss: 1.0058 - val_accuracy: 0.6322 - val_categorical_accuracy: 0.6322 - lr: 4.3297e-04\n",
      "Epoch 87/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 1.0050 - accuracy: 0.6320 - categorical_accuracy: 0.6320\n",
      "Epoch 87: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0050 - accuracy: 0.6320 - categorical_accuracy: 0.6320 - val_loss: 1.0086 - val_accuracy: 0.6303 - val_categorical_accuracy: 0.6303 - lr: 4.3297e-04\n",
      "Epoch 88/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0049 - accuracy: 0.6325 - categorical_accuracy: 0.6325\n",
      "Epoch 88: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0050 - accuracy: 0.6324 - categorical_accuracy: 0.6324 - val_loss: 1.0075 - val_accuracy: 0.6312 - val_categorical_accuracy: 0.6312 - lr: 4.3297e-04\n",
      "Epoch 89/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 1.0054 - accuracy: 0.6320 - categorical_accuracy: 0.6320\n",
      "Epoch 89: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0054 - accuracy: 0.6321 - categorical_accuracy: 0.6321 - val_loss: 1.0129 - val_accuracy: 0.6271 - val_categorical_accuracy: 0.6271 - lr: 4.3297e-04\n",
      "Epoch 90/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0052 - accuracy: 0.6317 - categorical_accuracy: 0.6317\n",
      "Epoch 90: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.0053 - accuracy: 0.6316 - categorical_accuracy: 0.6316 - val_loss: 1.0113 - val_accuracy: 0.6290 - val_categorical_accuracy: 0.6290 - lr: 4.3297e-04\n",
      "Epoch 91/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.0049 - accuracy: 0.6325 - categorical_accuracy: 0.6325\n",
      "Epoch 91: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.0046 - accuracy: 0.6327 - categorical_accuracy: 0.6327 - val_loss: 1.0121 - val_accuracy: 0.6284 - val_categorical_accuracy: 0.6284 - lr: 4.3297e-04\n",
      "Epoch 92/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 1.0047 - accuracy: 0.6326 - categorical_accuracy: 0.6326\n",
      "Epoch 92: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.0049 - accuracy: 0.6326 - categorical_accuracy: 0.6326 - val_loss: 1.0158 - val_accuracy: 0.6250 - val_categorical_accuracy: 0.6250 - lr: 4.3297e-04\n",
      "Epoch 93/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 1.0043 - accuracy: 0.6329 - categorical_accuracy: 0.6329\n",
      "Epoch 93: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 1.0043 - accuracy: 0.6329 - categorical_accuracy: 0.6329 - val_loss: 1.0107 - val_accuracy: 0.6285 - val_categorical_accuracy: 0.6285 - lr: 4.3297e-04\n",
      "Epoch 94/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0046 - accuracy: 0.6327 - categorical_accuracy: 0.6327\n",
      "Epoch 94: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 1.0046 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0135 - val_accuracy: 0.6275 - val_categorical_accuracy: 0.6275 - lr: 4.3297e-04\n",
      "Epoch 95/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 1.0041 - accuracy: 0.6328 - categorical_accuracy: 0.6328\n",
      "Epoch 95: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0042 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0081 - val_accuracy: 0.6298 - val_categorical_accuracy: 0.6298 - lr: 4.3297e-04\n",
      "Epoch 96/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 1.0042 - accuracy: 0.6326 - categorical_accuracy: 0.6326\n",
      "Epoch 96: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.0042 - accuracy: 0.6327 - categorical_accuracy: 0.6327 - val_loss: 1.0076 - val_accuracy: 0.6315 - val_categorical_accuracy: 0.6315 - lr: 4.3297e-04\n",
      "Epoch 97/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 1.0044 - accuracy: 0.6329 - categorical_accuracy: 0.6329\n",
      "Epoch 97: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.0045 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0081 - val_accuracy: 0.6307 - val_categorical_accuracy: 0.6307 - lr: 4.3297e-04\n",
      "Epoch 98/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 1.0040 - accuracy: 0.6329 - categorical_accuracy: 0.6329\n",
      "Epoch 98: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.0040 - accuracy: 0.6329 - categorical_accuracy: 0.6329 - val_loss: 1.0094 - val_accuracy: 0.6295 - val_categorical_accuracy: 0.6295 - lr: 4.3297e-04\n",
      "Epoch 99/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 1.0040 - accuracy: 0.6329 - categorical_accuracy: 0.6329\n",
      "Epoch 99: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0040 - accuracy: 0.6329 - categorical_accuracy: 0.6329 - val_loss: 1.0111 - val_accuracy: 0.6282 - val_categorical_accuracy: 0.6282 - lr: 4.3297e-04\n",
      "Epoch 100/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 1.0038 - accuracy: 0.6328 - categorical_accuracy: 0.6328\n",
      "Epoch 100: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0038 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0113 - val_accuracy: 0.6297 - val_categorical_accuracy: 0.6297 - lr: 4.3297e-04\n",
      "Epoch 101/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 1.0035 - accuracy: 0.6333 - categorical_accuracy: 0.6333\n",
      "Epoch 101: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0036 - accuracy: 0.6333 - categorical_accuracy: 0.6333 - val_loss: 1.0079 - val_accuracy: 0.6312 - val_categorical_accuracy: 0.6312 - lr: 4.3297e-04\n",
      "Epoch 102/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 1.0036 - accuracy: 0.6332 - categorical_accuracy: 0.6332\n",
      "Epoch 102: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 1.0036 - accuracy: 0.6332 - categorical_accuracy: 0.6332 - val_loss: 1.0086 - val_accuracy: 0.6311 - val_categorical_accuracy: 0.6311 - lr: 4.3297e-04\n",
      "Epoch 103/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 1.0036 - accuracy: 0.6328 - categorical_accuracy: 0.6328\n",
      "Epoch 103: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0036 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0099 - val_accuracy: 0.6282 - val_categorical_accuracy: 0.6282 - lr: 4.3297e-04\n",
      "Epoch 104/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 1.0035 - accuracy: 0.6334 - categorical_accuracy: 0.6334\n",
      "Epoch 104: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0035 - accuracy: 0.6334 - categorical_accuracy: 0.6334 - val_loss: 1.0087 - val_accuracy: 0.6294 - val_categorical_accuracy: 0.6294 - lr: 4.3297e-04\n",
      "Epoch 105/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 1.0037 - accuracy: 0.6329 - categorical_accuracy: 0.6329\n",
      "Epoch 105: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0038 - accuracy: 0.6329 - categorical_accuracy: 0.6329 - val_loss: 1.0077 - val_accuracy: 0.6305 - val_categorical_accuracy: 0.6305 - lr: 4.3297e-04\n",
      "Epoch 106/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 1.0033 - accuracy: 0.6331 - categorical_accuracy: 0.6331\n",
      "Epoch 106: val_accuracy did not improve from 0.63219\n",
      "7514/7514 [==============================] - 7s 925us/step - loss: 1.0034 - accuracy: 0.6331 - categorical_accuracy: 0.6331 - val_loss: 1.0080 - val_accuracy: 0.6320 - val_categorical_accuracy: 0.6320 - lr: 4.3297e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kfold num: 1\n",
      "\n",
      "----------------\n",
      "Data loading complete:\n",
      "File name: None\n",
      "Training data size: 480,840\n",
      "Test data size: 120,210\n",
      "Number of constituents: 32\n",
      "Number of features: 3\n",
      "----------------\n",
      "\n",
      "(480840, 32, 3)\n",
      "(480840, 96) (120210, 96) (480840, 5) (120210, 5)\n",
      "number of G jets for training/validation: 96168/24042\n",
      "number of Q jets for training/validation: 96168/24042\n",
      "number of W jets for training/validation: 96168/24042\n",
      "number of Z jets for training/validation: 96168/24042\n",
      "number of T jets for training/validation: 96168/24042\n",
      "number of G jets for testing: 24042\n",
      "number of Q jets for testing: 24042\n",
      "number of W jets for testing: 24042\n",
      "number of Z jets for testing: 24042\n",
      "number of T jets for testing: 24042\n",
      "Epoch 1/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 1.5198 - accuracy: 0.4403 - categorical_accuracy: 0.4403\n",
      "Epoch 1: val_accuracy improved from -inf to 0.49136, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 1.5188 - accuracy: 0.4407 - categorical_accuracy: 0.4407 - val_loss: 1.3780 - val_accuracy: 0.4914 - val_categorical_accuracy: 0.4914 - lr: 4.3297e-04\n",
      "Epoch 2/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 1.2973 - accuracy: 0.5199 - categorical_accuracy: 0.5199\n",
      "Epoch 2: val_accuracy improved from 0.49136 to 0.54090, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 923us/step - loss: 1.2972 - accuracy: 0.5199 - categorical_accuracy: 0.5199 - val_loss: 1.2405 - val_accuracy: 0.5409 - val_categorical_accuracy: 0.5409 - lr: 4.3297e-04\n",
      "Epoch 3/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 1.2061 - accuracy: 0.5483 - categorical_accuracy: 0.5483\n",
      "Epoch 3: val_accuracy improved from 0.54090 to 0.54975, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 1.2060 - accuracy: 0.5483 - categorical_accuracy: 0.5483 - val_loss: 1.1916 - val_accuracy: 0.5498 - val_categorical_accuracy: 0.5498 - lr: 4.3297e-04\n",
      "Epoch 4/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.1567 - accuracy: 0.5659 - categorical_accuracy: 0.5659\n",
      "Epoch 4: val_accuracy improved from 0.54975 to 0.57454, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 921us/step - loss: 1.1567 - accuracy: 0.5658 - categorical_accuracy: 0.5658 - val_loss: 1.1351 - val_accuracy: 0.5745 - val_categorical_accuracy: 0.5745 - lr: 4.3297e-04\n",
      "Epoch 5/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.1168 - accuracy: 0.5825 - categorical_accuracy: 0.5825\n",
      "Epoch 5: val_accuracy improved from 0.57454 to 0.58669, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.1165 - accuracy: 0.5826 - categorical_accuracy: 0.5826 - val_loss: 1.1075 - val_accuracy: 0.5867 - val_categorical_accuracy: 0.5867 - lr: 4.3297e-04\n",
      "Epoch 6/200\n",
      "7459/7514 [============================>.] - ETA: 0s - loss: 1.0930 - accuracy: 0.5917 - categorical_accuracy: 0.5917\n",
      "Epoch 6: val_accuracy improved from 0.58669 to 0.59475, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0929 - accuracy: 0.5917 - categorical_accuracy: 0.5917 - val_loss: 1.0893 - val_accuracy: 0.5948 - val_categorical_accuracy: 0.5948 - lr: 4.3297e-04\n",
      "Epoch 7/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 1.0787 - accuracy: 0.5983 - categorical_accuracy: 0.5983\n",
      "Epoch 7: val_accuracy improved from 0.59475 to 0.59718, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0785 - accuracy: 0.5984 - categorical_accuracy: 0.5984 - val_loss: 1.0805 - val_accuracy: 0.5972 - val_categorical_accuracy: 0.5972 - lr: 4.3297e-04\n",
      "Epoch 8/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 1.0690 - accuracy: 0.6026 - categorical_accuracy: 0.6026\n",
      "Epoch 8: val_accuracy improved from 0.59718 to 0.60322, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0690 - accuracy: 0.6026 - categorical_accuracy: 0.6026 - val_loss: 1.0683 - val_accuracy: 0.6032 - val_categorical_accuracy: 0.6032 - lr: 4.3297e-04\n",
      "Epoch 9/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 1.0620 - accuracy: 0.6061 - categorical_accuracy: 0.6061\n",
      "Epoch 9: val_accuracy improved from 0.60322 to 0.60469, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0620 - accuracy: 0.6061 - categorical_accuracy: 0.6061 - val_loss: 1.0617 - val_accuracy: 0.6047 - val_categorical_accuracy: 0.6047 - lr: 4.3297e-04\n",
      "Epoch 10/200\n",
      "7503/7514 [============================>.] - ETA: 0s - loss: 1.0556 - accuracy: 0.6093 - categorical_accuracy: 0.6093\n",
      "Epoch 10: val_accuracy improved from 0.60469 to 0.60688, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0556 - accuracy: 0.6093 - categorical_accuracy: 0.6093 - val_loss: 1.0592 - val_accuracy: 0.6069 - val_categorical_accuracy: 0.6069 - lr: 4.3297e-04\n",
      "Epoch 11/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.0516 - accuracy: 0.6113 - categorical_accuracy: 0.6113\n",
      "Epoch 11: val_accuracy improved from 0.60688 to 0.60859, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0516 - accuracy: 0.6113 - categorical_accuracy: 0.6113 - val_loss: 1.0548 - val_accuracy: 0.6086 - val_categorical_accuracy: 0.6086 - lr: 4.3297e-04\n",
      "Epoch 12/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 1.0482 - accuracy: 0.6128 - categorical_accuracy: 0.6128\n",
      "Epoch 12: val_accuracy improved from 0.60859 to 0.61033, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0483 - accuracy: 0.6128 - categorical_accuracy: 0.6128 - val_loss: 1.0519 - val_accuracy: 0.6103 - val_categorical_accuracy: 0.6103 - lr: 4.3297e-04\n",
      "Epoch 13/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 1.0450 - accuracy: 0.6147 - categorical_accuracy: 0.6147\n",
      "Epoch 13: val_accuracy improved from 0.61033 to 0.61344, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 1.0452 - accuracy: 0.6147 - categorical_accuracy: 0.6147 - val_loss: 1.0489 - val_accuracy: 0.6134 - val_categorical_accuracy: 0.6134 - lr: 4.3297e-04\n",
      "Epoch 14/200\n",
      "7454/7514 [============================>.] - ETA: 0s - loss: 1.0432 - accuracy: 0.6155 - categorical_accuracy: 0.6155\n",
      "Epoch 14: val_accuracy did not improve from 0.61344\n",
      "7514/7514 [==============================] - 7s 922us/step - loss: 1.0432 - accuracy: 0.6155 - categorical_accuracy: 0.6155 - val_loss: 1.0494 - val_accuracy: 0.6130 - val_categorical_accuracy: 0.6130 - lr: 4.3297e-04\n",
      "Epoch 15/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 1.0409 - accuracy: 0.6163 - categorical_accuracy: 0.6163\n",
      "Epoch 15: val_accuracy did not improve from 0.61344\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0408 - accuracy: 0.6164 - categorical_accuracy: 0.6164 - val_loss: 1.0504 - val_accuracy: 0.6107 - val_categorical_accuracy: 0.6107 - lr: 4.3297e-04\n",
      "Epoch 16/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 1.0393 - accuracy: 0.6167 - categorical_accuracy: 0.6167\n",
      "Epoch 16: val_accuracy improved from 0.61344 to 0.61408, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0394 - accuracy: 0.6167 - categorical_accuracy: 0.6167 - val_loss: 1.0452 - val_accuracy: 0.6141 - val_categorical_accuracy: 0.6141 - lr: 4.3297e-04\n",
      "Epoch 17/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 1.0379 - accuracy: 0.6170 - categorical_accuracy: 0.6170\n",
      "Epoch 17: val_accuracy did not improve from 0.61408\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 1.0379 - accuracy: 0.6170 - categorical_accuracy: 0.6170 - val_loss: 1.0485 - val_accuracy: 0.6102 - val_categorical_accuracy: 0.6102 - lr: 4.3297e-04\n",
      "Epoch 18/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0368 - accuracy: 0.6183 - categorical_accuracy: 0.6183\n",
      "Epoch 18: val_accuracy improved from 0.61408 to 0.61550, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0367 - accuracy: 0.6183 - categorical_accuracy: 0.6183 - val_loss: 1.0430 - val_accuracy: 0.6155 - val_categorical_accuracy: 0.6155 - lr: 4.3297e-04\n",
      "Epoch 19/200\n",
      "7503/7514 [============================>.] - ETA: 0s - loss: 1.0356 - accuracy: 0.6185 - categorical_accuracy: 0.6185\n",
      "Epoch 19: val_accuracy did not improve from 0.61550\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 1.0356 - accuracy: 0.6185 - categorical_accuracy: 0.6185 - val_loss: 1.0437 - val_accuracy: 0.6143 - val_categorical_accuracy: 0.6143 - lr: 4.3297e-04\n",
      "Epoch 20/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.6191 - categorical_accuracy: 0.6191\n",
      "Epoch 20: val_accuracy improved from 0.61550 to 0.61719, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 917us/step - loss: 1.0343 - accuracy: 0.6191 - categorical_accuracy: 0.6191 - val_loss: 1.0397 - val_accuracy: 0.6172 - val_categorical_accuracy: 0.6172 - lr: 4.3297e-04\n",
      "Epoch 21/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0328 - accuracy: 0.6194 - categorical_accuracy: 0.6194\n",
      "Epoch 21: val_accuracy improved from 0.61719 to 0.61783, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 921us/step - loss: 1.0330 - accuracy: 0.6193 - categorical_accuracy: 0.6193 - val_loss: 1.0387 - val_accuracy: 0.6178 - val_categorical_accuracy: 0.6178 - lr: 4.3297e-04\n",
      "Epoch 22/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0321 - accuracy: 0.6194 - categorical_accuracy: 0.6194\n",
      "Epoch 22: val_accuracy did not improve from 0.61783\n",
      "7514/7514 [==============================] - 7s 927us/step - loss: 1.0322 - accuracy: 0.6193 - categorical_accuracy: 0.6193 - val_loss: 1.0491 - val_accuracy: 0.6104 - val_categorical_accuracy: 0.6104 - lr: 4.3297e-04\n",
      "Epoch 23/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 1.0304 - accuracy: 0.6199 - categorical_accuracy: 0.6199\n",
      "Epoch 23: val_accuracy improved from 0.61783 to 0.61818, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0304 - accuracy: 0.6200 - categorical_accuracy: 0.6200 - val_loss: 1.0370 - val_accuracy: 0.6182 - val_categorical_accuracy: 0.6182 - lr: 4.3297e-04\n",
      "Epoch 24/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 1.0293 - accuracy: 0.6204 - categorical_accuracy: 0.6204\n",
      "Epoch 24: val_accuracy improved from 0.61818 to 0.61976, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0293 - accuracy: 0.6204 - categorical_accuracy: 0.6204 - val_loss: 1.0348 - val_accuracy: 0.6198 - val_categorical_accuracy: 0.6198 - lr: 4.3297e-04\n",
      "Epoch 25/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 1.0287 - accuracy: 0.6205 - categorical_accuracy: 0.6205\n",
      "Epoch 25: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 1.0287 - accuracy: 0.6205 - categorical_accuracy: 0.6205 - val_loss: 1.0367 - val_accuracy: 0.6174 - val_categorical_accuracy: 0.6174 - lr: 4.3297e-04\n",
      "Epoch 26/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 1.0277 - accuracy: 0.6213 - categorical_accuracy: 0.6213\n",
      "Epoch 26: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 927us/step - loss: 1.0277 - accuracy: 0.6213 - categorical_accuracy: 0.6213 - val_loss: 1.0380 - val_accuracy: 0.6161 - val_categorical_accuracy: 0.6161 - lr: 4.3297e-04\n",
      "Epoch 27/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 1.0267 - accuracy: 0.6217 - categorical_accuracy: 0.6217\n",
      "Epoch 27: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0267 - accuracy: 0.6217 - categorical_accuracy: 0.6217 - val_loss: 1.0352 - val_accuracy: 0.6162 - val_categorical_accuracy: 0.6162 - lr: 4.3297e-04\n",
      "Epoch 28/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 1.0262 - accuracy: 0.6215 - categorical_accuracy: 0.6215\n",
      "Epoch 28: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 923us/step - loss: 1.0262 - accuracy: 0.6215 - categorical_accuracy: 0.6215 - val_loss: 1.0314 - val_accuracy: 0.6197 - val_categorical_accuracy: 0.6197 - lr: 4.3297e-04\n",
      "Epoch 29/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 1.0256 - accuracy: 0.6219 - categorical_accuracy: 0.6219\n",
      "Epoch 29: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 922us/step - loss: 1.0256 - accuracy: 0.6219 - categorical_accuracy: 0.6219 - val_loss: 1.0338 - val_accuracy: 0.6178 - val_categorical_accuracy: 0.6178 - lr: 4.3297e-04\n",
      "Epoch 30/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 1.0248 - accuracy: 0.6224 - categorical_accuracy: 0.6224\n",
      "Epoch 30: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0249 - accuracy: 0.6223 - categorical_accuracy: 0.6223 - val_loss: 1.0300 - val_accuracy: 0.6194 - val_categorical_accuracy: 0.6194 - lr: 4.3297e-04\n",
      "Epoch 31/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.0241 - accuracy: 0.6226 - categorical_accuracy: 0.6226\n",
      "Epoch 31: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0241 - accuracy: 0.6225 - categorical_accuracy: 0.6225 - val_loss: 1.0324 - val_accuracy: 0.6180 - val_categorical_accuracy: 0.6180 - lr: 4.3297e-04\n",
      "Epoch 32/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 1.0230 - accuracy: 0.6225 - categorical_accuracy: 0.6225\n",
      "Epoch 32: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 1.0231 - accuracy: 0.6225 - categorical_accuracy: 0.6225 - val_loss: 1.0341 - val_accuracy: 0.6158 - val_categorical_accuracy: 0.6158 - lr: 4.3297e-04\n",
      "Epoch 33/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 1.0223 - accuracy: 0.6231 - categorical_accuracy: 0.6231\n",
      "Epoch 33: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0224 - accuracy: 0.6231 - categorical_accuracy: 0.6231 - val_loss: 1.0352 - val_accuracy: 0.6163 - val_categorical_accuracy: 0.6163 - lr: 4.3297e-04\n",
      "Epoch 34/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 1.0216 - accuracy: 0.6238 - categorical_accuracy: 0.6238\n",
      "Epoch 34: val_accuracy did not improve from 0.61976\n",
      "7514/7514 [==============================] - 7s 923us/step - loss: 1.0217 - accuracy: 0.6238 - categorical_accuracy: 0.6238 - val_loss: 1.0295 - val_accuracy: 0.6180 - val_categorical_accuracy: 0.6180 - lr: 4.3297e-04\n",
      "Epoch 35/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 1.0212 - accuracy: 0.6239 - categorical_accuracy: 0.6239\n",
      "Epoch 35: val_accuracy improved from 0.61976 to 0.61986, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 1.0212 - accuracy: 0.6239 - categorical_accuracy: 0.6239 - val_loss: 1.0285 - val_accuracy: 0.6199 - val_categorical_accuracy: 0.6199 - lr: 4.3297e-04\n",
      "Epoch 36/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 1.0210 - accuracy: 0.6238 - categorical_accuracy: 0.6238\n",
      "Epoch 36: val_accuracy did not improve from 0.61986\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0209 - accuracy: 0.6239 - categorical_accuracy: 0.6239 - val_loss: 1.0362 - val_accuracy: 0.6175 - val_categorical_accuracy: 0.6175 - lr: 4.3297e-04\n",
      "Epoch 37/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0198 - accuracy: 0.6243 - categorical_accuracy: 0.6243\n",
      "Epoch 37: val_accuracy improved from 0.61986 to 0.62036, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0197 - accuracy: 0.6244 - categorical_accuracy: 0.6244 - val_loss: 1.0257 - val_accuracy: 0.6204 - val_categorical_accuracy: 0.6204 - lr: 4.3297e-04\n",
      "Epoch 38/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 1.0196 - accuracy: 0.6240 - categorical_accuracy: 0.6240\n",
      "Epoch 38: val_accuracy did not improve from 0.62036\n",
      "7514/7514 [==============================] - 7s 921us/step - loss: 1.0197 - accuracy: 0.6240 - categorical_accuracy: 0.6240 - val_loss: 1.0328 - val_accuracy: 0.6178 - val_categorical_accuracy: 0.6178 - lr: 4.3297e-04\n",
      "Epoch 39/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.0191 - accuracy: 0.6242 - categorical_accuracy: 0.6242\n",
      "Epoch 39: val_accuracy did not improve from 0.62036\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 1.0190 - accuracy: 0.6242 - categorical_accuracy: 0.6242 - val_loss: 1.0286 - val_accuracy: 0.6196 - val_categorical_accuracy: 0.6196 - lr: 4.3297e-04\n",
      "Epoch 40/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.0187 - accuracy: 0.6251 - categorical_accuracy: 0.6251\n",
      "Epoch 40: val_accuracy did not improve from 0.62036\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0186 - accuracy: 0.6252 - categorical_accuracy: 0.6252 - val_loss: 1.0325 - val_accuracy: 0.6181 - val_categorical_accuracy: 0.6181 - lr: 4.3297e-04\n",
      "Epoch 41/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0186 - accuracy: 0.6255 - categorical_accuracy: 0.6255\n",
      "Epoch 41: val_accuracy did not improve from 0.62036\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 1.0185 - accuracy: 0.6255 - categorical_accuracy: 0.6255 - val_loss: 1.0305 - val_accuracy: 0.6190 - val_categorical_accuracy: 0.6190 - lr: 4.3297e-04\n",
      "Epoch 42/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 1.0182 - accuracy: 0.6250 - categorical_accuracy: 0.6250\n",
      "Epoch 42: val_accuracy improved from 0.62036 to 0.62077, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 925us/step - loss: 1.0181 - accuracy: 0.6250 - categorical_accuracy: 0.6250 - val_loss: 1.0284 - val_accuracy: 0.6208 - val_categorical_accuracy: 0.6208 - lr: 4.3297e-04\n",
      "Epoch 43/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 1.0176 - accuracy: 0.6252 - categorical_accuracy: 0.6252\n",
      "Epoch 43: val_accuracy improved from 0.62077 to 0.62195, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0176 - accuracy: 0.6252 - categorical_accuracy: 0.6252 - val_loss: 1.0259 - val_accuracy: 0.6220 - val_categorical_accuracy: 0.6220 - lr: 4.3297e-04\n",
      "Epoch 44/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 1.0181 - accuracy: 0.6256 - categorical_accuracy: 0.6256\n",
      "Epoch 44: val_accuracy did not improve from 0.62195\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 1.0180 - accuracy: 0.6256 - categorical_accuracy: 0.6256 - val_loss: 1.0278 - val_accuracy: 0.6189 - val_categorical_accuracy: 0.6189 - lr: 4.3297e-04\n",
      "Epoch 45/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0172 - accuracy: 0.6253 - categorical_accuracy: 0.6253\n",
      "Epoch 45: val_accuracy did not improve from 0.62195\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0173 - accuracy: 0.6253 - categorical_accuracy: 0.6253 - val_loss: 1.0309 - val_accuracy: 0.6173 - val_categorical_accuracy: 0.6173 - lr: 4.3297e-04\n",
      "Epoch 46/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 1.0167 - accuracy: 0.6250 - categorical_accuracy: 0.6250\n",
      "Epoch 46: val_accuracy did not improve from 0.62195\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 1.0168 - accuracy: 0.6250 - categorical_accuracy: 0.6250 - val_loss: 1.0257 - val_accuracy: 0.6209 - val_categorical_accuracy: 0.6209 - lr: 4.3297e-04\n",
      "Epoch 47/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.0159 - accuracy: 0.6256 - categorical_accuracy: 0.6256\n",
      "Epoch 47: val_accuracy did not improve from 0.62195\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.0160 - accuracy: 0.6256 - categorical_accuracy: 0.6256 - val_loss: 1.0249 - val_accuracy: 0.6193 - val_categorical_accuracy: 0.6193 - lr: 4.3297e-04\n",
      "Epoch 48/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 1.0155 - accuracy: 0.6260 - categorical_accuracy: 0.6260\n",
      "Epoch 48: val_accuracy did not improve from 0.62195\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 1.0155 - accuracy: 0.6260 - categorical_accuracy: 0.6260 - val_loss: 1.0240 - val_accuracy: 0.6210 - val_categorical_accuracy: 0.6210 - lr: 4.3297e-04\n",
      "Epoch 49/200\n",
      "7503/7514 [============================>.] - ETA: 0s - loss: 1.0153 - accuracy: 0.6264 - categorical_accuracy: 0.6264\n",
      "Epoch 49: val_accuracy improved from 0.62195 to 0.62262, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 1.0152 - accuracy: 0.6264 - categorical_accuracy: 0.6264 - val_loss: 1.0245 - val_accuracy: 0.6226 - val_categorical_accuracy: 0.6226 - lr: 4.3297e-04\n",
      "Epoch 50/200\n",
      "7503/7514 [============================>.] - ETA: 0s - loss: 1.0146 - accuracy: 0.6266 - categorical_accuracy: 0.6266\n",
      "Epoch 50: val_accuracy did not improve from 0.62262\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.0146 - accuracy: 0.6267 - categorical_accuracy: 0.6267 - val_loss: 1.0242 - val_accuracy: 0.6199 - val_categorical_accuracy: 0.6199 - lr: 4.3297e-04\n",
      "Epoch 51/200\n",
      "7459/7514 [============================>.] - ETA: 0s - loss: 1.0138 - accuracy: 0.6272 - categorical_accuracy: 0.6272\n",
      "Epoch 51: val_accuracy did not improve from 0.62262\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 1.0138 - accuracy: 0.6271 - categorical_accuracy: 0.6271 - val_loss: 1.0286 - val_accuracy: 0.6213 - val_categorical_accuracy: 0.6213 - lr: 4.3297e-04\n",
      "Epoch 52/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.0134 - accuracy: 0.6269 - categorical_accuracy: 0.6269\n",
      "Epoch 52: val_accuracy improved from 0.62262 to 0.62336, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 1.0134 - accuracy: 0.6268 - categorical_accuracy: 0.6268 - val_loss: 1.0209 - val_accuracy: 0.6234 - val_categorical_accuracy: 0.6234 - lr: 4.3297e-04\n",
      "Epoch 53/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 1.0129 - accuracy: 0.6277 - categorical_accuracy: 0.6277\n",
      "Epoch 53: val_accuracy did not improve from 0.62336\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0129 - accuracy: 0.6278 - categorical_accuracy: 0.6278 - val_loss: 1.0243 - val_accuracy: 0.6217 - val_categorical_accuracy: 0.6217 - lr: 4.3297e-04\n",
      "Epoch 54/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 1.0126 - accuracy: 0.6267 - categorical_accuracy: 0.6267\n",
      "Epoch 54: val_accuracy did not improve from 0.62336\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 1.0126 - accuracy: 0.6267 - categorical_accuracy: 0.6267 - val_loss: 1.0208 - val_accuracy: 0.6229 - val_categorical_accuracy: 0.6229 - lr: 4.3297e-04\n",
      "Epoch 55/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0122 - accuracy: 0.6276 - categorical_accuracy: 0.6276\n",
      "Epoch 55: val_accuracy did not improve from 0.62336\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 1.0123 - accuracy: 0.6275 - categorical_accuracy: 0.6275 - val_loss: 1.0236 - val_accuracy: 0.6217 - val_categorical_accuracy: 0.6217 - lr: 4.3297e-04\n",
      "Epoch 56/200\n",
      "7509/7514 [============================>.] - ETA: 0s - loss: 1.0116 - accuracy: 0.6277 - categorical_accuracy: 0.6277\n",
      "Epoch 56: val_accuracy did not improve from 0.62336\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0116 - accuracy: 0.6277 - categorical_accuracy: 0.6277 - val_loss: 1.0315 - val_accuracy: 0.6176 - val_categorical_accuracy: 0.6176 - lr: 4.3297e-04\n",
      "Epoch 57/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 1.0115 - accuracy: 0.6278 - categorical_accuracy: 0.6278\n",
      "Epoch 57: val_accuracy improved from 0.62336 to 0.62488, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.0115 - accuracy: 0.6278 - categorical_accuracy: 0.6278 - val_loss: 1.0194 - val_accuracy: 0.6249 - val_categorical_accuracy: 0.6249 - lr: 4.3297e-04\n",
      "Epoch 58/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 1.0112 - accuracy: 0.6282 - categorical_accuracy: 0.6282\n",
      "Epoch 58: val_accuracy did not improve from 0.62488\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0112 - accuracy: 0.6282 - categorical_accuracy: 0.6282 - val_loss: 1.0193 - val_accuracy: 0.6238 - val_categorical_accuracy: 0.6238 - lr: 4.3297e-04\n",
      "Epoch 59/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 1.0115 - accuracy: 0.6280 - categorical_accuracy: 0.6280\n",
      "Epoch 59: val_accuracy did not improve from 0.62488\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0113 - accuracy: 0.6281 - categorical_accuracy: 0.6281 - val_loss: 1.0229 - val_accuracy: 0.6218 - val_categorical_accuracy: 0.6218 - lr: 4.3297e-04\n",
      "Epoch 60/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 1.0111 - accuracy: 0.6281 - categorical_accuracy: 0.6281\n",
      "Epoch 60: val_accuracy did not improve from 0.62488\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0110 - accuracy: 0.6281 - categorical_accuracy: 0.6281 - val_loss: 1.0236 - val_accuracy: 0.6218 - val_categorical_accuracy: 0.6218 - lr: 4.3297e-04\n",
      "Epoch 61/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0105 - accuracy: 0.6284 - categorical_accuracy: 0.6284\n",
      "Epoch 61: val_accuracy did not improve from 0.62488\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0105 - accuracy: 0.6284 - categorical_accuracy: 0.6284 - val_loss: 1.0177 - val_accuracy: 0.6230 - val_categorical_accuracy: 0.6230 - lr: 4.3297e-04\n",
      "Epoch 62/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 1.0107 - accuracy: 0.6282 - categorical_accuracy: 0.6282\n",
      "Epoch 62: val_accuracy did not improve from 0.62488\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 1.0107 - accuracy: 0.6282 - categorical_accuracy: 0.6282 - val_loss: 1.0179 - val_accuracy: 0.6240 - val_categorical_accuracy: 0.6240 - lr: 4.3297e-04\n",
      "Epoch 63/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.0102 - accuracy: 0.6282 - categorical_accuracy: 0.6282\n",
      "Epoch 63: val_accuracy improved from 0.62488 to 0.62504, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0102 - accuracy: 0.6282 - categorical_accuracy: 0.6282 - val_loss: 1.0181 - val_accuracy: 0.6250 - val_categorical_accuracy: 0.6250 - lr: 4.3297e-04\n",
      "Epoch 64/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0098 - accuracy: 0.6282 - categorical_accuracy: 0.6282\n",
      "Epoch 64: val_accuracy did not improve from 0.62504\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0097 - accuracy: 0.6282 - categorical_accuracy: 0.6282 - val_loss: 1.0219 - val_accuracy: 0.6229 - val_categorical_accuracy: 0.6229 - lr: 4.3297e-04\n",
      "Epoch 65/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 1.0097 - accuracy: 0.6287 - categorical_accuracy: 0.6287\n",
      "Epoch 65: val_accuracy did not improve from 0.62504\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 1.0097 - accuracy: 0.6287 - categorical_accuracy: 0.6287 - val_loss: 1.0233 - val_accuracy: 0.6220 - val_categorical_accuracy: 0.6220 - lr: 4.3297e-04\n",
      "Epoch 66/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 1.0099 - accuracy: 0.6285 - categorical_accuracy: 0.6285\n",
      "Epoch 66: val_accuracy did not improve from 0.62504\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0100 - accuracy: 0.6284 - categorical_accuracy: 0.6284 - val_loss: 1.0184 - val_accuracy: 0.6246 - val_categorical_accuracy: 0.6246 - lr: 4.3297e-04\n",
      "Epoch 67/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0094 - accuracy: 0.6282 - categorical_accuracy: 0.6282\n",
      "Epoch 67: val_accuracy did not improve from 0.62504\n",
      "7514/7514 [==============================] - 7s 918us/step - loss: 1.0094 - accuracy: 0.6282 - categorical_accuracy: 0.6282 - val_loss: 1.0163 - val_accuracy: 0.6239 - val_categorical_accuracy: 0.6239 - lr: 4.3297e-04\n",
      "Epoch 68/200\n",
      "7509/7514 [============================>.] - ETA: 0s - loss: 1.0093 - accuracy: 0.6293 - categorical_accuracy: 0.6293\n",
      "Epoch 68: val_accuracy did not improve from 0.62504\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.0093 - accuracy: 0.6293 - categorical_accuracy: 0.6293 - val_loss: 1.0181 - val_accuracy: 0.6235 - val_categorical_accuracy: 0.6235 - lr: 4.3297e-04\n",
      "Epoch 69/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 1.0092 - accuracy: 0.6293 - categorical_accuracy: 0.6293\n",
      "Epoch 69: val_accuracy did not improve from 0.62504\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0091 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0223 - val_accuracy: 0.6229 - val_categorical_accuracy: 0.6229 - lr: 4.3297e-04\n",
      "Epoch 70/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 1.0095 - accuracy: 0.6290 - categorical_accuracy: 0.6290\n",
      "Epoch 70: val_accuracy improved from 0.62504 to 0.62564, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 1.0094 - accuracy: 0.6290 - categorical_accuracy: 0.6290 - val_loss: 1.0154 - val_accuracy: 0.6256 - val_categorical_accuracy: 0.6256 - lr: 4.3297e-04\n",
      "Epoch 71/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 1.0087 - accuracy: 0.6289 - categorical_accuracy: 0.6289\n",
      "Epoch 71: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 923us/step - loss: 1.0086 - accuracy: 0.6289 - categorical_accuracy: 0.6289 - val_loss: 1.0189 - val_accuracy: 0.6235 - val_categorical_accuracy: 0.6235 - lr: 4.3297e-04\n",
      "Epoch 72/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 1.0089 - accuracy: 0.6293 - categorical_accuracy: 0.6293\n",
      "Epoch 72: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0089 - accuracy: 0.6293 - categorical_accuracy: 0.6293 - val_loss: 1.0171 - val_accuracy: 0.6244 - val_categorical_accuracy: 0.6244 - lr: 4.3297e-04\n",
      "Epoch 73/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 1.0086 - accuracy: 0.6293 - categorical_accuracy: 0.6293\n",
      "Epoch 73: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 1.0086 - accuracy: 0.6292 - categorical_accuracy: 0.6292 - val_loss: 1.0176 - val_accuracy: 0.6243 - val_categorical_accuracy: 0.6243 - lr: 4.3297e-04\n",
      "Epoch 74/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.0084 - accuracy: 0.6297 - categorical_accuracy: 0.6297\n",
      "Epoch 74: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 1.0085 - accuracy: 0.6297 - categorical_accuracy: 0.6297 - val_loss: 1.0197 - val_accuracy: 0.6227 - val_categorical_accuracy: 0.6227 - lr: 4.3297e-04\n",
      "Epoch 75/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0081 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 75: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 920us/step - loss: 1.0080 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0212 - val_accuracy: 0.6223 - val_categorical_accuracy: 0.6223 - lr: 4.3297e-04\n",
      "Epoch 76/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 1.0082 - accuracy: 0.6289 - categorical_accuracy: 0.6289\n",
      "Epoch 76: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 922us/step - loss: 1.0081 - accuracy: 0.6289 - categorical_accuracy: 0.6289 - val_loss: 1.0197 - val_accuracy: 0.6238 - val_categorical_accuracy: 0.6238 - lr: 4.3297e-04\n",
      "Epoch 77/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 1.0081 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 77: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0080 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0252 - val_accuracy: 0.6206 - val_categorical_accuracy: 0.6206 - lr: 4.3297e-04\n",
      "Epoch 78/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 1.0080 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 78: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 1.0079 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0154 - val_accuracy: 0.6251 - val_categorical_accuracy: 0.6251 - lr: 4.3297e-04\n",
      "Epoch 79/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0076 - accuracy: 0.6296 - categorical_accuracy: 0.6296\n",
      "Epoch 79: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0077 - accuracy: 0.6295 - categorical_accuracy: 0.6295 - val_loss: 1.0199 - val_accuracy: 0.6231 - val_categorical_accuracy: 0.6231 - lr: 4.3297e-04\n",
      "Epoch 80/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 1.0076 - accuracy: 0.6295 - categorical_accuracy: 0.6295\n",
      "Epoch 80: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0076 - accuracy: 0.6295 - categorical_accuracy: 0.6295 - val_loss: 1.0192 - val_accuracy: 0.6229 - val_categorical_accuracy: 0.6229 - lr: 4.3297e-04\n",
      "Epoch 81/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.6298 - categorical_accuracy: 0.6298\n",
      "Epoch 81: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0076 - accuracy: 0.6298 - categorical_accuracy: 0.6298 - val_loss: 1.0176 - val_accuracy: 0.6249 - val_categorical_accuracy: 0.6249 - lr: 4.3297e-04\n",
      "Epoch 82/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 82: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0075 - accuracy: 0.6295 - categorical_accuracy: 0.6295 - val_loss: 1.0188 - val_accuracy: 0.6225 - val_categorical_accuracy: 0.6225 - lr: 4.3297e-04\n",
      "Epoch 83/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 1.0072 - accuracy: 0.6295 - categorical_accuracy: 0.6295\n",
      "Epoch 83: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0071 - accuracy: 0.6295 - categorical_accuracy: 0.6295 - val_loss: 1.0170 - val_accuracy: 0.6244 - val_categorical_accuracy: 0.6244 - lr: 4.3297e-04\n",
      "Epoch 84/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 1.0073 - accuracy: 0.6290 - categorical_accuracy: 0.6290\n",
      "Epoch 84: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 1.0073 - accuracy: 0.6290 - categorical_accuracy: 0.6290 - val_loss: 1.0200 - val_accuracy: 0.6231 - val_categorical_accuracy: 0.6231 - lr: 4.3297e-04\n",
      "Epoch 85/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 1.0075 - accuracy: 0.6292 - categorical_accuracy: 0.6292\n",
      "Epoch 85: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 1.0075 - accuracy: 0.6292 - categorical_accuracy: 0.6292 - val_loss: 1.0167 - val_accuracy: 0.6232 - val_categorical_accuracy: 0.6232 - lr: 4.3297e-04\n",
      "Epoch 86/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 1.0071 - accuracy: 0.6295 - categorical_accuracy: 0.6295\n",
      "Epoch 86: val_accuracy did not improve from 0.62564\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0070 - accuracy: 0.6296 - categorical_accuracy: 0.6296 - val_loss: 1.0213 - val_accuracy: 0.6233 - val_categorical_accuracy: 0.6233 - lr: 4.3297e-04\n",
      "Epoch 87/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 1.0067 - accuracy: 0.6299 - categorical_accuracy: 0.6299\n",
      "Epoch 87: val_accuracy improved from 0.62564 to 0.62569, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0067 - accuracy: 0.6299 - categorical_accuracy: 0.6299 - val_loss: 1.0148 - val_accuracy: 0.6257 - val_categorical_accuracy: 0.6257 - lr: 4.3297e-04\n",
      "Epoch 88/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 1.0066 - accuracy: 0.6298 - categorical_accuracy: 0.6298\n",
      "Epoch 88: val_accuracy did not improve from 0.62569\n",
      "7514/7514 [==============================] - 7s 918us/step - loss: 1.0066 - accuracy: 0.6298 - categorical_accuracy: 0.6298 - val_loss: 1.0159 - val_accuracy: 0.6246 - val_categorical_accuracy: 0.6246 - lr: 4.3297e-04\n",
      "Epoch 89/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 1.0065 - accuracy: 0.6296 - categorical_accuracy: 0.6296\n",
      "Epoch 89: val_accuracy did not improve from 0.62569\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.0065 - accuracy: 0.6296 - categorical_accuracy: 0.6296 - val_loss: 1.0147 - val_accuracy: 0.6250 - val_categorical_accuracy: 0.6250 - lr: 4.3297e-04\n",
      "Epoch 90/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0065 - accuracy: 0.6295 - categorical_accuracy: 0.6295\n",
      "Epoch 90: val_accuracy did not improve from 0.62569\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 1.0067 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0223 - val_accuracy: 0.6217 - val_categorical_accuracy: 0.6217 - lr: 4.3297e-04\n",
      "Epoch 91/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9804 - accuracy: 0.6420 - categorical_accuracy: 0.6420\n",
      "Epoch 91: val_accuracy improved from 0.62569 to 0.63524, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 0.9804 - accuracy: 0.6421 - categorical_accuracy: 0.6421 - val_loss: 0.9933 - val_accuracy: 0.6352 - val_categorical_accuracy: 0.6352 - lr: 8.6593e-05\n",
      "Epoch 92/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 0.9753 - accuracy: 0.6443 - categorical_accuracy: 0.6443\n",
      "Epoch 92: val_accuracy improved from 0.63524 to 0.63580, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 0.9753 - accuracy: 0.6443 - categorical_accuracy: 0.6443 - val_loss: 0.9922 - val_accuracy: 0.6358 - val_categorical_accuracy: 0.6358 - lr: 8.6593e-05\n",
      "Epoch 93/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 0.9739 - accuracy: 0.6448 - categorical_accuracy: 0.6448\n",
      "Epoch 93: val_accuracy improved from 0.63580 to 0.63711, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 0.9739 - accuracy: 0.6449 - categorical_accuracy: 0.6449 - val_loss: 0.9902 - val_accuracy: 0.6371 - val_categorical_accuracy: 0.6371 - lr: 8.6593e-05\n",
      "Epoch 94/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9734 - accuracy: 0.6449 - categorical_accuracy: 0.6449\n",
      "Epoch 94: val_accuracy did not improve from 0.63711\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 0.9733 - accuracy: 0.6450 - categorical_accuracy: 0.6450 - val_loss: 0.9900 - val_accuracy: 0.6365 - val_categorical_accuracy: 0.6365 - lr: 8.6593e-05\n",
      "Epoch 95/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9730 - accuracy: 0.6456 - categorical_accuracy: 0.6456\n",
      "Epoch 95: val_accuracy did not improve from 0.63711\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 0.9730 - accuracy: 0.6456 - categorical_accuracy: 0.6456 - val_loss: 0.9900 - val_accuracy: 0.6363 - val_categorical_accuracy: 0.6363 - lr: 8.6593e-05\n",
      "Epoch 96/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 0.9728 - accuracy: 0.6451 - categorical_accuracy: 0.6451\n",
      "Epoch 96: val_accuracy did not improve from 0.63711\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 0.9728 - accuracy: 0.6452 - categorical_accuracy: 0.6452 - val_loss: 0.9889 - val_accuracy: 0.6364 - val_categorical_accuracy: 0.6364 - lr: 8.6593e-05\n",
      "Epoch 97/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 0.9723 - accuracy: 0.6460 - categorical_accuracy: 0.6460\n",
      "Epoch 97: val_accuracy did not improve from 0.63711\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 0.9723 - accuracy: 0.6460 - categorical_accuracy: 0.6460 - val_loss: 0.9903 - val_accuracy: 0.6363 - val_categorical_accuracy: 0.6363 - lr: 8.6593e-05\n",
      "Epoch 98/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 0.9722 - accuracy: 0.6454 - categorical_accuracy: 0.6454\n",
      "Epoch 98: val_accuracy improved from 0.63711 to 0.63728, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 0.9720 - accuracy: 0.6455 - categorical_accuracy: 0.6455 - val_loss: 0.9893 - val_accuracy: 0.6373 - val_categorical_accuracy: 0.6373 - lr: 8.6593e-05\n",
      "Epoch 99/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9716 - accuracy: 0.6461 - categorical_accuracy: 0.6461\n",
      "Epoch 99: val_accuracy did not improve from 0.63728\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 0.9715 - accuracy: 0.6461 - categorical_accuracy: 0.6461 - val_loss: 0.9890 - val_accuracy: 0.6367 - val_categorical_accuracy: 0.6367 - lr: 8.6593e-05\n",
      "Epoch 100/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 0.9716 - accuracy: 0.6459 - categorical_accuracy: 0.6459\n",
      "Epoch 100: val_accuracy did not improve from 0.63728\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 0.9716 - accuracy: 0.6459 - categorical_accuracy: 0.6459 - val_loss: 0.9908 - val_accuracy: 0.6360 - val_categorical_accuracy: 0.6360 - lr: 8.6593e-05\n",
      "Epoch 101/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 0.9716 - accuracy: 0.6459 - categorical_accuracy: 0.6459\n",
      "Epoch 101: val_accuracy improved from 0.63728 to 0.63798, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9716 - accuracy: 0.6459 - categorical_accuracy: 0.6459 - val_loss: 0.9882 - val_accuracy: 0.6380 - val_categorical_accuracy: 0.6380 - lr: 8.6593e-05\n",
      "Epoch 102/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9712 - accuracy: 0.6459 - categorical_accuracy: 0.6459\n",
      "Epoch 102: val_accuracy improved from 0.63798 to 0.63828, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 0.9713 - accuracy: 0.6459 - categorical_accuracy: 0.6459 - val_loss: 0.9885 - val_accuracy: 0.6383 - val_categorical_accuracy: 0.6383 - lr: 8.6593e-05\n",
      "Epoch 103/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9710 - accuracy: 0.6462 - categorical_accuracy: 0.6462\n",
      "Epoch 103: val_accuracy did not improve from 0.63828\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 0.9710 - accuracy: 0.6462 - categorical_accuracy: 0.6462 - val_loss: 0.9912 - val_accuracy: 0.6362 - val_categorical_accuracy: 0.6362 - lr: 8.6593e-05\n",
      "Epoch 104/200\n",
      "7459/7514 [============================>.] - ETA: 0s - loss: 0.9705 - accuracy: 0.6468 - categorical_accuracy: 0.6468\n",
      "Epoch 104: val_accuracy improved from 0.63828 to 0.63842, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 0.9707 - accuracy: 0.6467 - categorical_accuracy: 0.6467 - val_loss: 0.9876 - val_accuracy: 0.6384 - val_categorical_accuracy: 0.6384 - lr: 8.6593e-05\n",
      "Epoch 105/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9706 - accuracy: 0.6462 - categorical_accuracy: 0.6462\n",
      "Epoch 105: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9706 - accuracy: 0.6462 - categorical_accuracy: 0.6462 - val_loss: 0.9881 - val_accuracy: 0.6367 - val_categorical_accuracy: 0.6367 - lr: 8.6593e-05\n",
      "Epoch 106/200\n",
      "7503/7514 [============================>.] - ETA: 0s - loss: 0.9705 - accuracy: 0.6463 - categorical_accuracy: 0.6463\n",
      "Epoch 106: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 951us/step - loss: 0.9706 - accuracy: 0.6463 - categorical_accuracy: 0.6463 - val_loss: 0.9893 - val_accuracy: 0.6368 - val_categorical_accuracy: 0.6368 - lr: 8.6593e-05\n",
      "Epoch 107/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9703 - accuracy: 0.6469 - categorical_accuracy: 0.6469\n",
      "Epoch 107: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 0.9705 - accuracy: 0.6468 - categorical_accuracy: 0.6468 - val_loss: 0.9896 - val_accuracy: 0.6372 - val_categorical_accuracy: 0.6372 - lr: 8.6593e-05\n",
      "Epoch 108/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 0.9705 - accuracy: 0.6461 - categorical_accuracy: 0.6461\n",
      "Epoch 108: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 0.9705 - accuracy: 0.6461 - categorical_accuracy: 0.6461 - val_loss: 0.9886 - val_accuracy: 0.6373 - val_categorical_accuracy: 0.6373 - lr: 8.6593e-05\n",
      "Epoch 109/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 0.9702 - accuracy: 0.6462 - categorical_accuracy: 0.6462\n",
      "Epoch 109: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 0.9702 - accuracy: 0.6462 - categorical_accuracy: 0.6462 - val_loss: 0.9883 - val_accuracy: 0.6377 - val_categorical_accuracy: 0.6377 - lr: 8.6593e-05\n",
      "Epoch 110/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 0.9701 - accuracy: 0.6464 - categorical_accuracy: 0.6464\n",
      "Epoch 110: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 0.9702 - accuracy: 0.6464 - categorical_accuracy: 0.6464 - val_loss: 0.9876 - val_accuracy: 0.6379 - val_categorical_accuracy: 0.6379 - lr: 8.6593e-05\n",
      "Epoch 111/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9699 - accuracy: 0.6467 - categorical_accuracy: 0.6467\n",
      "Epoch 111: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 0.9700 - accuracy: 0.6467 - categorical_accuracy: 0.6467 - val_loss: 0.9882 - val_accuracy: 0.6375 - val_categorical_accuracy: 0.6375 - lr: 8.6593e-05\n",
      "Epoch 112/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9699 - accuracy: 0.6465 - categorical_accuracy: 0.6465\n",
      "Epoch 112: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 0.9700 - accuracy: 0.6464 - categorical_accuracy: 0.6464 - val_loss: 0.9907 - val_accuracy: 0.6369 - val_categorical_accuracy: 0.6369 - lr: 8.6593e-05\n",
      "Epoch 113/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6467 - categorical_accuracy: 0.6467\n",
      "Epoch 113: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 0.9697 - accuracy: 0.6467 - categorical_accuracy: 0.6467 - val_loss: 0.9891 - val_accuracy: 0.6363 - val_categorical_accuracy: 0.6363 - lr: 8.6593e-05\n",
      "Epoch 114/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9696 - accuracy: 0.6469 - categorical_accuracy: 0.6469\n",
      "Epoch 114: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 0.9697 - accuracy: 0.6469 - categorical_accuracy: 0.6469 - val_loss: 0.9889 - val_accuracy: 0.6380 - val_categorical_accuracy: 0.6380 - lr: 8.6593e-05\n",
      "Epoch 115/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6470 - categorical_accuracy: 0.6470\n",
      "Epoch 115: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 917us/step - loss: 0.9697 - accuracy: 0.6470 - categorical_accuracy: 0.6470 - val_loss: 0.9910 - val_accuracy: 0.6356 - val_categorical_accuracy: 0.6356 - lr: 8.6593e-05\n",
      "Epoch 116/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6470 - categorical_accuracy: 0.6470\n",
      "Epoch 116: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 0.9697 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9871 - val_accuracy: 0.6375 - val_categorical_accuracy: 0.6375 - lr: 8.6593e-05\n",
      "Epoch 117/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 0.9693 - accuracy: 0.6468 - categorical_accuracy: 0.6468\n",
      "Epoch 117: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9693 - accuracy: 0.6468 - categorical_accuracy: 0.6468 - val_loss: 0.9874 - val_accuracy: 0.6384 - val_categorical_accuracy: 0.6384 - lr: 8.6593e-05\n",
      "Epoch 118/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6471 - categorical_accuracy: 0.6471\n",
      "Epoch 118: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 0.9692 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9892 - val_accuracy: 0.6369 - val_categorical_accuracy: 0.6369 - lr: 8.6593e-05\n",
      "Epoch 119/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6464 - categorical_accuracy: 0.6464\n",
      "Epoch 119: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 0.9691 - accuracy: 0.6465 - categorical_accuracy: 0.6465 - val_loss: 0.9873 - val_accuracy: 0.6383 - val_categorical_accuracy: 0.6383 - lr: 8.6593e-05\n",
      "Epoch 120/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9693 - accuracy: 0.6471 - categorical_accuracy: 0.6471\n",
      "Epoch 120: val_accuracy did not improve from 0.63842\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 0.9692 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9876 - val_accuracy: 0.6377 - val_categorical_accuracy: 0.6377 - lr: 8.6593e-05\n",
      "Epoch 121/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6474 - categorical_accuracy: 0.6474\n",
      "Epoch 121: val_accuracy improved from 0.63842 to 0.63863, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 919us/step - loss: 0.9691 - accuracy: 0.6475 - categorical_accuracy: 0.6475 - val_loss: 0.9865 - val_accuracy: 0.6386 - val_categorical_accuracy: 0.6386 - lr: 8.6593e-05\n",
      "Epoch 122/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6473 - categorical_accuracy: 0.6473\n",
      "Epoch 122: val_accuracy did not improve from 0.63863\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 0.9692 - accuracy: 0.6473 - categorical_accuracy: 0.6473 - val_loss: 0.9868 - val_accuracy: 0.6383 - val_categorical_accuracy: 0.6383 - lr: 8.6593e-05\n",
      "Epoch 123/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 0.9689 - accuracy: 0.6471 - categorical_accuracy: 0.6471\n",
      "Epoch 123: val_accuracy improved from 0.63863 to 0.63925, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_1.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9690 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9864 - val_accuracy: 0.6392 - val_categorical_accuracy: 0.6392 - lr: 8.6593e-05\n",
      "Epoch 124/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9690 - accuracy: 0.6471 - categorical_accuracy: 0.6471\n",
      "Epoch 124: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 0.9690 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9878 - val_accuracy: 0.6381 - val_categorical_accuracy: 0.6381 - lr: 8.6593e-05\n",
      "Epoch 125/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9690 - accuracy: 0.6469 - categorical_accuracy: 0.6469\n",
      "Epoch 125: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9689 - accuracy: 0.6470 - categorical_accuracy: 0.6470 - val_loss: 0.9864 - val_accuracy: 0.6389 - val_categorical_accuracy: 0.6389 - lr: 8.6593e-05\n",
      "Epoch 126/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9688 - accuracy: 0.6472 - categorical_accuracy: 0.6472\n",
      "Epoch 126: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 0.9688 - accuracy: 0.6472 - categorical_accuracy: 0.6472 - val_loss: 0.9868 - val_accuracy: 0.6379 - val_categorical_accuracy: 0.6379 - lr: 8.6593e-05\n",
      "Epoch 127/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 0.9692 - accuracy: 0.6468 - categorical_accuracy: 0.6468\n",
      "Epoch 127: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 0.9689 - accuracy: 0.6469 - categorical_accuracy: 0.6469 - val_loss: 0.9878 - val_accuracy: 0.6373 - val_categorical_accuracy: 0.6373 - lr: 8.6593e-05\n",
      "Epoch 128/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9688 - accuracy: 0.6473 - categorical_accuracy: 0.6473\n",
      "Epoch 128: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 0.9689 - accuracy: 0.6472 - categorical_accuracy: 0.6472 - val_loss: 0.9881 - val_accuracy: 0.6377 - val_categorical_accuracy: 0.6377 - lr: 8.6593e-05\n",
      "Epoch 129/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 0.9686 - accuracy: 0.6470 - categorical_accuracy: 0.6470\n",
      "Epoch 129: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9686 - accuracy: 0.6470 - categorical_accuracy: 0.6470 - val_loss: 0.9894 - val_accuracy: 0.6364 - val_categorical_accuracy: 0.6364 - lr: 8.6593e-05\n",
      "Epoch 130/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9687 - accuracy: 0.6465 - categorical_accuracy: 0.6465\n",
      "Epoch 130: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 0.9687 - accuracy: 0.6465 - categorical_accuracy: 0.6465 - val_loss: 0.9869 - val_accuracy: 0.6382 - val_categorical_accuracy: 0.6382 - lr: 8.6593e-05\n",
      "Epoch 131/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9687 - accuracy: 0.6470 - categorical_accuracy: 0.6470\n",
      "Epoch 131: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 0.9686 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9881 - val_accuracy: 0.6379 - val_categorical_accuracy: 0.6379 - lr: 8.6593e-05\n",
      "Epoch 132/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 0.9683 - accuracy: 0.6470 - categorical_accuracy: 0.6470\n",
      "Epoch 132: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 0.9684 - accuracy: 0.6470 - categorical_accuracy: 0.6470 - val_loss: 0.9869 - val_accuracy: 0.6374 - val_categorical_accuracy: 0.6374 - lr: 8.6593e-05\n",
      "Epoch 133/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9684 - accuracy: 0.6476 - categorical_accuracy: 0.6476\n",
      "Epoch 133: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 0.9684 - accuracy: 0.6476 - categorical_accuracy: 0.6476 - val_loss: 0.9868 - val_accuracy: 0.6375 - val_categorical_accuracy: 0.6375 - lr: 8.6593e-05\n",
      "Epoch 134/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9683 - accuracy: 0.6469 - categorical_accuracy: 0.6469\n",
      "Epoch 134: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 918us/step - loss: 0.9684 - accuracy: 0.6469 - categorical_accuracy: 0.6469 - val_loss: 0.9871 - val_accuracy: 0.6382 - val_categorical_accuracy: 0.6382 - lr: 8.6593e-05\n",
      "Epoch 135/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 0.9684 - accuracy: 0.6472 - categorical_accuracy: 0.6472\n",
      "Epoch 135: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9683 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9875 - val_accuracy: 0.6387 - val_categorical_accuracy: 0.6387 - lr: 8.6593e-05\n",
      "Epoch 136/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 0.9683 - accuracy: 0.6477 - categorical_accuracy: 0.6477\n",
      "Epoch 136: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 0.9683 - accuracy: 0.6477 - categorical_accuracy: 0.6477 - val_loss: 0.9870 - val_accuracy: 0.6384 - val_categorical_accuracy: 0.6384 - lr: 8.6593e-05\n",
      "Epoch 137/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9682 - accuracy: 0.6472 - categorical_accuracy: 0.6472\n",
      "Epoch 137: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 925us/step - loss: 0.9681 - accuracy: 0.6472 - categorical_accuracy: 0.6472 - val_loss: 0.9872 - val_accuracy: 0.6387 - val_categorical_accuracy: 0.6387 - lr: 8.6593e-05\n",
      "Epoch 138/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 0.9684 - accuracy: 0.6469 - categorical_accuracy: 0.6469\n",
      "Epoch 138: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 928us/step - loss: 0.9684 - accuracy: 0.6470 - categorical_accuracy: 0.6470 - val_loss: 0.9863 - val_accuracy: 0.6383 - val_categorical_accuracy: 0.6383 - lr: 8.6593e-05\n",
      "Epoch 139/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.6477 - categorical_accuracy: 0.6477\n",
      "Epoch 139: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 0.9680 - accuracy: 0.6476 - categorical_accuracy: 0.6476 - val_loss: 0.9862 - val_accuracy: 0.6386 - val_categorical_accuracy: 0.6386 - lr: 8.6593e-05\n",
      "Epoch 140/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.6472 - categorical_accuracy: 0.6472\n",
      "Epoch 140: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 0.9680 - accuracy: 0.6472 - categorical_accuracy: 0.6472 - val_loss: 0.9870 - val_accuracy: 0.6378 - val_categorical_accuracy: 0.6378 - lr: 8.6593e-05\n",
      "Epoch 141/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 0.9681 - accuracy: 0.6472 - categorical_accuracy: 0.6472\n",
      "Epoch 141: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 0.9682 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 0.9867 - val_accuracy: 0.6390 - val_categorical_accuracy: 0.6390 - lr: 8.6593e-05\n",
      "Epoch 142/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 0.9679 - accuracy: 0.6473 - categorical_accuracy: 0.6473\n",
      "Epoch 142: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 0.9678 - accuracy: 0.6474 - categorical_accuracy: 0.6474 - val_loss: 0.9872 - val_accuracy: 0.6369 - val_categorical_accuracy: 0.6369 - lr: 8.6593e-05\n",
      "Epoch 143/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.6474 - categorical_accuracy: 0.6474\n",
      "Epoch 143: val_accuracy did not improve from 0.63925\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 0.9679 - accuracy: 0.6475 - categorical_accuracy: 0.6475 - val_loss: 0.9859 - val_accuracy: 0.6384 - val_categorical_accuracy: 0.6384 - lr: 8.6593e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kfold num: 2\n",
      "\n",
      "----------------\n",
      "Data loading complete:\n",
      "File name: None\n",
      "Training data size: 480,840\n",
      "Test data size: 120,210\n",
      "Number of constituents: 32\n",
      "Number of features: 3\n",
      "----------------\n",
      "\n",
      "(480840, 32, 3)\n",
      "(480840, 96) (120210, 96) (480840, 5) (120210, 5)\n",
      "number of G jets for training/validation: 96168/24042\n",
      "number of Q jets for training/validation: 96168/24042\n",
      "number of W jets for training/validation: 96168/24042\n",
      "number of Z jets for training/validation: 96168/24042\n",
      "number of T jets for training/validation: 96168/24042\n",
      "number of G jets for testing: 24042\n",
      "number of Q jets for testing: 24042\n",
      "number of W jets for testing: 24042\n",
      "number of Z jets for testing: 24042\n",
      "number of T jets for testing: 24042\n",
      "Epoch 1/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 1.7127 - accuracy: 0.3622 - categorical_accuracy: 0.3622\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41704, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 8s 946us/step - loss: 1.7124 - accuracy: 0.3624 - categorical_accuracy: 0.3624 - val_loss: 1.5932 - val_accuracy: 0.4170 - val_categorical_accuracy: 0.4170 - lr: 8.6593e-05\n",
      "Epoch 2/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 1.5322 - accuracy: 0.4429 - categorical_accuracy: 0.4429\n",
      "Epoch 2: val_accuracy improved from 0.41704 to 0.46004, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.5320 - accuracy: 0.4430 - categorical_accuracy: 0.4430 - val_loss: 1.4882 - val_accuracy: 0.4600 - val_categorical_accuracy: 0.4600 - lr: 8.6593e-05\n",
      "Epoch 3/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 1.4540 - accuracy: 0.4715 - categorical_accuracy: 0.4715\n",
      "Epoch 3: val_accuracy improved from 0.46004 to 0.47816, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 930us/step - loss: 1.4539 - accuracy: 0.4715 - categorical_accuracy: 0.4715 - val_loss: 1.4339 - val_accuracy: 0.4782 - val_categorical_accuracy: 0.4782 - lr: 8.6593e-05\n",
      "Epoch 4/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.4051 - accuracy: 0.4868 - categorical_accuracy: 0.4868\n",
      "Epoch 4: val_accuracy improved from 0.47816 to 0.48892, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 1.4049 - accuracy: 0.4868 - categorical_accuracy: 0.4868 - val_loss: 1.3933 - val_accuracy: 0.4889 - val_categorical_accuracy: 0.4889 - lr: 8.6593e-05\n",
      "Epoch 5/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.3670 - accuracy: 0.4994 - categorical_accuracy: 0.4994\n",
      "Epoch 5: val_accuracy improved from 0.48892 to 0.49877, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.3668 - accuracy: 0.4995 - categorical_accuracy: 0.4995 - val_loss: 1.3591 - val_accuracy: 0.4988 - val_categorical_accuracy: 0.4988 - lr: 8.6593e-05\n",
      "Epoch 6/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 1.3351 - accuracy: 0.5098 - categorical_accuracy: 0.5098\n",
      "Epoch 6: val_accuracy improved from 0.49877 to 0.50876, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.3349 - accuracy: 0.5099 - categorical_accuracy: 0.5099 - val_loss: 1.3278 - val_accuracy: 0.5088 - val_categorical_accuracy: 0.5088 - lr: 8.6593e-05\n",
      "Epoch 7/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 1.3051 - accuracy: 0.5189 - categorical_accuracy: 0.5189\n",
      "Epoch 7: val_accuracy improved from 0.50876 to 0.51853, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.3051 - accuracy: 0.5189 - categorical_accuracy: 0.5189 - val_loss: 1.2979 - val_accuracy: 0.5185 - val_categorical_accuracy: 0.5185 - lr: 8.6593e-05\n",
      "Epoch 8/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 1.2750 - accuracy: 0.5293 - categorical_accuracy: 0.5293\n",
      "Epoch 8: val_accuracy improved from 0.51853 to 0.52984, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 895us/step - loss: 1.2750 - accuracy: 0.5293 - categorical_accuracy: 0.5293 - val_loss: 1.2691 - val_accuracy: 0.5298 - val_categorical_accuracy: 0.5298 - lr: 8.6593e-05\n",
      "Epoch 9/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 1.2475 - accuracy: 0.5399 - categorical_accuracy: 0.5399\n",
      "Epoch 9: val_accuracy improved from 0.52984 to 0.53910, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 886us/step - loss: 1.2475 - accuracy: 0.5399 - categorical_accuracy: 0.5399 - val_loss: 1.2438 - val_accuracy: 0.5391 - val_categorical_accuracy: 0.5391 - lr: 8.6593e-05\n",
      "Epoch 10/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.2265 - accuracy: 0.5467 - categorical_accuracy: 0.5467\n",
      "Epoch 10: val_accuracy improved from 0.53910 to 0.54475, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 897us/step - loss: 1.2263 - accuracy: 0.5468 - categorical_accuracy: 0.5468 - val_loss: 1.2264 - val_accuracy: 0.5447 - val_categorical_accuracy: 0.5447 - lr: 8.6593e-05\n",
      "Epoch 11/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 1.2102 - accuracy: 0.5524 - categorical_accuracy: 0.5524\n",
      "Epoch 11: val_accuracy improved from 0.54475 to 0.54980, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 895us/step - loss: 1.2102 - accuracy: 0.5524 - categorical_accuracy: 0.5524 - val_loss: 1.2117 - val_accuracy: 0.5498 - val_categorical_accuracy: 0.5498 - lr: 8.6593e-05\n",
      "Epoch 12/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 1.1968 - accuracy: 0.5561 - categorical_accuracy: 0.5561\n",
      "Epoch 12: val_accuracy improved from 0.54980 to 0.55205, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 1.1968 - accuracy: 0.5561 - categorical_accuracy: 0.5561 - val_loss: 1.2011 - val_accuracy: 0.5521 - val_categorical_accuracy: 0.5521 - lr: 8.6593e-05\n",
      "Epoch 13/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.1845 - accuracy: 0.5602 - categorical_accuracy: 0.5602\n",
      "Epoch 13: val_accuracy improved from 0.55205 to 0.55757, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.1845 - accuracy: 0.5602 - categorical_accuracy: 0.5602 - val_loss: 1.1884 - val_accuracy: 0.5576 - val_categorical_accuracy: 0.5576 - lr: 8.6593e-05\n",
      "Epoch 14/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 1.1729 - accuracy: 0.5637 - categorical_accuracy: 0.5637\n",
      "Epoch 14: val_accuracy improved from 0.55757 to 0.56069, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 1.1729 - accuracy: 0.5637 - categorical_accuracy: 0.5637 - val_loss: 1.1760 - val_accuracy: 0.5607 - val_categorical_accuracy: 0.5607 - lr: 8.6593e-05\n",
      "Epoch 15/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 1.1616 - accuracy: 0.5674 - categorical_accuracy: 0.5674\n",
      "Epoch 15: val_accuracy improved from 0.56069 to 0.56324, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.1615 - accuracy: 0.5674 - categorical_accuracy: 0.5674 - val_loss: 1.1660 - val_accuracy: 0.5632 - val_categorical_accuracy: 0.5632 - lr: 8.6593e-05\n",
      "Epoch 16/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 1.1506 - accuracy: 0.5721 - categorical_accuracy: 0.5721\n",
      "Epoch 16: val_accuracy improved from 0.56324 to 0.56959, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.1506 - accuracy: 0.5721 - categorical_accuracy: 0.5721 - val_loss: 1.1554 - val_accuracy: 0.5696 - val_categorical_accuracy: 0.5696 - lr: 8.6593e-05\n",
      "Epoch 17/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 1.1402 - accuracy: 0.5762 - categorical_accuracy: 0.5762\n",
      "Epoch 17: val_accuracy improved from 0.56959 to 0.57353, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.1401 - accuracy: 0.5763 - categorical_accuracy: 0.5763 - val_loss: 1.1439 - val_accuracy: 0.5735 - val_categorical_accuracy: 0.5735 - lr: 8.6593e-05\n",
      "Epoch 18/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 1.1301 - accuracy: 0.5801 - categorical_accuracy: 0.5801\n",
      "Epoch 18: val_accuracy improved from 0.57353 to 0.57743, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.1300 - accuracy: 0.5802 - categorical_accuracy: 0.5802 - val_loss: 1.1341 - val_accuracy: 0.5774 - val_categorical_accuracy: 0.5774 - lr: 8.6593e-05\n",
      "Epoch 19/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.1206 - accuracy: 0.5843 - categorical_accuracy: 0.5843\n",
      "Epoch 19: val_accuracy improved from 0.57743 to 0.58198, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.1207 - accuracy: 0.5843 - categorical_accuracy: 0.5843 - val_loss: 1.1242 - val_accuracy: 0.5820 - val_categorical_accuracy: 0.5820 - lr: 8.6593e-05\n",
      "Epoch 20/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 1.1120 - accuracy: 0.5876 - categorical_accuracy: 0.5876\n",
      "Epoch 20: val_accuracy improved from 0.58198 to 0.58458, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.1121 - accuracy: 0.5876 - categorical_accuracy: 0.5876 - val_loss: 1.1169 - val_accuracy: 0.5846 - val_categorical_accuracy: 0.5846 - lr: 8.6593e-05\n",
      "Epoch 21/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.1045 - accuracy: 0.5906 - categorical_accuracy: 0.5906\n",
      "Epoch 21: val_accuracy improved from 0.58458 to 0.58797, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 1.1045 - accuracy: 0.5906 - categorical_accuracy: 0.5906 - val_loss: 1.1091 - val_accuracy: 0.5880 - val_categorical_accuracy: 0.5880 - lr: 8.6593e-05\n",
      "Epoch 22/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 1.0978 - accuracy: 0.5934 - categorical_accuracy: 0.5934\n",
      "Epoch 22: val_accuracy did not improve from 0.58797\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 1.0978 - accuracy: 0.5934 - categorical_accuracy: 0.5934 - val_loss: 1.1095 - val_accuracy: 0.5842 - val_categorical_accuracy: 0.5842 - lr: 8.6593e-05\n",
      "Epoch 23/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0912 - accuracy: 0.5965 - categorical_accuracy: 0.5965\n",
      "Epoch 23: val_accuracy improved from 0.58797 to 0.59156, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0911 - accuracy: 0.5965 - categorical_accuracy: 0.5965 - val_loss: 1.0979 - val_accuracy: 0.5916 - val_categorical_accuracy: 0.5916 - lr: 8.6593e-05\n",
      "Epoch 24/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0853 - accuracy: 0.5987 - categorical_accuracy: 0.5987\n",
      "Epoch 24: val_accuracy improved from 0.59156 to 0.59496, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0854 - accuracy: 0.5987 - categorical_accuracy: 0.5987 - val_loss: 1.0921 - val_accuracy: 0.5950 - val_categorical_accuracy: 0.5950 - lr: 8.6593e-05\n",
      "Epoch 25/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 1.0807 - accuracy: 0.6005 - categorical_accuracy: 0.6005\n",
      "Epoch 25: val_accuracy improved from 0.59496 to 0.59732, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 1.0807 - accuracy: 0.6005 - categorical_accuracy: 0.6005 - val_loss: 1.0860 - val_accuracy: 0.5973 - val_categorical_accuracy: 0.5973 - lr: 8.6593e-05\n",
      "Epoch 26/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 1.0759 - accuracy: 0.6031 - categorical_accuracy: 0.6031\n",
      "Epoch 26: val_accuracy improved from 0.59732 to 0.59824, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0759 - accuracy: 0.6030 - categorical_accuracy: 0.6030 - val_loss: 1.0816 - val_accuracy: 0.5982 - val_categorical_accuracy: 0.5982 - lr: 8.6593e-05\n",
      "Epoch 27/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 1.0718 - accuracy: 0.6050 - categorical_accuracy: 0.6050\n",
      "Epoch 27: val_accuracy improved from 0.59824 to 0.59850, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0718 - accuracy: 0.6049 - categorical_accuracy: 0.6049 - val_loss: 1.0811 - val_accuracy: 0.5985 - val_categorical_accuracy: 0.5985 - lr: 8.6593e-05\n",
      "Epoch 28/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0679 - accuracy: 0.6062 - categorical_accuracy: 0.6062\n",
      "Epoch 28: val_accuracy improved from 0.59850 to 0.60072, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 1.0680 - accuracy: 0.6061 - categorical_accuracy: 0.6061 - val_loss: 1.0744 - val_accuracy: 0.6007 - val_categorical_accuracy: 0.6007 - lr: 8.6593e-05\n",
      "Epoch 29/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 1.0646 - accuracy: 0.6080 - categorical_accuracy: 0.6080\n",
      "Epoch 29: val_accuracy improved from 0.60072 to 0.60224, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0646 - accuracy: 0.6080 - categorical_accuracy: 0.6080 - val_loss: 1.0725 - val_accuracy: 0.6022 - val_categorical_accuracy: 0.6022 - lr: 8.6593e-05\n",
      "Epoch 30/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 1.0611 - accuracy: 0.6095 - categorical_accuracy: 0.6095\n",
      "Epoch 30: val_accuracy improved from 0.60224 to 0.60402, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0612 - accuracy: 0.6095 - categorical_accuracy: 0.6095 - val_loss: 1.0697 - val_accuracy: 0.6040 - val_categorical_accuracy: 0.6040 - lr: 8.6593e-05\n",
      "Epoch 31/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 1.0585 - accuracy: 0.6103 - categorical_accuracy: 0.6103\n",
      "Epoch 31: val_accuracy did not improve from 0.60402\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 1.0584 - accuracy: 0.6103 - categorical_accuracy: 0.6103 - val_loss: 1.0674 - val_accuracy: 0.6037 - val_categorical_accuracy: 0.6037 - lr: 8.6593e-05\n",
      "Epoch 32/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 1.0558 - accuracy: 0.6123 - categorical_accuracy: 0.6123\n",
      "Epoch 32: val_accuracy improved from 0.60402 to 0.60650, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0558 - accuracy: 0.6123 - categorical_accuracy: 0.6123 - val_loss: 1.0632 - val_accuracy: 0.6065 - val_categorical_accuracy: 0.6065 - lr: 8.6593e-05\n",
      "Epoch 33/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 1.0532 - accuracy: 0.6133 - categorical_accuracy: 0.6133\n",
      "Epoch 33: val_accuracy did not improve from 0.60650\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0532 - accuracy: 0.6133 - categorical_accuracy: 0.6133 - val_loss: 1.0639 - val_accuracy: 0.6055 - val_categorical_accuracy: 0.6055 - lr: 8.6593e-05\n",
      "Epoch 34/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 1.0508 - accuracy: 0.6146 - categorical_accuracy: 0.6146\n",
      "Epoch 34: val_accuracy improved from 0.60650 to 0.60855, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 1.0507 - accuracy: 0.6145 - categorical_accuracy: 0.6145 - val_loss: 1.0602 - val_accuracy: 0.6086 - val_categorical_accuracy: 0.6086 - lr: 8.6593e-05\n",
      "Epoch 35/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0484 - accuracy: 0.6157 - categorical_accuracy: 0.6157\n",
      "Epoch 35: val_accuracy improved from 0.60855 to 0.60862, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.0484 - accuracy: 0.6157 - categorical_accuracy: 0.6157 - val_loss: 1.0584 - val_accuracy: 0.6086 - val_categorical_accuracy: 0.6086 - lr: 8.6593e-05\n",
      "Epoch 36/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 1.0461 - accuracy: 0.6166 - categorical_accuracy: 0.6166\n",
      "Epoch 36: val_accuracy improved from 0.60862 to 0.61039, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 1.0462 - accuracy: 0.6165 - categorical_accuracy: 0.6165 - val_loss: 1.0567 - val_accuracy: 0.6104 - val_categorical_accuracy: 0.6104 - lr: 8.6593e-05\n",
      "Epoch 37/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 1.0440 - accuracy: 0.6173 - categorical_accuracy: 0.6173\n",
      "Epoch 37: val_accuracy improved from 0.61039 to 0.61178, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 1.0440 - accuracy: 0.6173 - categorical_accuracy: 0.6173 - val_loss: 1.0543 - val_accuracy: 0.6118 - val_categorical_accuracy: 0.6118 - lr: 8.6593e-05\n",
      "Epoch 38/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.0419 - accuracy: 0.6191 - categorical_accuracy: 0.6191\n",
      "Epoch 38: val_accuracy did not improve from 0.61178\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0420 - accuracy: 0.6190 - categorical_accuracy: 0.6190 - val_loss: 1.0550 - val_accuracy: 0.6109 - val_categorical_accuracy: 0.6109 - lr: 8.6593e-05\n",
      "Epoch 39/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0399 - accuracy: 0.6196 - categorical_accuracy: 0.6196\n",
      "Epoch 39: val_accuracy improved from 0.61178 to 0.61314, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.0399 - accuracy: 0.6195 - categorical_accuracy: 0.6195 - val_loss: 1.0502 - val_accuracy: 0.6131 - val_categorical_accuracy: 0.6131 - lr: 8.6593e-05\n",
      "Epoch 40/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0382 - accuracy: 0.6208 - categorical_accuracy: 0.6208\n",
      "Epoch 40: val_accuracy improved from 0.61314 to 0.61368, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 1.0381 - accuracy: 0.6208 - categorical_accuracy: 0.6208 - val_loss: 1.0494 - val_accuracy: 0.6137 - val_categorical_accuracy: 0.6137 - lr: 8.6593e-05\n",
      "Epoch 41/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0364 - accuracy: 0.6218 - categorical_accuracy: 0.6218\n",
      "Epoch 41: val_accuracy improved from 0.61368 to 0.61423, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0364 - accuracy: 0.6218 - categorical_accuracy: 0.6218 - val_loss: 1.0474 - val_accuracy: 0.6142 - val_categorical_accuracy: 0.6142 - lr: 8.6593e-05\n",
      "Epoch 42/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 1.0345 - accuracy: 0.6229 - categorical_accuracy: 0.6229\n",
      "Epoch 42: val_accuracy improved from 0.61423 to 0.61548, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 1.0344 - accuracy: 0.6230 - categorical_accuracy: 0.6230 - val_loss: 1.0462 - val_accuracy: 0.6155 - val_categorical_accuracy: 0.6155 - lr: 8.6593e-05\n",
      "Epoch 43/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 1.0328 - accuracy: 0.6238 - categorical_accuracy: 0.6238\n",
      "Epoch 43: val_accuracy improved from 0.61548 to 0.61824, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0328 - accuracy: 0.6238 - categorical_accuracy: 0.6238 - val_loss: 1.0433 - val_accuracy: 0.6182 - val_categorical_accuracy: 0.6182 - lr: 8.6593e-05\n",
      "Epoch 44/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0311 - accuracy: 0.6244 - categorical_accuracy: 0.6244\n",
      "Epoch 44: val_accuracy did not improve from 0.61824\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 1.0310 - accuracy: 0.6244 - categorical_accuracy: 0.6244 - val_loss: 1.0433 - val_accuracy: 0.6167 - val_categorical_accuracy: 0.6167 - lr: 8.6593e-05\n",
      "Epoch 45/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0295 - accuracy: 0.6254 - categorical_accuracy: 0.6254\n",
      "Epoch 45: val_accuracy did not improve from 0.61824\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0294 - accuracy: 0.6254 - categorical_accuracy: 0.6254 - val_loss: 1.0410 - val_accuracy: 0.6179 - val_categorical_accuracy: 0.6179 - lr: 8.6593e-05\n",
      "Epoch 46/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0278 - accuracy: 0.6263 - categorical_accuracy: 0.6263\n",
      "Epoch 46: val_accuracy did not improve from 0.61824\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 1.0279 - accuracy: 0.6263 - categorical_accuracy: 0.6263 - val_loss: 1.0422 - val_accuracy: 0.6177 - val_categorical_accuracy: 0.6177 - lr: 8.6593e-05\n",
      "Epoch 47/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0267 - accuracy: 0.6265 - categorical_accuracy: 0.6265\n",
      "Epoch 47: val_accuracy improved from 0.61824 to 0.61919, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 1.0267 - accuracy: 0.6265 - categorical_accuracy: 0.6265 - val_loss: 1.0387 - val_accuracy: 0.6192 - val_categorical_accuracy: 0.6192 - lr: 8.6593e-05\n",
      "Epoch 48/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 1.0252 - accuracy: 0.6273 - categorical_accuracy: 0.6273\n",
      "Epoch 48: val_accuracy improved from 0.61919 to 0.61975, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.0252 - accuracy: 0.6274 - categorical_accuracy: 0.6274 - val_loss: 1.0367 - val_accuracy: 0.6197 - val_categorical_accuracy: 0.6197 - lr: 8.6593e-05\n",
      "Epoch 49/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 1.0239 - accuracy: 0.6282 - categorical_accuracy: 0.6282\n",
      "Epoch 49: val_accuracy did not improve from 0.61975\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 1.0239 - accuracy: 0.6282 - categorical_accuracy: 0.6282 - val_loss: 1.0368 - val_accuracy: 0.6197 - val_categorical_accuracy: 0.6197 - lr: 8.6593e-05\n",
      "Epoch 50/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 1.0226 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 50: val_accuracy improved from 0.61975 to 0.62105, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0227 - accuracy: 0.6294 - categorical_accuracy: 0.6294 - val_loss: 1.0356 - val_accuracy: 0.6210 - val_categorical_accuracy: 0.6210 - lr: 8.6593e-05\n",
      "Epoch 51/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 1.0212 - accuracy: 0.6302 - categorical_accuracy: 0.6302\n",
      "Epoch 51: val_accuracy improved from 0.62105 to 0.62199, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0212 - accuracy: 0.6302 - categorical_accuracy: 0.6302 - val_loss: 1.0339 - val_accuracy: 0.6220 - val_categorical_accuracy: 0.6220 - lr: 8.6593e-05\n",
      "Epoch 52/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0204 - accuracy: 0.6300 - categorical_accuracy: 0.6300\n",
      "Epoch 52: val_accuracy did not improve from 0.62199\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 1.0204 - accuracy: 0.6299 - categorical_accuracy: 0.6299 - val_loss: 1.0352 - val_accuracy: 0.6213 - val_categorical_accuracy: 0.6213 - lr: 8.6593e-05\n",
      "Epoch 53/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 1.0189 - accuracy: 0.6308 - categorical_accuracy: 0.6308\n",
      "Epoch 53: val_accuracy improved from 0.62199 to 0.62260, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0188 - accuracy: 0.6308 - categorical_accuracy: 0.6308 - val_loss: 1.0322 - val_accuracy: 0.6226 - val_categorical_accuracy: 0.6226 - lr: 8.6593e-05\n",
      "Epoch 54/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.0180 - accuracy: 0.6305 - categorical_accuracy: 0.6305\n",
      "Epoch 54: val_accuracy improved from 0.62260 to 0.62352, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 1.0179 - accuracy: 0.6306 - categorical_accuracy: 0.6306 - val_loss: 1.0304 - val_accuracy: 0.6235 - val_categorical_accuracy: 0.6235 - lr: 8.6593e-05\n",
      "Epoch 55/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 1.0167 - accuracy: 0.6317 - categorical_accuracy: 0.6317\n",
      "Epoch 55: val_accuracy did not improve from 0.62352\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 1.0168 - accuracy: 0.6317 - categorical_accuracy: 0.6317 - val_loss: 1.0334 - val_accuracy: 0.6228 - val_categorical_accuracy: 0.6228 - lr: 8.6593e-05\n",
      "Epoch 56/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 1.0155 - accuracy: 0.6328 - categorical_accuracy: 0.6328\n",
      "Epoch 56: val_accuracy did not improve from 0.62352\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 1.0156 - accuracy: 0.6327 - categorical_accuracy: 0.6327 - val_loss: 1.0347 - val_accuracy: 0.6223 - val_categorical_accuracy: 0.6223 - lr: 8.6593e-05\n",
      "Epoch 57/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 1.0146 - accuracy: 0.6325 - categorical_accuracy: 0.6325\n",
      "Epoch 57: val_accuracy improved from 0.62352 to 0.62519, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 1.0146 - accuracy: 0.6325 - categorical_accuracy: 0.6325 - val_loss: 1.0281 - val_accuracy: 0.6252 - val_categorical_accuracy: 0.6252 - lr: 8.6593e-05\n",
      "Epoch 58/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0135 - accuracy: 0.6335 - categorical_accuracy: 0.6335\n",
      "Epoch 58: val_accuracy improved from 0.62519 to 0.62714, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 1.0135 - accuracy: 0.6335 - categorical_accuracy: 0.6335 - val_loss: 1.0263 - val_accuracy: 0.6271 - val_categorical_accuracy: 0.6271 - lr: 8.6593e-05\n",
      "Epoch 59/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0127 - accuracy: 0.6340 - categorical_accuracy: 0.6340\n",
      "Epoch 59: val_accuracy did not improve from 0.62714\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0126 - accuracy: 0.6341 - categorical_accuracy: 0.6341 - val_loss: 1.0248 - val_accuracy: 0.6257 - val_categorical_accuracy: 0.6257 - lr: 8.6593e-05\n",
      "Epoch 60/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.0116 - accuracy: 0.6340 - categorical_accuracy: 0.6340\n",
      "Epoch 60: val_accuracy did not improve from 0.62714\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0115 - accuracy: 0.6340 - categorical_accuracy: 0.6340 - val_loss: 1.0243 - val_accuracy: 0.6271 - val_categorical_accuracy: 0.6271 - lr: 8.6593e-05\n",
      "Epoch 61/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 1.0102 - accuracy: 0.6355 - categorical_accuracy: 0.6355\n",
      "Epoch 61: val_accuracy improved from 0.62714 to 0.62721, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0101 - accuracy: 0.6355 - categorical_accuracy: 0.6355 - val_loss: 1.0233 - val_accuracy: 0.6272 - val_categorical_accuracy: 0.6272 - lr: 8.6593e-05\n",
      "Epoch 62/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 1.0091 - accuracy: 0.6354 - categorical_accuracy: 0.6354\n",
      "Epoch 62: val_accuracy improved from 0.62721 to 0.62778, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0091 - accuracy: 0.6354 - categorical_accuracy: 0.6354 - val_loss: 1.0231 - val_accuracy: 0.6278 - val_categorical_accuracy: 0.6278 - lr: 8.6593e-05\n",
      "Epoch 63/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 1.0083 - accuracy: 0.6366 - categorical_accuracy: 0.6366\n",
      "Epoch 63: val_accuracy improved from 0.62778 to 0.62943, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0083 - accuracy: 0.6366 - categorical_accuracy: 0.6366 - val_loss: 1.0201 - val_accuracy: 0.6294 - val_categorical_accuracy: 0.6294 - lr: 8.6593e-05\n",
      "Epoch 64/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 1.0073 - accuracy: 0.6365 - categorical_accuracy: 0.6365\n",
      "Epoch 64: val_accuracy did not improve from 0.62943\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 1.0073 - accuracy: 0.6365 - categorical_accuracy: 0.6365 - val_loss: 1.0209 - val_accuracy: 0.6285 - val_categorical_accuracy: 0.6285 - lr: 8.6593e-05\n",
      "Epoch 65/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0063 - accuracy: 0.6370 - categorical_accuracy: 0.6370\n",
      "Epoch 65: val_accuracy improved from 0.62943 to 0.63009, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 1.0063 - accuracy: 0.6370 - categorical_accuracy: 0.6370 - val_loss: 1.0180 - val_accuracy: 0.6301 - val_categorical_accuracy: 0.6301 - lr: 8.6593e-05\n",
      "Epoch 66/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0051 - accuracy: 0.6377 - categorical_accuracy: 0.6377\n",
      "Epoch 66: val_accuracy did not improve from 0.63009\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0051 - accuracy: 0.6376 - categorical_accuracy: 0.6376 - val_loss: 1.0188 - val_accuracy: 0.6297 - val_categorical_accuracy: 0.6297 - lr: 8.6593e-05\n",
      "Epoch 67/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.0038 - accuracy: 0.6377 - categorical_accuracy: 0.6377\n",
      "Epoch 67: val_accuracy improved from 0.63009 to 0.63046, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 1.0038 - accuracy: 0.6377 - categorical_accuracy: 0.6377 - val_loss: 1.0166 - val_accuracy: 0.6305 - val_categorical_accuracy: 0.6305 - lr: 8.6593e-05\n",
      "Epoch 68/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0031 - accuracy: 0.6380 - categorical_accuracy: 0.6380\n",
      "Epoch 68: val_accuracy improved from 0.63046 to 0.63181, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 1.0031 - accuracy: 0.6381 - categorical_accuracy: 0.6381 - val_loss: 1.0153 - val_accuracy: 0.6318 - val_categorical_accuracy: 0.6318 - lr: 8.6593e-05\n",
      "Epoch 69/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 1.0024 - accuracy: 0.6393 - categorical_accuracy: 0.6393\n",
      "Epoch 69: val_accuracy did not improve from 0.63181\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 1.0024 - accuracy: 0.6394 - categorical_accuracy: 0.6394 - val_loss: 1.0159 - val_accuracy: 0.6313 - val_categorical_accuracy: 0.6313 - lr: 8.6593e-05\n",
      "Epoch 70/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0017 - accuracy: 0.6390 - categorical_accuracy: 0.6390\n",
      "Epoch 70: val_accuracy improved from 0.63181 to 0.63293, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 951us/step - loss: 1.0017 - accuracy: 0.6390 - categorical_accuracy: 0.6390 - val_loss: 1.0157 - val_accuracy: 0.6329 - val_categorical_accuracy: 0.6329 - lr: 8.6593e-05\n",
      "Epoch 71/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 1.0005 - accuracy: 0.6397 - categorical_accuracy: 0.6397\n",
      "Epoch 71: val_accuracy did not improve from 0.63293\n",
      "7514/7514 [==============================] - 7s 953us/step - loss: 1.0003 - accuracy: 0.6397 - categorical_accuracy: 0.6397 - val_loss: 1.0135 - val_accuracy: 0.6324 - val_categorical_accuracy: 0.6324 - lr: 8.6593e-05\n",
      "Epoch 72/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9994 - accuracy: 0.6401 - categorical_accuracy: 0.6401\n",
      "Epoch 72: val_accuracy did not improve from 0.63293\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 0.9994 - accuracy: 0.6401 - categorical_accuracy: 0.6401 - val_loss: 1.0159 - val_accuracy: 0.6317 - val_categorical_accuracy: 0.6317 - lr: 8.6593e-05\n",
      "Epoch 73/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9986 - accuracy: 0.6408 - categorical_accuracy: 0.6408\n",
      "Epoch 73: val_accuracy did not improve from 0.63293\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 0.9986 - accuracy: 0.6407 - categorical_accuracy: 0.6407 - val_loss: 1.0125 - val_accuracy: 0.6324 - val_categorical_accuracy: 0.6324 - lr: 8.6593e-05\n",
      "Epoch 74/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 0.9981 - accuracy: 0.6409 - categorical_accuracy: 0.6409\n",
      "Epoch 74: val_accuracy did not improve from 0.63293\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9980 - accuracy: 0.6409 - categorical_accuracy: 0.6409 - val_loss: 1.0121 - val_accuracy: 0.6321 - val_categorical_accuracy: 0.6321 - lr: 8.6593e-05\n",
      "Epoch 75/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9975 - accuracy: 0.6408 - categorical_accuracy: 0.6408\n",
      "Epoch 75: val_accuracy improved from 0.63293 to 0.63436, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 958us/step - loss: 0.9974 - accuracy: 0.6408 - categorical_accuracy: 0.6408 - val_loss: 1.0104 - val_accuracy: 0.6344 - val_categorical_accuracy: 0.6344 - lr: 8.6593e-05\n",
      "Epoch 76/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9964 - accuracy: 0.6419 - categorical_accuracy: 0.6419\n",
      "Epoch 76: val_accuracy did not improve from 0.63436\n",
      "7514/7514 [==============================] - 7s 953us/step - loss: 0.9964 - accuracy: 0.6419 - categorical_accuracy: 0.6419 - val_loss: 1.0091 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342 - lr: 8.6593e-05\n",
      "Epoch 77/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9961 - accuracy: 0.6419 - categorical_accuracy: 0.6419\n",
      "Epoch 77: val_accuracy did not improve from 0.63436\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9960 - accuracy: 0.6420 - categorical_accuracy: 0.6420 - val_loss: 1.0101 - val_accuracy: 0.6335 - val_categorical_accuracy: 0.6335 - lr: 8.6593e-05\n",
      "Epoch 78/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9951 - accuracy: 0.6419 - categorical_accuracy: 0.6419\n",
      "Epoch 78: val_accuracy did not improve from 0.63436\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9950 - accuracy: 0.6420 - categorical_accuracy: 0.6420 - val_loss: 1.0093 - val_accuracy: 0.6341 - val_categorical_accuracy: 0.6341 - lr: 8.6593e-05\n",
      "Epoch 79/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 0.9945 - accuracy: 0.6419 - categorical_accuracy: 0.6419\n",
      "Epoch 79: val_accuracy did not improve from 0.63436\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 0.9946 - accuracy: 0.6419 - categorical_accuracy: 0.6419 - val_loss: 1.0130 - val_accuracy: 0.6318 - val_categorical_accuracy: 0.6318 - lr: 8.6593e-05\n",
      "Epoch 80/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 0.9936 - accuracy: 0.6423 - categorical_accuracy: 0.6423\n",
      "Epoch 80: val_accuracy improved from 0.63436 to 0.63553, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9936 - accuracy: 0.6423 - categorical_accuracy: 0.6423 - val_loss: 1.0059 - val_accuracy: 0.6355 - val_categorical_accuracy: 0.6355 - lr: 8.6593e-05\n",
      "Epoch 81/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9931 - accuracy: 0.6433 - categorical_accuracy: 0.6433\n",
      "Epoch 81: val_accuracy did not improve from 0.63553\n",
      "7514/7514 [==============================] - 7s 953us/step - loss: 0.9931 - accuracy: 0.6433 - categorical_accuracy: 0.6433 - val_loss: 1.0074 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342 - lr: 8.6593e-05\n",
      "Epoch 82/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9924 - accuracy: 0.6432 - categorical_accuracy: 0.6432\n",
      "Epoch 82: val_accuracy did not improve from 0.63553\n",
      "7514/7514 [==============================] - 7s 958us/step - loss: 0.9923 - accuracy: 0.6433 - categorical_accuracy: 0.6433 - val_loss: 1.0084 - val_accuracy: 0.6328 - val_categorical_accuracy: 0.6328 - lr: 8.6593e-05\n",
      "Epoch 83/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 0.9916 - accuracy: 0.6438 - categorical_accuracy: 0.6438\n",
      "Epoch 83: val_accuracy did not improve from 0.63553\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9915 - accuracy: 0.6438 - categorical_accuracy: 0.6438 - val_loss: 1.0061 - val_accuracy: 0.6350 - val_categorical_accuracy: 0.6350 - lr: 8.6593e-05\n",
      "Epoch 84/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9905 - accuracy: 0.6442 - categorical_accuracy: 0.6442\n",
      "Epoch 84: val_accuracy improved from 0.63553 to 0.63563, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 0.9905 - accuracy: 0.6442 - categorical_accuracy: 0.6442 - val_loss: 1.0054 - val_accuracy: 0.6356 - val_categorical_accuracy: 0.6356 - lr: 8.6593e-05\n",
      "Epoch 85/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9899 - accuracy: 0.6446 - categorical_accuracy: 0.6446\n",
      "Epoch 85: val_accuracy improved from 0.63563 to 0.63723, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 943us/step - loss: 0.9899 - accuracy: 0.6446 - categorical_accuracy: 0.6446 - val_loss: 1.0024 - val_accuracy: 0.6372 - val_categorical_accuracy: 0.6372 - lr: 8.6593e-05\n",
      "Epoch 86/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 0.9891 - accuracy: 0.6446 - categorical_accuracy: 0.6446\n",
      "Epoch 86: val_accuracy did not improve from 0.63723\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9891 - accuracy: 0.6446 - categorical_accuracy: 0.6446 - val_loss: 1.0061 - val_accuracy: 0.6349 - val_categorical_accuracy: 0.6349 - lr: 8.6593e-05\n",
      "Epoch 87/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 0.9883 - accuracy: 0.6457 - categorical_accuracy: 0.6457\n",
      "Epoch 87: val_accuracy improved from 0.63723 to 0.63743, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 951us/step - loss: 0.9884 - accuracy: 0.6456 - categorical_accuracy: 0.6456 - val_loss: 1.0020 - val_accuracy: 0.6374 - val_categorical_accuracy: 0.6374 - lr: 8.6593e-05\n",
      "Epoch 88/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 0.9874 - accuracy: 0.6454 - categorical_accuracy: 0.6454\n",
      "Epoch 88: val_accuracy did not improve from 0.63743\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 0.9874 - accuracy: 0.6454 - categorical_accuracy: 0.6454 - val_loss: 1.0031 - val_accuracy: 0.6362 - val_categorical_accuracy: 0.6362 - lr: 8.6593e-05\n",
      "Epoch 89/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9867 - accuracy: 0.6458 - categorical_accuracy: 0.6458\n",
      "Epoch 89: val_accuracy improved from 0.63743 to 0.63897, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9867 - accuracy: 0.6458 - categorical_accuracy: 0.6458 - val_loss: 1.0004 - val_accuracy: 0.6390 - val_categorical_accuracy: 0.6390 - lr: 8.6593e-05\n",
      "Epoch 90/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 0.9863 - accuracy: 0.6463 - categorical_accuracy: 0.6463\n",
      "Epoch 90: val_accuracy did not improve from 0.63897\n",
      "7514/7514 [==============================] - 7s 951us/step - loss: 0.9863 - accuracy: 0.6462 - categorical_accuracy: 0.6462 - val_loss: 1.0009 - val_accuracy: 0.6384 - val_categorical_accuracy: 0.6384 - lr: 8.6593e-05\n",
      "Epoch 91/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9857 - accuracy: 0.6468 - categorical_accuracy: 0.6468\n",
      "Epoch 91: val_accuracy did not improve from 0.63897\n",
      "7514/7514 [==============================] - 7s 956us/step - loss: 0.9857 - accuracy: 0.6469 - categorical_accuracy: 0.6469 - val_loss: 0.9988 - val_accuracy: 0.6386 - val_categorical_accuracy: 0.6386 - lr: 8.6593e-05\n",
      "Epoch 92/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9851 - accuracy: 0.6464 - categorical_accuracy: 0.6464\n",
      "Epoch 92: val_accuracy did not improve from 0.63897\n",
      "7514/7514 [==============================] - 7s 981us/step - loss: 0.9851 - accuracy: 0.6464 - categorical_accuracy: 0.6464 - val_loss: 0.9987 - val_accuracy: 0.6388 - val_categorical_accuracy: 0.6388 - lr: 8.6593e-05\n",
      "Epoch 93/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 0.9842 - accuracy: 0.6474 - categorical_accuracy: 0.6474\n",
      "Epoch 93: val_accuracy improved from 0.63897 to 0.63966, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 957us/step - loss: 0.9841 - accuracy: 0.6474 - categorical_accuracy: 0.6474 - val_loss: 0.9989 - val_accuracy: 0.6397 - val_categorical_accuracy: 0.6397 - lr: 8.6593e-05\n",
      "Epoch 94/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 0.9836 - accuracy: 0.6473 - categorical_accuracy: 0.6473\n",
      "Epoch 94: val_accuracy improved from 0.63966 to 0.64127, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 0.9836 - accuracy: 0.6473 - categorical_accuracy: 0.6473 - val_loss: 0.9959 - val_accuracy: 0.6413 - val_categorical_accuracy: 0.6413 - lr: 8.6593e-05\n",
      "Epoch 95/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 0.9829 - accuracy: 0.6476 - categorical_accuracy: 0.6476\n",
      "Epoch 95: val_accuracy did not improve from 0.64127\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 0.9829 - accuracy: 0.6476 - categorical_accuracy: 0.6476 - val_loss: 0.9963 - val_accuracy: 0.6395 - val_categorical_accuracy: 0.6395 - lr: 8.6593e-05\n",
      "Epoch 96/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 0.9822 - accuracy: 0.6484 - categorical_accuracy: 0.6484\n",
      "Epoch 96: val_accuracy did not improve from 0.64127\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 0.9822 - accuracy: 0.6484 - categorical_accuracy: 0.6484 - val_loss: 0.9962 - val_accuracy: 0.6402 - val_categorical_accuracy: 0.6402 - lr: 8.6593e-05\n",
      "Epoch 97/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.6487 - categorical_accuracy: 0.6487\n",
      "Epoch 97: val_accuracy did not improve from 0.64127\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 0.9817 - accuracy: 0.6486 - categorical_accuracy: 0.6486 - val_loss: 0.9960 - val_accuracy: 0.6397 - val_categorical_accuracy: 0.6397 - lr: 8.6593e-05\n",
      "Epoch 98/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9814 - accuracy: 0.6486 - categorical_accuracy: 0.6486\n",
      "Epoch 98: val_accuracy did not improve from 0.64127\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9812 - accuracy: 0.6487 - categorical_accuracy: 0.6487 - val_loss: 0.9964 - val_accuracy: 0.6409 - val_categorical_accuracy: 0.6409 - lr: 8.6593e-05\n",
      "Epoch 99/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 0.9806 - accuracy: 0.6491 - categorical_accuracy: 0.6491\n",
      "Epoch 99: val_accuracy improved from 0.64127 to 0.64128, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 0.9806 - accuracy: 0.6491 - categorical_accuracy: 0.6491 - val_loss: 0.9937 - val_accuracy: 0.6413 - val_categorical_accuracy: 0.6413 - lr: 8.6593e-05\n",
      "Epoch 100/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9798 - accuracy: 0.6493 - categorical_accuracy: 0.6493\n",
      "Epoch 100: val_accuracy improved from 0.64128 to 0.64252, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9798 - accuracy: 0.6493 - categorical_accuracy: 0.6493 - val_loss: 0.9937 - val_accuracy: 0.6425 - val_categorical_accuracy: 0.6425 - lr: 8.6593e-05\n",
      "Epoch 101/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 0.9791 - accuracy: 0.6495 - categorical_accuracy: 0.6495\n",
      "Epoch 101: val_accuracy did not improve from 0.64252\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9792 - accuracy: 0.6494 - categorical_accuracy: 0.6494 - val_loss: 0.9932 - val_accuracy: 0.6417 - val_categorical_accuracy: 0.6417 - lr: 8.6593e-05\n",
      "Epoch 102/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 0.9786 - accuracy: 0.6498 - categorical_accuracy: 0.6498\n",
      "Epoch 102: val_accuracy did not improve from 0.64252\n",
      "7514/7514 [==============================] - 7s 953us/step - loss: 0.9786 - accuracy: 0.6499 - categorical_accuracy: 0.6499 - val_loss: 0.9940 - val_accuracy: 0.6409 - val_categorical_accuracy: 0.6409 - lr: 8.6593e-05\n",
      "Epoch 103/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9785 - accuracy: 0.6499 - categorical_accuracy: 0.6499\n",
      "Epoch 103: val_accuracy did not improve from 0.64252\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 0.9785 - accuracy: 0.6499 - categorical_accuracy: 0.6499 - val_loss: 0.9938 - val_accuracy: 0.6403 - val_categorical_accuracy: 0.6403 - lr: 8.6593e-05\n",
      "Epoch 104/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9777 - accuracy: 0.6504 - categorical_accuracy: 0.6504\n",
      "Epoch 104: val_accuracy improved from 0.64252 to 0.64273, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 0.9778 - accuracy: 0.6503 - categorical_accuracy: 0.6503 - val_loss: 0.9911 - val_accuracy: 0.6427 - val_categorical_accuracy: 0.6427 - lr: 8.6593e-05\n",
      "Epoch 105/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9771 - accuracy: 0.6508 - categorical_accuracy: 0.6508\n",
      "Epoch 105: val_accuracy did not improve from 0.64273\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 0.9771 - accuracy: 0.6508 - categorical_accuracy: 0.6508 - val_loss: 0.9918 - val_accuracy: 0.6412 - val_categorical_accuracy: 0.6412 - lr: 8.6593e-05\n",
      "Epoch 106/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9766 - accuracy: 0.6508 - categorical_accuracy: 0.6508\n",
      "Epoch 106: val_accuracy did not improve from 0.64273\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 0.9766 - accuracy: 0.6508 - categorical_accuracy: 0.6508 - val_loss: 0.9915 - val_accuracy: 0.6425 - val_categorical_accuracy: 0.6425 - lr: 8.6593e-05\n",
      "Epoch 107/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9769 - accuracy: 0.6506 - categorical_accuracy: 0.6506\n",
      "Epoch 107: val_accuracy improved from 0.64273 to 0.64282, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 0.9769 - accuracy: 0.6506 - categorical_accuracy: 0.6506 - val_loss: 0.9913 - val_accuracy: 0.6428 - val_categorical_accuracy: 0.6428 - lr: 8.6593e-05\n",
      "Epoch 108/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 0.9764 - accuracy: 0.6507 - categorical_accuracy: 0.6507\n",
      "Epoch 108: val_accuracy did not improve from 0.64282\n",
      "7514/7514 [==============================] - 7s 956us/step - loss: 0.9764 - accuracy: 0.6507 - categorical_accuracy: 0.6507 - val_loss: 0.9907 - val_accuracy: 0.6422 - val_categorical_accuracy: 0.6422 - lr: 8.6593e-05\n",
      "Epoch 109/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9758 - accuracy: 0.6515 - categorical_accuracy: 0.6515\n",
      "Epoch 109: val_accuracy improved from 0.64282 to 0.64301, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 961us/step - loss: 0.9758 - accuracy: 0.6515 - categorical_accuracy: 0.6515 - val_loss: 0.9891 - val_accuracy: 0.6430 - val_categorical_accuracy: 0.6430 - lr: 8.6593e-05\n",
      "Epoch 110/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 0.9756 - accuracy: 0.6511 - categorical_accuracy: 0.6511\n",
      "Epoch 110: val_accuracy improved from 0.64301 to 0.64363, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 961us/step - loss: 0.9756 - accuracy: 0.6511 - categorical_accuracy: 0.6511 - val_loss: 0.9901 - val_accuracy: 0.6436 - val_categorical_accuracy: 0.6436 - lr: 8.6593e-05\n",
      "Epoch 111/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 0.9756 - accuracy: 0.6511 - categorical_accuracy: 0.6511\n",
      "Epoch 111: val_accuracy did not improve from 0.64363\n",
      "7514/7514 [==============================] - 7s 956us/step - loss: 0.9755 - accuracy: 0.6512 - categorical_accuracy: 0.6512 - val_loss: 0.9903 - val_accuracy: 0.6424 - val_categorical_accuracy: 0.6424 - lr: 8.6593e-05\n",
      "Epoch 112/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9753 - accuracy: 0.6516 - categorical_accuracy: 0.6516\n",
      "Epoch 112: val_accuracy did not improve from 0.64363\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9752 - accuracy: 0.6516 - categorical_accuracy: 0.6516 - val_loss: 0.9895 - val_accuracy: 0.6426 - val_categorical_accuracy: 0.6426 - lr: 8.6593e-05\n",
      "Epoch 113/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 0.9748 - accuracy: 0.6519 - categorical_accuracy: 0.6519\n",
      "Epoch 113: val_accuracy did not improve from 0.64363\n",
      "7514/7514 [==============================] - 8s 1ms/step - loss: 0.9747 - accuracy: 0.6519 - categorical_accuracy: 0.6519 - val_loss: 0.9903 - val_accuracy: 0.6432 - val_categorical_accuracy: 0.6432 - lr: 8.6593e-05\n",
      "Epoch 114/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9739 - accuracy: 0.6520 - categorical_accuracy: 0.6520\n",
      "Epoch 114: val_accuracy did not improve from 0.64363\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 0.9741 - accuracy: 0.6519 - categorical_accuracy: 0.6519 - val_loss: 0.9896 - val_accuracy: 0.6420 - val_categorical_accuracy: 0.6420 - lr: 8.6593e-05\n",
      "Epoch 115/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9740 - accuracy: 0.6522 - categorical_accuracy: 0.6522\n",
      "Epoch 115: val_accuracy did not improve from 0.64363\n",
      "7514/7514 [==============================] - 7s 957us/step - loss: 0.9740 - accuracy: 0.6522 - categorical_accuracy: 0.6522 - val_loss: 0.9922 - val_accuracy: 0.6414 - val_categorical_accuracy: 0.6414 - lr: 8.6593e-05\n",
      "Epoch 116/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9737 - accuracy: 0.6522 - categorical_accuracy: 0.6522\n",
      "Epoch 116: val_accuracy improved from 0.64363 to 0.64421, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 990us/step - loss: 0.9737 - accuracy: 0.6523 - categorical_accuracy: 0.6523 - val_loss: 0.9900 - val_accuracy: 0.6442 - val_categorical_accuracy: 0.6442 - lr: 8.6593e-05\n",
      "Epoch 117/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9731 - accuracy: 0.6526 - categorical_accuracy: 0.6526\n",
      "Epoch 117: val_accuracy did not improve from 0.64421\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9731 - accuracy: 0.6526 - categorical_accuracy: 0.6526 - val_loss: 0.9877 - val_accuracy: 0.6439 - val_categorical_accuracy: 0.6439 - lr: 8.6593e-05\n",
      "Epoch 118/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9733 - accuracy: 0.6527 - categorical_accuracy: 0.6527\n",
      "Epoch 118: val_accuracy did not improve from 0.64421\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 0.9733 - accuracy: 0.6527 - categorical_accuracy: 0.6527 - val_loss: 0.9885 - val_accuracy: 0.6438 - val_categorical_accuracy: 0.6438 - lr: 8.6593e-05\n",
      "Epoch 119/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 0.9731 - accuracy: 0.6528 - categorical_accuracy: 0.6528\n",
      "Epoch 119: val_accuracy did not improve from 0.64421\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 0.9731 - accuracy: 0.6528 - categorical_accuracy: 0.6528 - val_loss: 0.9899 - val_accuracy: 0.6431 - val_categorical_accuracy: 0.6431 - lr: 8.6593e-05\n",
      "Epoch 120/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9725 - accuracy: 0.6526 - categorical_accuracy: 0.6526\n",
      "Epoch 120: val_accuracy improved from 0.64421 to 0.64484, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9724 - accuracy: 0.6526 - categorical_accuracy: 0.6526 - val_loss: 0.9867 - val_accuracy: 0.6448 - val_categorical_accuracy: 0.6448 - lr: 8.6593e-05\n",
      "Epoch 121/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 0.9723 - accuracy: 0.6529 - categorical_accuracy: 0.6529\n",
      "Epoch 121: val_accuracy did not improve from 0.64484\n",
      "7514/7514 [==============================] - 7s 956us/step - loss: 0.9722 - accuracy: 0.6530 - categorical_accuracy: 0.6530 - val_loss: 0.9901 - val_accuracy: 0.6438 - val_categorical_accuracy: 0.6438 - lr: 8.6593e-05\n",
      "Epoch 122/200\n",
      "7509/7514 [============================>.] - ETA: 0s - loss: 0.9720 - accuracy: 0.6534 - categorical_accuracy: 0.6534\n",
      "Epoch 122: val_accuracy did not improve from 0.64484\n",
      "7514/7514 [==============================] - 7s 958us/step - loss: 0.9720 - accuracy: 0.6534 - categorical_accuracy: 0.6534 - val_loss: 0.9897 - val_accuracy: 0.6426 - val_categorical_accuracy: 0.6426 - lr: 8.6593e-05\n",
      "Epoch 123/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9714 - accuracy: 0.6537 - categorical_accuracy: 0.6537\n",
      "Epoch 123: val_accuracy did not improve from 0.64484\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9715 - accuracy: 0.6537 - categorical_accuracy: 0.6537 - val_loss: 0.9880 - val_accuracy: 0.6437 - val_categorical_accuracy: 0.6437 - lr: 8.6593e-05\n",
      "Epoch 124/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 0.9713 - accuracy: 0.6537 - categorical_accuracy: 0.6537\n",
      "Epoch 124: val_accuracy did not improve from 0.64484\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 0.9713 - accuracy: 0.6537 - categorical_accuracy: 0.6537 - val_loss: 0.9886 - val_accuracy: 0.6434 - val_categorical_accuracy: 0.6434 - lr: 8.6593e-05\n",
      "Epoch 125/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 0.9712 - accuracy: 0.6534 - categorical_accuracy: 0.6534\n",
      "Epoch 125: val_accuracy improved from 0.64484 to 0.64489, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9712 - accuracy: 0.6534 - categorical_accuracy: 0.6534 - val_loss: 0.9861 - val_accuracy: 0.6449 - val_categorical_accuracy: 0.6449 - lr: 8.6593e-05\n",
      "Epoch 126/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9711 - accuracy: 0.6536 - categorical_accuracy: 0.6536\n",
      "Epoch 126: val_accuracy did not improve from 0.64489\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9711 - accuracy: 0.6536 - categorical_accuracy: 0.6536 - val_loss: 0.9874 - val_accuracy: 0.6436 - val_categorical_accuracy: 0.6436 - lr: 8.6593e-05\n",
      "Epoch 127/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9709 - accuracy: 0.6535 - categorical_accuracy: 0.6535\n",
      "Epoch 127: val_accuracy did not improve from 0.64489\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 0.9707 - accuracy: 0.6536 - categorical_accuracy: 0.6536 - val_loss: 0.9855 - val_accuracy: 0.6437 - val_categorical_accuracy: 0.6437 - lr: 8.6593e-05\n",
      "Epoch 128/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9702 - accuracy: 0.6539 - categorical_accuracy: 0.6539\n",
      "Epoch 128: val_accuracy did not improve from 0.64489\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 0.9703 - accuracy: 0.6538 - categorical_accuracy: 0.6538 - val_loss: 0.9875 - val_accuracy: 0.6445 - val_categorical_accuracy: 0.6445 - lr: 8.6593e-05\n",
      "Epoch 129/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 0.9702 - accuracy: 0.6543 - categorical_accuracy: 0.6543\n",
      "Epoch 129: val_accuracy improved from 0.64489 to 0.64519, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9701 - accuracy: 0.6543 - categorical_accuracy: 0.6543 - val_loss: 0.9847 - val_accuracy: 0.6452 - val_categorical_accuracy: 0.6452 - lr: 8.6593e-05\n",
      "Epoch 130/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6542 - categorical_accuracy: 0.6542\n",
      "Epoch 130: val_accuracy did not improve from 0.64519\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9698 - accuracy: 0.6541 - categorical_accuracy: 0.6541 - val_loss: 0.9878 - val_accuracy: 0.6442 - val_categorical_accuracy: 0.6442 - lr: 8.6593e-05\n",
      "Epoch 131/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9697 - accuracy: 0.6541 - categorical_accuracy: 0.6541\n",
      "Epoch 131: val_accuracy did not improve from 0.64519\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9697 - accuracy: 0.6542 - categorical_accuracy: 0.6542 - val_loss: 0.9864 - val_accuracy: 0.6440 - val_categorical_accuracy: 0.6440 - lr: 8.6593e-05\n",
      "Epoch 132/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 0.9696 - accuracy: 0.6536 - categorical_accuracy: 0.6536\n",
      "Epoch 132: val_accuracy improved from 0.64519 to 0.64579, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9698 - accuracy: 0.6536 - categorical_accuracy: 0.6536 - val_loss: 0.9844 - val_accuracy: 0.6458 - val_categorical_accuracy: 0.6458 - lr: 8.6593e-05\n",
      "Epoch 133/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 0.9690 - accuracy: 0.6543 - categorical_accuracy: 0.6543\n",
      "Epoch 133: val_accuracy did not improve from 0.64579\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 0.9691 - accuracy: 0.6542 - categorical_accuracy: 0.6542 - val_loss: 0.9854 - val_accuracy: 0.6443 - val_categorical_accuracy: 0.6443 - lr: 8.6593e-05\n",
      "Epoch 134/200\n",
      "7509/7514 [============================>.] - ETA: 0s - loss: 0.9687 - accuracy: 0.6547 - categorical_accuracy: 0.6547\n",
      "Epoch 134: val_accuracy did not improve from 0.64579\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 0.9687 - accuracy: 0.6547 - categorical_accuracy: 0.6547 - val_loss: 0.9881 - val_accuracy: 0.6425 - val_categorical_accuracy: 0.6425 - lr: 8.6593e-05\n",
      "Epoch 135/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 0.9686 - accuracy: 0.6552 - categorical_accuracy: 0.6552\n",
      "Epoch 135: val_accuracy improved from 0.64579 to 0.64679, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9686 - accuracy: 0.6552 - categorical_accuracy: 0.6552 - val_loss: 0.9829 - val_accuracy: 0.6468 - val_categorical_accuracy: 0.6468 - lr: 8.6593e-05\n",
      "Epoch 136/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9683 - accuracy: 0.6552 - categorical_accuracy: 0.6552\n",
      "Epoch 136: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 951us/step - loss: 0.9683 - accuracy: 0.6552 - categorical_accuracy: 0.6552 - val_loss: 0.9828 - val_accuracy: 0.6460 - val_categorical_accuracy: 0.6460 - lr: 8.6593e-05\n",
      "Epoch 137/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9682 - accuracy: 0.6544 - categorical_accuracy: 0.6544\n",
      "Epoch 137: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 0.9681 - accuracy: 0.6544 - categorical_accuracy: 0.6544 - val_loss: 0.9843 - val_accuracy: 0.6457 - val_categorical_accuracy: 0.6457 - lr: 8.6593e-05\n",
      "Epoch 138/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9684 - accuracy: 0.6551 - categorical_accuracy: 0.6551\n",
      "Epoch 138: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9684 - accuracy: 0.6552 - categorical_accuracy: 0.6552 - val_loss: 0.9845 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444 - lr: 8.6593e-05\n",
      "Epoch 139/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 0.9678 - accuracy: 0.6554 - categorical_accuracy: 0.6554\n",
      "Epoch 139: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 0.9679 - accuracy: 0.6554 - categorical_accuracy: 0.6554 - val_loss: 0.9855 - val_accuracy: 0.6434 - val_categorical_accuracy: 0.6434 - lr: 8.6593e-05\n",
      "Epoch 140/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 0.9678 - accuracy: 0.6553 - categorical_accuracy: 0.6553\n",
      "Epoch 140: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9678 - accuracy: 0.6553 - categorical_accuracy: 0.6553 - val_loss: 0.9832 - val_accuracy: 0.6462 - val_categorical_accuracy: 0.6462 - lr: 8.6593e-05\n",
      "Epoch 141/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 0.9674 - accuracy: 0.6550 - categorical_accuracy: 0.6550\n",
      "Epoch 141: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 957us/step - loss: 0.9674 - accuracy: 0.6550 - categorical_accuracy: 0.6550 - val_loss: 0.9839 - val_accuracy: 0.6466 - val_categorical_accuracy: 0.6466 - lr: 8.6593e-05\n",
      "Epoch 142/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9673 - accuracy: 0.6554 - categorical_accuracy: 0.6554\n",
      "Epoch 142: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 952us/step - loss: 0.9672 - accuracy: 0.6554 - categorical_accuracy: 0.6554 - val_loss: 0.9874 - val_accuracy: 0.6429 - val_categorical_accuracy: 0.6429 - lr: 8.6593e-05\n",
      "Epoch 143/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 0.9675 - accuracy: 0.6552 - categorical_accuracy: 0.6552\n",
      "Epoch 143: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 929us/step - loss: 0.9675 - accuracy: 0.6552 - categorical_accuracy: 0.6552 - val_loss: 0.9839 - val_accuracy: 0.6465 - val_categorical_accuracy: 0.6465 - lr: 8.6593e-05\n",
      "Epoch 144/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9670 - accuracy: 0.6554 - categorical_accuracy: 0.6554\n",
      "Epoch 144: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 0.9670 - accuracy: 0.6554 - categorical_accuracy: 0.6554 - val_loss: 0.9836 - val_accuracy: 0.6464 - val_categorical_accuracy: 0.6464 - lr: 8.6593e-05\n",
      "Epoch 145/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9664 - accuracy: 0.6557 - categorical_accuracy: 0.6557\n",
      "Epoch 145: val_accuracy did not improve from 0.64679\n",
      "7514/7514 [==============================] - 7s 949us/step - loss: 0.9665 - accuracy: 0.6556 - categorical_accuracy: 0.6556 - val_loss: 0.9825 - val_accuracy: 0.6449 - val_categorical_accuracy: 0.6449 - lr: 8.6593e-05\n",
      "Epoch 146/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 0.9664 - accuracy: 0.6557 - categorical_accuracy: 0.6557\n",
      "Epoch 146: val_accuracy improved from 0.64679 to 0.64729, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 0.9664 - accuracy: 0.6557 - categorical_accuracy: 0.6557 - val_loss: 0.9832 - val_accuracy: 0.6473 - val_categorical_accuracy: 0.6473 - lr: 8.6593e-05\n",
      "Epoch 147/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 0.9658 - accuracy: 0.6562 - categorical_accuracy: 0.6562\n",
      "Epoch 147: val_accuracy did not improve from 0.64729\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 0.9659 - accuracy: 0.6561 - categorical_accuracy: 0.6561 - val_loss: 0.9812 - val_accuracy: 0.6464 - val_categorical_accuracy: 0.6464 - lr: 8.6593e-05\n",
      "Epoch 148/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9662 - accuracy: 0.6561 - categorical_accuracy: 0.6561\n",
      "Epoch 148: val_accuracy did not improve from 0.64729\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 0.9662 - accuracy: 0.6562 - categorical_accuracy: 0.6562 - val_loss: 0.9828 - val_accuracy: 0.6464 - val_categorical_accuracy: 0.6464 - lr: 8.6593e-05\n",
      "Epoch 149/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 0.9661 - accuracy: 0.6558 - categorical_accuracy: 0.6558\n",
      "Epoch 149: val_accuracy did not improve from 0.64729\n",
      "7514/7514 [==============================] - 7s 935us/step - loss: 0.9661 - accuracy: 0.6558 - categorical_accuracy: 0.6558 - val_loss: 0.9810 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 150/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 0.9660 - accuracy: 0.6561 - categorical_accuracy: 0.6561\n",
      "Epoch 150: val_accuracy did not improve from 0.64729\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 0.9661 - accuracy: 0.6561 - categorical_accuracy: 0.6561 - val_loss: 0.9817 - val_accuracy: 0.6468 - val_categorical_accuracy: 0.6468 - lr: 8.6593e-05\n",
      "Epoch 151/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9654 - accuracy: 0.6562 - categorical_accuracy: 0.6562\n",
      "Epoch 151: val_accuracy did not improve from 0.64729\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 0.9654 - accuracy: 0.6561 - categorical_accuracy: 0.6561 - val_loss: 0.9838 - val_accuracy: 0.6463 - val_categorical_accuracy: 0.6463 - lr: 8.6593e-05\n",
      "Epoch 152/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9653 - accuracy: 0.6562 - categorical_accuracy: 0.6562\n",
      "Epoch 152: val_accuracy did not improve from 0.64729\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 0.9654 - accuracy: 0.6562 - categorical_accuracy: 0.6562 - val_loss: 0.9814 - val_accuracy: 0.6473 - val_categorical_accuracy: 0.6473 - lr: 8.6593e-05\n",
      "Epoch 153/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9652 - accuracy: 0.6567 - categorical_accuracy: 0.6567\n",
      "Epoch 153: val_accuracy did not improve from 0.64729\n",
      "7514/7514 [==============================] - 7s 941us/step - loss: 0.9653 - accuracy: 0.6567 - categorical_accuracy: 0.6567 - val_loss: 0.9804 - val_accuracy: 0.6471 - val_categorical_accuracy: 0.6471 - lr: 8.6593e-05\n",
      "Epoch 154/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9644 - accuracy: 0.6569 - categorical_accuracy: 0.6569\n",
      "Epoch 154: val_accuracy improved from 0.64729 to 0.64822, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 937us/step - loss: 0.9645 - accuracy: 0.6568 - categorical_accuracy: 0.6568 - val_loss: 0.9788 - val_accuracy: 0.6482 - val_categorical_accuracy: 0.6482 - lr: 8.6593e-05\n",
      "Epoch 155/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9649 - accuracy: 0.6563 - categorical_accuracy: 0.6563\n",
      "Epoch 155: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 0.9649 - accuracy: 0.6562 - categorical_accuracy: 0.6562 - val_loss: 0.9816 - val_accuracy: 0.6470 - val_categorical_accuracy: 0.6470 - lr: 8.6593e-05\n",
      "Epoch 156/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9644 - accuracy: 0.6570 - categorical_accuracy: 0.6570\n",
      "Epoch 156: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 0.9646 - accuracy: 0.6569 - categorical_accuracy: 0.6569 - val_loss: 0.9800 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 157/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9647 - accuracy: 0.6565 - categorical_accuracy: 0.6565\n",
      "Epoch 157: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 0.9646 - accuracy: 0.6565 - categorical_accuracy: 0.6565 - val_loss: 0.9792 - val_accuracy: 0.6473 - val_categorical_accuracy: 0.6473 - lr: 8.6593e-05\n",
      "Epoch 158/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 0.9643 - accuracy: 0.6566 - categorical_accuracy: 0.6566\n",
      "Epoch 158: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 927us/step - loss: 0.9643 - accuracy: 0.6566 - categorical_accuracy: 0.6566 - val_loss: 0.9802 - val_accuracy: 0.6481 - val_categorical_accuracy: 0.6481 - lr: 8.6593e-05\n",
      "Epoch 159/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 0.9639 - accuracy: 0.6569 - categorical_accuracy: 0.6569\n",
      "Epoch 159: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 0.9639 - accuracy: 0.6569 - categorical_accuracy: 0.6569 - val_loss: 0.9838 - val_accuracy: 0.6442 - val_categorical_accuracy: 0.6442 - lr: 8.6593e-05\n",
      "Epoch 160/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9640 - accuracy: 0.6568 - categorical_accuracy: 0.6568\n",
      "Epoch 160: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 955us/step - loss: 0.9641 - accuracy: 0.6567 - categorical_accuracy: 0.6567 - val_loss: 0.9800 - val_accuracy: 0.6474 - val_categorical_accuracy: 0.6474 - lr: 8.6593e-05\n",
      "Epoch 161/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 0.9641 - accuracy: 0.6566 - categorical_accuracy: 0.6566\n",
      "Epoch 161: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9640 - accuracy: 0.6567 - categorical_accuracy: 0.6567 - val_loss: 0.9804 - val_accuracy: 0.6465 - val_categorical_accuracy: 0.6465 - lr: 8.6593e-05\n",
      "Epoch 162/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9637 - accuracy: 0.6572 - categorical_accuracy: 0.6572\n",
      "Epoch 162: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 0.9637 - accuracy: 0.6572 - categorical_accuracy: 0.6572 - val_loss: 0.9800 - val_accuracy: 0.6470 - val_categorical_accuracy: 0.6470 - lr: 8.6593e-05\n",
      "Epoch 163/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9633 - accuracy: 0.6574 - categorical_accuracy: 0.6574\n",
      "Epoch 163: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 0.9635 - accuracy: 0.6572 - categorical_accuracy: 0.6572 - val_loss: 0.9803 - val_accuracy: 0.6473 - val_categorical_accuracy: 0.6473 - lr: 8.6593e-05\n",
      "Epoch 164/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 0.9634 - accuracy: 0.6573 - categorical_accuracy: 0.6573\n",
      "Epoch 164: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9633 - accuracy: 0.6573 - categorical_accuracy: 0.6573 - val_loss: 0.9804 - val_accuracy: 0.6475 - val_categorical_accuracy: 0.6475 - lr: 8.6593e-05\n",
      "Epoch 165/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 0.9634 - accuracy: 0.6571 - categorical_accuracy: 0.6571\n",
      "Epoch 165: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 954us/step - loss: 0.9634 - accuracy: 0.6571 - categorical_accuracy: 0.6571 - val_loss: 0.9802 - val_accuracy: 0.6481 - val_categorical_accuracy: 0.6481 - lr: 8.6593e-05\n",
      "Epoch 166/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9633 - accuracy: 0.6572 - categorical_accuracy: 0.6572\n",
      "Epoch 166: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 947us/step - loss: 0.9633 - accuracy: 0.6572 - categorical_accuracy: 0.6572 - val_loss: 0.9782 - val_accuracy: 0.6480 - val_categorical_accuracy: 0.6480 - lr: 8.6593e-05\n",
      "Epoch 167/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 0.9631 - accuracy: 0.6572 - categorical_accuracy: 0.6572\n",
      "Epoch 167: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 0.9631 - accuracy: 0.6572 - categorical_accuracy: 0.6572 - val_loss: 0.9799 - val_accuracy: 0.6467 - val_categorical_accuracy: 0.6467 - lr: 8.6593e-05\n",
      "Epoch 168/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9629 - accuracy: 0.6575 - categorical_accuracy: 0.6575\n",
      "Epoch 168: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 0.9629 - accuracy: 0.6575 - categorical_accuracy: 0.6575 - val_loss: 0.9799 - val_accuracy: 0.6481 - val_categorical_accuracy: 0.6481 - lr: 8.6593e-05\n",
      "Epoch 169/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9631 - accuracy: 0.6572 - categorical_accuracy: 0.6572\n",
      "Epoch 169: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 938us/step - loss: 0.9631 - accuracy: 0.6571 - categorical_accuracy: 0.6571 - val_loss: 0.9786 - val_accuracy: 0.6474 - val_categorical_accuracy: 0.6474 - lr: 8.6593e-05\n",
      "Epoch 170/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9624 - accuracy: 0.6575 - categorical_accuracy: 0.6575\n",
      "Epoch 170: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 936us/step - loss: 0.9626 - accuracy: 0.6574 - categorical_accuracy: 0.6574 - val_loss: 0.9805 - val_accuracy: 0.6470 - val_categorical_accuracy: 0.6470 - lr: 8.6593e-05\n",
      "Epoch 171/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9622 - accuracy: 0.6580 - categorical_accuracy: 0.6580\n",
      "Epoch 171: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 946us/step - loss: 0.9622 - accuracy: 0.6580 - categorical_accuracy: 0.6580 - val_loss: 0.9787 - val_accuracy: 0.6482 - val_categorical_accuracy: 0.6482 - lr: 8.6593e-05\n",
      "Epoch 172/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 0.9623 - accuracy: 0.6577 - categorical_accuracy: 0.6577\n",
      "Epoch 172: val_accuracy did not improve from 0.64822\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 0.9623 - accuracy: 0.6577 - categorical_accuracy: 0.6577 - val_loss: 0.9801 - val_accuracy: 0.6473 - val_categorical_accuracy: 0.6473 - lr: 8.6593e-05\n",
      "Epoch 173/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9623 - accuracy: 0.6576 - categorical_accuracy: 0.6576\n",
      "Epoch 173: val_accuracy improved from 0.64822 to 0.64927, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 0.9623 - accuracy: 0.6575 - categorical_accuracy: 0.6575 - val_loss: 0.9776 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 174/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9617 - accuracy: 0.6582 - categorical_accuracy: 0.6582\n",
      "Epoch 174: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 0.9616 - accuracy: 0.6582 - categorical_accuracy: 0.6582 - val_loss: 0.9781 - val_accuracy: 0.6482 - val_categorical_accuracy: 0.6482 - lr: 8.6593e-05\n",
      "Epoch 175/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9619 - accuracy: 0.6580 - categorical_accuracy: 0.6580\n",
      "Epoch 175: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9619 - accuracy: 0.6581 - categorical_accuracy: 0.6581 - val_loss: 0.9780 - val_accuracy: 0.6487 - val_categorical_accuracy: 0.6487 - lr: 8.6593e-05\n",
      "Epoch 176/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9616 - accuracy: 0.6580 - categorical_accuracy: 0.6580\n",
      "Epoch 176: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 0.9616 - accuracy: 0.6580 - categorical_accuracy: 0.6580 - val_loss: 0.9787 - val_accuracy: 0.6478 - val_categorical_accuracy: 0.6478 - lr: 8.6593e-05\n",
      "Epoch 177/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 0.9614 - accuracy: 0.6581 - categorical_accuracy: 0.6581\n",
      "Epoch 177: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 0.9613 - accuracy: 0.6581 - categorical_accuracy: 0.6581 - val_loss: 0.9768 - val_accuracy: 0.6485 - val_categorical_accuracy: 0.6485 - lr: 8.6593e-05\n",
      "Epoch 178/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 0.9614 - accuracy: 0.6581 - categorical_accuracy: 0.6581\n",
      "Epoch 178: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 939us/step - loss: 0.9614 - accuracy: 0.6581 - categorical_accuracy: 0.6581 - val_loss: 0.9796 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 179/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9616 - accuracy: 0.6583 - categorical_accuracy: 0.6583\n",
      "Epoch 179: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 953us/step - loss: 0.9615 - accuracy: 0.6583 - categorical_accuracy: 0.6583 - val_loss: 0.9793 - val_accuracy: 0.6480 - val_categorical_accuracy: 0.6480 - lr: 8.6593e-05\n",
      "Epoch 180/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9611 - accuracy: 0.6587 - categorical_accuracy: 0.6587\n",
      "Epoch 180: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 0.9610 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.9768 - val_accuracy: 0.6490 - val_categorical_accuracy: 0.6490 - lr: 8.6593e-05\n",
      "Epoch 181/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 0.9610 - accuracy: 0.6587 - categorical_accuracy: 0.6587\n",
      "Epoch 181: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 931us/step - loss: 0.9610 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.9787 - val_accuracy: 0.6489 - val_categorical_accuracy: 0.6489 - lr: 8.6593e-05\n",
      "Epoch 182/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9606 - accuracy: 0.6584 - categorical_accuracy: 0.6584\n",
      "Epoch 182: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 924us/step - loss: 0.9607 - accuracy: 0.6584 - categorical_accuracy: 0.6584 - val_loss: 0.9784 - val_accuracy: 0.6491 - val_categorical_accuracy: 0.6491 - lr: 8.6593e-05\n",
      "Epoch 183/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 0.9607 - accuracy: 0.6586 - categorical_accuracy: 0.6586\n",
      "Epoch 183: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 0.9608 - accuracy: 0.6586 - categorical_accuracy: 0.6586 - val_loss: 0.9775 - val_accuracy: 0.6482 - val_categorical_accuracy: 0.6482 - lr: 8.6593e-05\n",
      "Epoch 184/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9609 - accuracy: 0.6585 - categorical_accuracy: 0.6585\n",
      "Epoch 184: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 0.9610 - accuracy: 0.6585 - categorical_accuracy: 0.6585 - val_loss: 0.9781 - val_accuracy: 0.6471 - val_categorical_accuracy: 0.6471 - lr: 8.6593e-05\n",
      "Epoch 185/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9607 - accuracy: 0.6584 - categorical_accuracy: 0.6584\n",
      "Epoch 185: val_accuracy improved from 0.64927 to 0.64928, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9607 - accuracy: 0.6584 - categorical_accuracy: 0.6584 - val_loss: 0.9788 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 186/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 0.9608 - accuracy: 0.6585 - categorical_accuracy: 0.6585\n",
      "Epoch 186: val_accuracy did not improve from 0.64928\n",
      "7514/7514 [==============================] - 7s 942us/step - loss: 0.9608 - accuracy: 0.6585 - categorical_accuracy: 0.6585 - val_loss: 0.9765 - val_accuracy: 0.6491 - val_categorical_accuracy: 0.6491 - lr: 8.6593e-05\n",
      "Epoch 187/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 0.9604 - accuracy: 0.6587 - categorical_accuracy: 0.6587\n",
      "Epoch 187: val_accuracy did not improve from 0.64928\n",
      "7514/7514 [==============================] - 7s 940us/step - loss: 0.9605 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.9777 - val_accuracy: 0.6474 - val_categorical_accuracy: 0.6474 - lr: 8.6593e-05\n",
      "Epoch 188/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9603 - accuracy: 0.6582 - categorical_accuracy: 0.6582\n",
      "Epoch 188: val_accuracy improved from 0.64928 to 0.64939, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 0.9603 - accuracy: 0.6581 - categorical_accuracy: 0.6581 - val_loss: 0.9762 - val_accuracy: 0.6494 - val_categorical_accuracy: 0.6494 - lr: 8.6593e-05\n",
      "Epoch 189/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 0.9603 - accuracy: 0.6590 - categorical_accuracy: 0.6590\n",
      "Epoch 189: val_accuracy did not improve from 0.64939\n",
      "7514/7514 [==============================] - 7s 925us/step - loss: 0.9603 - accuracy: 0.6590 - categorical_accuracy: 0.6590 - val_loss: 0.9789 - val_accuracy: 0.6469 - val_categorical_accuracy: 0.6469 - lr: 8.6593e-05\n",
      "Epoch 190/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 0.9605 - accuracy: 0.6592 - categorical_accuracy: 0.6592\n",
      "Epoch 190: val_accuracy improved from 0.64939 to 0.64948, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 948us/step - loss: 0.9604 - accuracy: 0.6592 - categorical_accuracy: 0.6592 - val_loss: 0.9766 - val_accuracy: 0.6495 - val_categorical_accuracy: 0.6495 - lr: 8.6593e-05\n",
      "Epoch 191/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 0.9601 - accuracy: 0.6592 - categorical_accuracy: 0.6592\n",
      "Epoch 191: val_accuracy did not improve from 0.64948\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 0.9601 - accuracy: 0.6592 - categorical_accuracy: 0.6592 - val_loss: 0.9776 - val_accuracy: 0.6482 - val_categorical_accuracy: 0.6482 - lr: 8.6593e-05\n",
      "Epoch 192/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9600 - accuracy: 0.6587 - categorical_accuracy: 0.6587\n",
      "Epoch 192: val_accuracy improved from 0.64948 to 0.65140, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_2.h5\n",
      "7514/7514 [==============================] - 7s 945us/step - loss: 0.9600 - accuracy: 0.6588 - categorical_accuracy: 0.6588 - val_loss: 0.9740 - val_accuracy: 0.6514 - val_categorical_accuracy: 0.6514 - lr: 8.6593e-05\n",
      "Epoch 193/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 0.9596 - accuracy: 0.6587 - categorical_accuracy: 0.6587\n",
      "Epoch 193: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 944us/step - loss: 0.9596 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.9762 - val_accuracy: 0.6491 - val_categorical_accuracy: 0.6491 - lr: 8.6593e-05\n",
      "Epoch 194/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9597 - accuracy: 0.6592 - categorical_accuracy: 0.6592\n",
      "Epoch 194: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 0.9598 - accuracy: 0.6592 - categorical_accuracy: 0.6592 - val_loss: 0.9761 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496 - lr: 8.6593e-05\n",
      "Epoch 195/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9599 - accuracy: 0.6594 - categorical_accuracy: 0.6594\n",
      "Epoch 195: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 932us/step - loss: 0.9598 - accuracy: 0.6594 - categorical_accuracy: 0.6594 - val_loss: 0.9756 - val_accuracy: 0.6509 - val_categorical_accuracy: 0.6509 - lr: 8.6593e-05\n",
      "Epoch 196/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9597 - accuracy: 0.6589 - categorical_accuracy: 0.6589\n",
      "Epoch 196: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 933us/step - loss: 0.9597 - accuracy: 0.6588 - categorical_accuracy: 0.6588 - val_loss: 0.9799 - val_accuracy: 0.6464 - val_categorical_accuracy: 0.6464 - lr: 8.6593e-05\n",
      "Epoch 197/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 0.9592 - accuracy: 0.6593 - categorical_accuracy: 0.6593\n",
      "Epoch 197: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 925us/step - loss: 0.9592 - accuracy: 0.6593 - categorical_accuracy: 0.6593 - val_loss: 0.9790 - val_accuracy: 0.6476 - val_categorical_accuracy: 0.6476 - lr: 8.6593e-05\n",
      "Epoch 198/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9595 - accuracy: 0.6591 - categorical_accuracy: 0.6591\n",
      "Epoch 198: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 0.9594 - accuracy: 0.6591 - categorical_accuracy: 0.6591 - val_loss: 0.9748 - val_accuracy: 0.6508 - val_categorical_accuracy: 0.6508 - lr: 8.6593e-05\n",
      "Epoch 199/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9593 - accuracy: 0.6592 - categorical_accuracy: 0.6592\n",
      "Epoch 199: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 926us/step - loss: 0.9593 - accuracy: 0.6592 - categorical_accuracy: 0.6592 - val_loss: 0.9768 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 200/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 0.9592 - accuracy: 0.6596 - categorical_accuracy: 0.6596\n",
      "Epoch 200: val_accuracy did not improve from 0.65140\n",
      "7514/7514 [==============================] - 7s 927us/step - loss: 0.9593 - accuracy: 0.6595 - categorical_accuracy: 0.6595 - val_loss: 0.9746 - val_accuracy: 0.6506 - val_categorical_accuracy: 0.6506 - lr: 8.6593e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kfold num: 3\n",
      "\n",
      "----------------\n",
      "Data loading complete:\n",
      "File name: None\n",
      "Training data size: 480,840\n",
      "Test data size: 120,210\n",
      "Number of constituents: 32\n",
      "Number of features: 3\n",
      "----------------\n",
      "\n",
      "(480840, 32, 3)\n",
      "(480840, 96) (120210, 96) (480840, 5) (120210, 5)\n",
      "number of G jets for training/validation: 96168/24042\n",
      "number of Q jets for training/validation: 96168/24042\n",
      "number of W jets for training/validation: 96168/24042\n",
      "number of Z jets for training/validation: 96168/24042\n",
      "number of T jets for training/validation: 96168/24042\n",
      "number of G jets for testing: 24042\n",
      "number of Q jets for testing: 24042\n",
      "number of W jets for testing: 24042\n",
      "number of Z jets for testing: 24042\n",
      "number of T jets for testing: 24042\n",
      "Epoch 1/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 1.7418 - accuracy: 0.3464 - categorical_accuracy: 0.3464\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41595, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 950us/step - loss: 1.7416 - accuracy: 0.3465 - categorical_accuracy: 0.3465 - val_loss: 1.6033 - val_accuracy: 0.4159 - val_categorical_accuracy: 0.4159 - lr: 8.6593e-05\n",
      "Epoch 2/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 1.5420 - accuracy: 0.4422 - categorical_accuracy: 0.4422\n",
      "Epoch 2: val_accuracy improved from 0.41595 to 0.45920, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.5419 - accuracy: 0.4423 - categorical_accuracy: 0.4423 - val_loss: 1.4946 - val_accuracy: 0.4592 - val_categorical_accuracy: 0.4592 - lr: 8.6593e-05\n",
      "Epoch 3/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 1.4624 - accuracy: 0.4721 - categorical_accuracy: 0.4721\n",
      "Epoch 3: val_accuracy improved from 0.45920 to 0.47637, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.4623 - accuracy: 0.4721 - categorical_accuracy: 0.4721 - val_loss: 1.4406 - val_accuracy: 0.4764 - val_categorical_accuracy: 0.4764 - lr: 8.6593e-05\n",
      "Epoch 4/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.4128 - accuracy: 0.4882 - categorical_accuracy: 0.4882\n",
      "Epoch 4: val_accuracy improved from 0.47637 to 0.48933, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.4128 - accuracy: 0.4882 - categorical_accuracy: 0.4882 - val_loss: 1.3984 - val_accuracy: 0.4893 - val_categorical_accuracy: 0.4893 - lr: 8.6593e-05\n",
      "Epoch 5/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 1.3738 - accuracy: 0.5008 - categorical_accuracy: 0.5008\n",
      "Epoch 5: val_accuracy improved from 0.48933 to 0.50141, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 916us/step - loss: 1.3736 - accuracy: 0.5009 - categorical_accuracy: 0.5009 - val_loss: 1.3628 - val_accuracy: 0.5014 - val_categorical_accuracy: 0.5014 - lr: 8.6593e-05\n",
      "Epoch 6/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 1.3398 - accuracy: 0.5114 - categorical_accuracy: 0.5114\n",
      "Epoch 6: val_accuracy improved from 0.50141 to 0.51190, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.3398 - accuracy: 0.5115 - categorical_accuracy: 0.5115 - val_loss: 1.3308 - val_accuracy: 0.5119 - val_categorical_accuracy: 0.5119 - lr: 8.6593e-05\n",
      "Epoch 7/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 1.3056 - accuracy: 0.5234 - categorical_accuracy: 0.5234\n",
      "Epoch 7: val_accuracy improved from 0.51190 to 0.52305, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.3056 - accuracy: 0.5234 - categorical_accuracy: 0.5234 - val_loss: 1.2959 - val_accuracy: 0.5231 - val_categorical_accuracy: 0.5231 - lr: 8.6593e-05\n",
      "Epoch 8/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.2710 - accuracy: 0.5367 - categorical_accuracy: 0.5367\n",
      "Epoch 8: val_accuracy improved from 0.52305 to 0.53006, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.2709 - accuracy: 0.5368 - categorical_accuracy: 0.5368 - val_loss: 1.2688 - val_accuracy: 0.5301 - val_categorical_accuracy: 0.5301 - lr: 8.6593e-05\n",
      "Epoch 9/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 1.2445 - accuracy: 0.5452 - categorical_accuracy: 0.5452\n",
      "Epoch 9: val_accuracy improved from 0.53006 to 0.54243, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.2446 - accuracy: 0.5451 - categorical_accuracy: 0.5451 - val_loss: 1.2435 - val_accuracy: 0.5424 - val_categorical_accuracy: 0.5424 - lr: 8.6593e-05\n",
      "Epoch 10/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 1.2252 - accuracy: 0.5513 - categorical_accuracy: 0.5513\n",
      "Epoch 10: val_accuracy improved from 0.54243 to 0.54386, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.2250 - accuracy: 0.5515 - categorical_accuracy: 0.5515 - val_loss: 1.2286 - val_accuracy: 0.5439 - val_categorical_accuracy: 0.5439 - lr: 8.6593e-05\n",
      "Epoch 11/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 1.2100 - accuracy: 0.5557 - categorical_accuracy: 0.5557\n",
      "Epoch 11: val_accuracy improved from 0.54386 to 0.55149, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.2100 - accuracy: 0.5557 - categorical_accuracy: 0.5557 - val_loss: 1.2134 - val_accuracy: 0.5515 - val_categorical_accuracy: 0.5515 - lr: 8.6593e-05\n",
      "Epoch 12/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 1.1969 - accuracy: 0.5589 - categorical_accuracy: 0.5589\n",
      "Epoch 12: val_accuracy improved from 0.55149 to 0.55485, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 1.1969 - accuracy: 0.5589 - categorical_accuracy: 0.5589 - val_loss: 1.2016 - val_accuracy: 0.5548 - val_categorical_accuracy: 0.5548 - lr: 8.6593e-05\n",
      "Epoch 13/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 1.1846 - accuracy: 0.5632 - categorical_accuracy: 0.5632\n",
      "Epoch 13: val_accuracy improved from 0.55485 to 0.55872, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.1846 - accuracy: 0.5632 - categorical_accuracy: 0.5632 - val_loss: 1.1898 - val_accuracy: 0.5587 - val_categorical_accuracy: 0.5587 - lr: 8.6593e-05\n",
      "Epoch 14/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 1.1734 - accuracy: 0.5668 - categorical_accuracy: 0.5668\n",
      "Epoch 14: val_accuracy improved from 0.55872 to 0.56138, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1733 - accuracy: 0.5669 - categorical_accuracy: 0.5669 - val_loss: 1.1790 - val_accuracy: 0.5614 - val_categorical_accuracy: 0.5614 - lr: 8.6593e-05\n",
      "Epoch 15/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 1.1626 - accuracy: 0.5697 - categorical_accuracy: 0.5697\n",
      "Epoch 15: val_accuracy improved from 0.56138 to 0.56798, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1625 - accuracy: 0.5698 - categorical_accuracy: 0.5698 - val_loss: 1.1681 - val_accuracy: 0.5680 - val_categorical_accuracy: 0.5680 - lr: 8.6593e-05\n",
      "Epoch 16/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 1.1522 - accuracy: 0.5742 - categorical_accuracy: 0.5742\n",
      "Epoch 16: val_accuracy improved from 0.56798 to 0.57059, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.1520 - accuracy: 0.5743 - categorical_accuracy: 0.5743 - val_loss: 1.1581 - val_accuracy: 0.5706 - val_categorical_accuracy: 0.5706 - lr: 8.6593e-05\n",
      "Epoch 17/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 1.1422 - accuracy: 0.5777 - categorical_accuracy: 0.5777\n",
      "Epoch 17: val_accuracy improved from 0.57059 to 0.57565, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 1.1422 - accuracy: 0.5778 - categorical_accuracy: 0.5778 - val_loss: 1.1472 - val_accuracy: 0.5757 - val_categorical_accuracy: 0.5757 - lr: 8.6593e-05\n",
      "Epoch 18/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 1.1327 - accuracy: 0.5812 - categorical_accuracy: 0.5812\n",
      "Epoch 18: val_accuracy improved from 0.57565 to 0.57850, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.1326 - accuracy: 0.5812 - categorical_accuracy: 0.5812 - val_loss: 1.1391 - val_accuracy: 0.5785 - val_categorical_accuracy: 0.5785 - lr: 8.6593e-05\n",
      "Epoch 19/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.1236 - accuracy: 0.5848 - categorical_accuracy: 0.5848\n",
      "Epoch 19: val_accuracy improved from 0.57850 to 0.58151, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.1236 - accuracy: 0.5848 - categorical_accuracy: 0.5848 - val_loss: 1.1295 - val_accuracy: 0.5815 - val_categorical_accuracy: 0.5815 - lr: 8.6593e-05\n",
      "Epoch 20/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.1150 - accuracy: 0.5882 - categorical_accuracy: 0.5882\n",
      "Epoch 20: val_accuracy improved from 0.58151 to 0.58529, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.1150 - accuracy: 0.5882 - categorical_accuracy: 0.5882 - val_loss: 1.1213 - val_accuracy: 0.5853 - val_categorical_accuracy: 0.5853 - lr: 8.6593e-05\n",
      "Epoch 21/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.1071 - accuracy: 0.5916 - categorical_accuracy: 0.5916\n",
      "Epoch 21: val_accuracy improved from 0.58529 to 0.58806, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1071 - accuracy: 0.5916 - categorical_accuracy: 0.5916 - val_loss: 1.1127 - val_accuracy: 0.5881 - val_categorical_accuracy: 0.5881 - lr: 8.6593e-05\n",
      "Epoch 22/200\n",
      "7454/7514 [============================>.] - ETA: 0s - loss: 1.1002 - accuracy: 0.5942 - categorical_accuracy: 0.5942\n",
      "Epoch 22: val_accuracy did not improve from 0.58806\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.1002 - accuracy: 0.5942 - categorical_accuracy: 0.5942 - val_loss: 1.1128 - val_accuracy: 0.5849 - val_categorical_accuracy: 0.5849 - lr: 8.6593e-05\n",
      "Epoch 23/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.0936 - accuracy: 0.5968 - categorical_accuracy: 0.5968\n",
      "Epoch 23: val_accuracy improved from 0.58806 to 0.59354, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0935 - accuracy: 0.5968 - categorical_accuracy: 0.5968 - val_loss: 1.0987 - val_accuracy: 0.5935 - val_categorical_accuracy: 0.5935 - lr: 8.6593e-05\n",
      "Epoch 24/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 1.0874 - accuracy: 0.5996 - categorical_accuracy: 0.5996\n",
      "Epoch 24: val_accuracy improved from 0.59354 to 0.59646, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 901us/step - loss: 1.0875 - accuracy: 0.5996 - categorical_accuracy: 0.5996 - val_loss: 1.0933 - val_accuracy: 0.5965 - val_categorical_accuracy: 0.5965 - lr: 8.6593e-05\n",
      "Epoch 25/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0818 - accuracy: 0.6020 - categorical_accuracy: 0.6020\n",
      "Epoch 25: val_accuracy improved from 0.59646 to 0.59898, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 895us/step - loss: 1.0818 - accuracy: 0.6020 - categorical_accuracy: 0.6020 - val_loss: 1.0873 - val_accuracy: 0.5990 - val_categorical_accuracy: 0.5990 - lr: 8.6593e-05\n",
      "Epoch 26/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 1.0768 - accuracy: 0.6038 - categorical_accuracy: 0.6038\n",
      "Epoch 26: val_accuracy improved from 0.59898 to 0.59921, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 887us/step - loss: 1.0767 - accuracy: 0.6039 - categorical_accuracy: 0.6039 - val_loss: 1.0833 - val_accuracy: 0.5992 - val_categorical_accuracy: 0.5992 - lr: 8.6593e-05\n",
      "Epoch 27/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0719 - accuracy: 0.6059 - categorical_accuracy: 0.6059\n",
      "Epoch 27: val_accuracy improved from 0.59921 to 0.59947, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 892us/step - loss: 1.0720 - accuracy: 0.6058 - categorical_accuracy: 0.6058 - val_loss: 1.0818 - val_accuracy: 0.5995 - val_categorical_accuracy: 0.5995 - lr: 8.6593e-05\n",
      "Epoch 28/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0679 - accuracy: 0.6075 - categorical_accuracy: 0.6075\n",
      "Epoch 28: val_accuracy improved from 0.59947 to 0.60212, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 890us/step - loss: 1.0679 - accuracy: 0.6075 - categorical_accuracy: 0.6075 - val_loss: 1.0757 - val_accuracy: 0.6021 - val_categorical_accuracy: 0.6021 - lr: 8.6593e-05\n",
      "Epoch 29/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0637 - accuracy: 0.6096 - categorical_accuracy: 0.6096\n",
      "Epoch 29: val_accuracy improved from 0.60212 to 0.60630, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 891us/step - loss: 1.0638 - accuracy: 0.6095 - categorical_accuracy: 0.6095 - val_loss: 1.0712 - val_accuracy: 0.6063 - val_categorical_accuracy: 0.6063 - lr: 8.6593e-05\n",
      "Epoch 30/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 1.0598 - accuracy: 0.6109 - categorical_accuracy: 0.6109\n",
      "Epoch 30: val_accuracy improved from 0.60630 to 0.60683, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 891us/step - loss: 1.0599 - accuracy: 0.6108 - categorical_accuracy: 0.6108 - val_loss: 1.0684 - val_accuracy: 0.6068 - val_categorical_accuracy: 0.6068 - lr: 8.6593e-05\n",
      "Epoch 31/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0566 - accuracy: 0.6127 - categorical_accuracy: 0.6127\n",
      "Epoch 31: val_accuracy improved from 0.60683 to 0.60714, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 892us/step - loss: 1.0564 - accuracy: 0.6128 - categorical_accuracy: 0.6128 - val_loss: 1.0637 - val_accuracy: 0.6071 - val_categorical_accuracy: 0.6071 - lr: 8.6593e-05\n",
      "Epoch 32/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 1.0532 - accuracy: 0.6139 - categorical_accuracy: 0.6139\n",
      "Epoch 32: val_accuracy improved from 0.60714 to 0.61010, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 893us/step - loss: 1.0532 - accuracy: 0.6140 - categorical_accuracy: 0.6140 - val_loss: 1.0600 - val_accuracy: 0.6101 - val_categorical_accuracy: 0.6101 - lr: 8.6593e-05\n",
      "Epoch 33/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.0501 - accuracy: 0.6148 - categorical_accuracy: 0.6148\n",
      "Epoch 33: val_accuracy improved from 0.61010 to 0.61067, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0503 - accuracy: 0.6147 - categorical_accuracy: 0.6147 - val_loss: 1.0584 - val_accuracy: 0.6107 - val_categorical_accuracy: 0.6107 - lr: 8.6593e-05\n",
      "Epoch 34/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 1.0474 - accuracy: 0.6161 - categorical_accuracy: 0.6161\n",
      "Epoch 34: val_accuracy improved from 0.61067 to 0.61219, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0473 - accuracy: 0.6161 - categorical_accuracy: 0.6161 - val_loss: 1.0553 - val_accuracy: 0.6122 - val_categorical_accuracy: 0.6122 - lr: 8.6593e-05\n",
      "Epoch 35/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0448 - accuracy: 0.6177 - categorical_accuracy: 0.6177\n",
      "Epoch 35: val_accuracy improved from 0.61219 to 0.61321, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0448 - accuracy: 0.6177 - categorical_accuracy: 0.6177 - val_loss: 1.0534 - val_accuracy: 0.6132 - val_categorical_accuracy: 0.6132 - lr: 8.6593e-05\n",
      "Epoch 36/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 1.0420 - accuracy: 0.6185 - categorical_accuracy: 0.6185\n",
      "Epoch 36: val_accuracy improved from 0.61321 to 0.61381, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0421 - accuracy: 0.6185 - categorical_accuracy: 0.6185 - val_loss: 1.0511 - val_accuracy: 0.6138 - val_categorical_accuracy: 0.6138 - lr: 8.6593e-05\n",
      "Epoch 37/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.0397 - accuracy: 0.6199 - categorical_accuracy: 0.6199\n",
      "Epoch 37: val_accuracy improved from 0.61381 to 0.61491, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.0398 - accuracy: 0.6199 - categorical_accuracy: 0.6199 - val_loss: 1.0471 - val_accuracy: 0.6149 - val_categorical_accuracy: 0.6149 - lr: 8.6593e-05\n",
      "Epoch 38/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.0372 - accuracy: 0.6209 - categorical_accuracy: 0.6209\n",
      "Epoch 38: val_accuracy did not improve from 0.61491\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 1.0372 - accuracy: 0.6209 - categorical_accuracy: 0.6209 - val_loss: 1.0483 - val_accuracy: 0.6147 - val_categorical_accuracy: 0.6147 - lr: 8.6593e-05\n",
      "Epoch 39/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 1.0353 - accuracy: 0.6217 - categorical_accuracy: 0.6217\n",
      "Epoch 39: val_accuracy improved from 0.61491 to 0.61714, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 1.0353 - accuracy: 0.6218 - categorical_accuracy: 0.6218 - val_loss: 1.0442 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171 - lr: 8.6593e-05\n",
      "Epoch 40/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0332 - accuracy: 0.6230 - categorical_accuracy: 0.6230\n",
      "Epoch 40: val_accuracy improved from 0.61714 to 0.61868, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0331 - accuracy: 0.6230 - categorical_accuracy: 0.6230 - val_loss: 1.0412 - val_accuracy: 0.6187 - val_categorical_accuracy: 0.6187 - lr: 8.6593e-05\n",
      "Epoch 41/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 1.0311 - accuracy: 0.6238 - categorical_accuracy: 0.6238\n",
      "Epoch 41: val_accuracy improved from 0.61868 to 0.61979, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0310 - accuracy: 0.6238 - categorical_accuracy: 0.6238 - val_loss: 1.0389 - val_accuracy: 0.6198 - val_categorical_accuracy: 0.6198 - lr: 8.6593e-05\n",
      "Epoch 42/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 1.0290 - accuracy: 0.6247 - categorical_accuracy: 0.6247\n",
      "Epoch 42: val_accuracy improved from 0.61979 to 0.62011, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0290 - accuracy: 0.6247 - categorical_accuracy: 0.6247 - val_loss: 1.0384 - val_accuracy: 0.6201 - val_categorical_accuracy: 0.6201 - lr: 8.6593e-05\n",
      "Epoch 43/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 1.0277 - accuracy: 0.6252 - categorical_accuracy: 0.6252\n",
      "Epoch 43: val_accuracy improved from 0.62011 to 0.62018, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.0277 - accuracy: 0.6252 - categorical_accuracy: 0.6252 - val_loss: 1.0374 - val_accuracy: 0.6202 - val_categorical_accuracy: 0.6202 - lr: 8.6593e-05\n",
      "Epoch 44/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 1.0261 - accuracy: 0.6259 - categorical_accuracy: 0.6259\n",
      "Epoch 44: val_accuracy improved from 0.62018 to 0.62019, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0260 - accuracy: 0.6260 - categorical_accuracy: 0.6260 - val_loss: 1.0355 - val_accuracy: 0.6202 - val_categorical_accuracy: 0.6202 - lr: 8.6593e-05\n",
      "Epoch 45/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 1.0245 - accuracy: 0.6268 - categorical_accuracy: 0.6268\n",
      "Epoch 45: val_accuracy improved from 0.62019 to 0.62091, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0243 - accuracy: 0.6268 - categorical_accuracy: 0.6268 - val_loss: 1.0358 - val_accuracy: 0.6209 - val_categorical_accuracy: 0.6209 - lr: 8.6593e-05\n",
      "Epoch 46/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 1.0224 - accuracy: 0.6275 - categorical_accuracy: 0.6275\n",
      "Epoch 46: val_accuracy improved from 0.62091 to 0.62284, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0225 - accuracy: 0.6275 - categorical_accuracy: 0.6275 - val_loss: 1.0333 - val_accuracy: 0.6228 - val_categorical_accuracy: 0.6228 - lr: 8.6593e-05\n",
      "Epoch 47/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 1.0212 - accuracy: 0.6286 - categorical_accuracy: 0.6286\n",
      "Epoch 47: val_accuracy did not improve from 0.62284\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 1.0212 - accuracy: 0.6286 - categorical_accuracy: 0.6286 - val_loss: 1.0334 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222 - lr: 8.6593e-05\n",
      "Epoch 48/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.0201 - accuracy: 0.6292 - categorical_accuracy: 0.6292\n",
      "Epoch 48: val_accuracy improved from 0.62284 to 0.62423, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0201 - accuracy: 0.6293 - categorical_accuracy: 0.6293 - val_loss: 1.0300 - val_accuracy: 0.6242 - val_categorical_accuracy: 0.6242 - lr: 8.6593e-05\n",
      "Epoch 49/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 1.0188 - accuracy: 0.6298 - categorical_accuracy: 0.6298\n",
      "Epoch 49: val_accuracy did not improve from 0.62423\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0188 - accuracy: 0.6298 - categorical_accuracy: 0.6298 - val_loss: 1.0304 - val_accuracy: 0.6239 - val_categorical_accuracy: 0.6239 - lr: 8.6593e-05\n",
      "Epoch 50/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 1.0176 - accuracy: 0.6301 - categorical_accuracy: 0.6301\n",
      "Epoch 50: val_accuracy improved from 0.62423 to 0.62505, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 1.0176 - accuracy: 0.6301 - categorical_accuracy: 0.6301 - val_loss: 1.0296 - val_accuracy: 0.6250 - val_categorical_accuracy: 0.6250 - lr: 8.6593e-05\n",
      "Epoch 51/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.0161 - accuracy: 0.6312 - categorical_accuracy: 0.6312\n",
      "Epoch 51: val_accuracy did not improve from 0.62505\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 1.0161 - accuracy: 0.6311 - categorical_accuracy: 0.6311 - val_loss: 1.0283 - val_accuracy: 0.6249 - val_categorical_accuracy: 0.6249 - lr: 8.6593e-05\n",
      "Epoch 52/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 1.0152 - accuracy: 0.6317 - categorical_accuracy: 0.6317\n",
      "Epoch 52: val_accuracy improved from 0.62505 to 0.62599, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0153 - accuracy: 0.6316 - categorical_accuracy: 0.6316 - val_loss: 1.0272 - val_accuracy: 0.6260 - val_categorical_accuracy: 0.6260 - lr: 8.6593e-05\n",
      "Epoch 53/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.0144 - accuracy: 0.6321 - categorical_accuracy: 0.6321\n",
      "Epoch 53: val_accuracy improved from 0.62599 to 0.62708, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0143 - accuracy: 0.6321 - categorical_accuracy: 0.6321 - val_loss: 1.0255 - val_accuracy: 0.6271 - val_categorical_accuracy: 0.6271 - lr: 8.6593e-05\n",
      "Epoch 54/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.0132 - accuracy: 0.6324 - categorical_accuracy: 0.6324\n",
      "Epoch 54: val_accuracy improved from 0.62708 to 0.62734, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 1.0132 - accuracy: 0.6324 - categorical_accuracy: 0.6324 - val_loss: 1.0240 - val_accuracy: 0.6273 - val_categorical_accuracy: 0.6273 - lr: 8.6593e-05\n",
      "Epoch 55/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 1.0128 - accuracy: 0.6327 - categorical_accuracy: 0.6327\n",
      "Epoch 55: val_accuracy did not improve from 0.62734\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0127 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0284 - val_accuracy: 0.6255 - val_categorical_accuracy: 0.6255 - lr: 8.6593e-05\n",
      "Epoch 56/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.0116 - accuracy: 0.6333 - categorical_accuracy: 0.6333\n",
      "Epoch 56: val_accuracy did not improve from 0.62734\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0117 - accuracy: 0.6332 - categorical_accuracy: 0.6332 - val_loss: 1.0246 - val_accuracy: 0.6266 - val_categorical_accuracy: 0.6266 - lr: 8.6593e-05\n",
      "Epoch 57/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 1.0109 - accuracy: 0.6337 - categorical_accuracy: 0.6337\n",
      "Epoch 57: val_accuracy did not improve from 0.62734\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0109 - accuracy: 0.6337 - categorical_accuracy: 0.6337 - val_loss: 1.0233 - val_accuracy: 0.6269 - val_categorical_accuracy: 0.6269 - lr: 8.6593e-05\n",
      "Epoch 58/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 1.0099 - accuracy: 0.6340 - categorical_accuracy: 0.6340\n",
      "Epoch 58: val_accuracy improved from 0.62734 to 0.62782, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0099 - accuracy: 0.6340 - categorical_accuracy: 0.6340 - val_loss: 1.0241 - val_accuracy: 0.6278 - val_categorical_accuracy: 0.6278 - lr: 8.6593e-05\n",
      "Epoch 59/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 1.0089 - accuracy: 0.6344 - categorical_accuracy: 0.6344\n",
      "Epoch 59: val_accuracy improved from 0.62782 to 0.62891, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0089 - accuracy: 0.6344 - categorical_accuracy: 0.6344 - val_loss: 1.0213 - val_accuracy: 0.6289 - val_categorical_accuracy: 0.6289 - lr: 8.6593e-05\n",
      "Epoch 60/200\n",
      "7454/7514 [============================>.] - ETA: 0s - loss: 1.0081 - accuracy: 0.6348 - categorical_accuracy: 0.6348\n",
      "Epoch 60: val_accuracy did not improve from 0.62891\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0080 - accuracy: 0.6349 - categorical_accuracy: 0.6349 - val_loss: 1.0205 - val_accuracy: 0.6288 - val_categorical_accuracy: 0.6288 - lr: 8.6593e-05\n",
      "Epoch 61/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0077 - accuracy: 0.6352 - categorical_accuracy: 0.6352\n",
      "Epoch 61: val_accuracy improved from 0.62891 to 0.62969, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0077 - accuracy: 0.6351 - categorical_accuracy: 0.6351 - val_loss: 1.0196 - val_accuracy: 0.6297 - val_categorical_accuracy: 0.6297 - lr: 8.6593e-05\n",
      "Epoch 62/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0066 - accuracy: 0.6360 - categorical_accuracy: 0.6360\n",
      "Epoch 62: val_accuracy improved from 0.62969 to 0.63037, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0067 - accuracy: 0.6360 - categorical_accuracy: 0.6360 - val_loss: 1.0186 - val_accuracy: 0.6304 - val_categorical_accuracy: 0.6304 - lr: 8.6593e-05\n",
      "Epoch 63/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0058 - accuracy: 0.6361 - categorical_accuracy: 0.6361\n",
      "Epoch 63: val_accuracy did not improve from 0.63037\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 1.0058 - accuracy: 0.6361 - categorical_accuracy: 0.6361 - val_loss: 1.0187 - val_accuracy: 0.6303 - val_categorical_accuracy: 0.6303 - lr: 8.6593e-05\n",
      "Epoch 64/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.0051 - accuracy: 0.6364 - categorical_accuracy: 0.6364\n",
      "Epoch 64: val_accuracy did not improve from 0.63037\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0051 - accuracy: 0.6363 - categorical_accuracy: 0.6363 - val_loss: 1.0178 - val_accuracy: 0.6302 - val_categorical_accuracy: 0.6302 - lr: 8.6593e-05\n",
      "Epoch 65/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0046 - accuracy: 0.6370 - categorical_accuracy: 0.6370\n",
      "Epoch 65: val_accuracy improved from 0.63037 to 0.63051, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0046 - accuracy: 0.6370 - categorical_accuracy: 0.6370 - val_loss: 1.0180 - val_accuracy: 0.6305 - val_categorical_accuracy: 0.6305 - lr: 8.6593e-05\n",
      "Epoch 66/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 1.0040 - accuracy: 0.6375 - categorical_accuracy: 0.6375\n",
      "Epoch 66: val_accuracy improved from 0.63051 to 0.63249, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 1.0038 - accuracy: 0.6376 - categorical_accuracy: 0.6376 - val_loss: 1.0165 - val_accuracy: 0.6325 - val_categorical_accuracy: 0.6325 - lr: 8.6593e-05\n",
      "Epoch 67/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 1.0031 - accuracy: 0.6376 - categorical_accuracy: 0.6376\n",
      "Epoch 67: val_accuracy did not improve from 0.63249\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0030 - accuracy: 0.6377 - categorical_accuracy: 0.6377 - val_loss: 1.0147 - val_accuracy: 0.6323 - val_categorical_accuracy: 0.6323 - lr: 8.6593e-05\n",
      "Epoch 68/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0022 - accuracy: 0.6384 - categorical_accuracy: 0.6384\n",
      "Epoch 68: val_accuracy did not improve from 0.63249\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 1.0021 - accuracy: 0.6385 - categorical_accuracy: 0.6385 - val_loss: 1.0141 - val_accuracy: 0.6319 - val_categorical_accuracy: 0.6319 - lr: 8.6593e-05\n",
      "Epoch 69/200\n",
      "7453/7514 [============================>.] - ETA: 0s - loss: 1.0014 - accuracy: 0.6391 - categorical_accuracy: 0.6391\n",
      "Epoch 69: val_accuracy improved from 0.63249 to 0.63304, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0014 - accuracy: 0.6390 - categorical_accuracy: 0.6390 - val_loss: 1.0145 - val_accuracy: 0.6330 - val_categorical_accuracy: 0.6330 - lr: 8.6593e-05\n",
      "Epoch 70/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 1.0007 - accuracy: 0.6390 - categorical_accuracy: 0.6390\n",
      "Epoch 70: val_accuracy did not improve from 0.63304\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0006 - accuracy: 0.6389 - categorical_accuracy: 0.6389 - val_loss: 1.0156 - val_accuracy: 0.6317 - val_categorical_accuracy: 0.6317 - lr: 8.6593e-05\n",
      "Epoch 71/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0005 - accuracy: 0.6389 - categorical_accuracy: 0.6389\n",
      "Epoch 71: val_accuracy did not improve from 0.63304\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 1.0003 - accuracy: 0.6390 - categorical_accuracy: 0.6390 - val_loss: 1.0141 - val_accuracy: 0.6324 - val_categorical_accuracy: 0.6324 - lr: 8.6593e-05\n",
      "Epoch 72/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9997 - accuracy: 0.6392 - categorical_accuracy: 0.6392\n",
      "Epoch 72: val_accuracy improved from 0.63304 to 0.63424, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9996 - accuracy: 0.6393 - categorical_accuracy: 0.6393 - val_loss: 1.0131 - val_accuracy: 0.6342 - val_categorical_accuracy: 0.6342 - lr: 8.6593e-05\n",
      "Epoch 73/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9988 - accuracy: 0.6398 - categorical_accuracy: 0.6398\n",
      "Epoch 73: val_accuracy did not improve from 0.63424\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9988 - accuracy: 0.6398 - categorical_accuracy: 0.6398 - val_loss: 1.0135 - val_accuracy: 0.6329 - val_categorical_accuracy: 0.6329 - lr: 8.6593e-05\n",
      "Epoch 74/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9982 - accuracy: 0.6405 - categorical_accuracy: 0.6405\n",
      "Epoch 74: val_accuracy did not improve from 0.63424\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9982 - accuracy: 0.6405 - categorical_accuracy: 0.6405 - val_loss: 1.0120 - val_accuracy: 0.6320 - val_categorical_accuracy: 0.6320 - lr: 8.6593e-05\n",
      "Epoch 75/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9977 - accuracy: 0.6401 - categorical_accuracy: 0.6401\n",
      "Epoch 75: val_accuracy did not improve from 0.63424\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9978 - accuracy: 0.6401 - categorical_accuracy: 0.6401 - val_loss: 1.0135 - val_accuracy: 0.6331 - val_categorical_accuracy: 0.6331 - lr: 8.6593e-05\n",
      "Epoch 76/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9972 - accuracy: 0.6414 - categorical_accuracy: 0.6414\n",
      "Epoch 76: val_accuracy improved from 0.63424 to 0.63504, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9971 - accuracy: 0.6414 - categorical_accuracy: 0.6414 - val_loss: 1.0107 - val_accuracy: 0.6350 - val_categorical_accuracy: 0.6350 - lr: 8.6593e-05\n",
      "Epoch 77/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 0.9965 - accuracy: 0.6413 - categorical_accuracy: 0.6413\n",
      "Epoch 77: val_accuracy improved from 0.63504 to 0.63522, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9964 - accuracy: 0.6413 - categorical_accuracy: 0.6413 - val_loss: 1.0105 - val_accuracy: 0.6352 - val_categorical_accuracy: 0.6352 - lr: 8.6593e-05\n",
      "Epoch 78/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 0.9963 - accuracy: 0.6413 - categorical_accuracy: 0.6413\n",
      "Epoch 78: val_accuracy improved from 0.63522 to 0.63601, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9961 - accuracy: 0.6414 - categorical_accuracy: 0.6414 - val_loss: 1.0092 - val_accuracy: 0.6360 - val_categorical_accuracy: 0.6360 - lr: 8.6593e-05\n",
      "Epoch 79/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 0.9957 - accuracy: 0.6417 - categorical_accuracy: 0.6417\n",
      "Epoch 79: val_accuracy did not improve from 0.63601\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9957 - accuracy: 0.6417 - categorical_accuracy: 0.6417 - val_loss: 1.0098 - val_accuracy: 0.6355 - val_categorical_accuracy: 0.6355 - lr: 8.6593e-05\n",
      "Epoch 80/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 0.9951 - accuracy: 0.6415 - categorical_accuracy: 0.6415\n",
      "Epoch 80: val_accuracy improved from 0.63601 to 0.63617, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 916us/step - loss: 0.9951 - accuracy: 0.6415 - categorical_accuracy: 0.6415 - val_loss: 1.0090 - val_accuracy: 0.6362 - val_categorical_accuracy: 0.6362 - lr: 8.6593e-05\n",
      "Epoch 81/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9946 - accuracy: 0.6422 - categorical_accuracy: 0.6422\n",
      "Epoch 81: val_accuracy did not improve from 0.63617\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9947 - accuracy: 0.6422 - categorical_accuracy: 0.6422 - val_loss: 1.0083 - val_accuracy: 0.6348 - val_categorical_accuracy: 0.6348 - lr: 8.6593e-05\n",
      "Epoch 82/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 0.9942 - accuracy: 0.6425 - categorical_accuracy: 0.6425\n",
      "Epoch 82: val_accuracy did not improve from 0.63617\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9942 - accuracy: 0.6425 - categorical_accuracy: 0.6425 - val_loss: 1.0114 - val_accuracy: 0.6329 - val_categorical_accuracy: 0.6329 - lr: 8.6593e-05\n",
      "Epoch 83/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9936 - accuracy: 0.6424 - categorical_accuracy: 0.6424\n",
      "Epoch 83: val_accuracy did not improve from 0.63617\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9936 - accuracy: 0.6424 - categorical_accuracy: 0.6424 - val_loss: 1.0071 - val_accuracy: 0.6359 - val_categorical_accuracy: 0.6359 - lr: 8.6593e-05\n",
      "Epoch 84/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 0.9927 - accuracy: 0.6428 - categorical_accuracy: 0.6428\n",
      "Epoch 84: val_accuracy did not improve from 0.63617\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9928 - accuracy: 0.6428 - categorical_accuracy: 0.6428 - val_loss: 1.0081 - val_accuracy: 0.6357 - val_categorical_accuracy: 0.6357 - lr: 8.6593e-05\n",
      "Epoch 85/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9924 - accuracy: 0.6434 - categorical_accuracy: 0.6434\n",
      "Epoch 85: val_accuracy improved from 0.63617 to 0.63744, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9926 - accuracy: 0.6432 - categorical_accuracy: 0.6432 - val_loss: 1.0059 - val_accuracy: 0.6374 - val_categorical_accuracy: 0.6374 - lr: 8.6593e-05\n",
      "Epoch 86/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 0.9917 - accuracy: 0.6437 - categorical_accuracy: 0.6437\n",
      "Epoch 86: val_accuracy did not improve from 0.63744\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9917 - accuracy: 0.6437 - categorical_accuracy: 0.6437 - val_loss: 1.0062 - val_accuracy: 0.6367 - val_categorical_accuracy: 0.6367 - lr: 8.6593e-05\n",
      "Epoch 87/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 0.9912 - accuracy: 0.6437 - categorical_accuracy: 0.6437\n",
      "Epoch 87: val_accuracy did not improve from 0.63744\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9913 - accuracy: 0.6437 - categorical_accuracy: 0.6437 - val_loss: 1.0058 - val_accuracy: 0.6361 - val_categorical_accuracy: 0.6361 - lr: 8.6593e-05\n",
      "Epoch 88/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9910 - accuracy: 0.6440 - categorical_accuracy: 0.6440\n",
      "Epoch 88: val_accuracy did not improve from 0.63744\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9910 - accuracy: 0.6440 - categorical_accuracy: 0.6440 - val_loss: 1.0054 - val_accuracy: 0.6365 - val_categorical_accuracy: 0.6365 - lr: 8.6593e-05\n",
      "Epoch 89/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9904 - accuracy: 0.6443 - categorical_accuracy: 0.6443\n",
      "Epoch 89: val_accuracy improved from 0.63744 to 0.63859, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9905 - accuracy: 0.6443 - categorical_accuracy: 0.6443 - val_loss: 1.0050 - val_accuracy: 0.6386 - val_categorical_accuracy: 0.6386 - lr: 8.6593e-05\n",
      "Epoch 90/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 0.9898 - accuracy: 0.6443 - categorical_accuracy: 0.6443\n",
      "Epoch 90: val_accuracy did not improve from 0.63859\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9898 - accuracy: 0.6443 - categorical_accuracy: 0.6443 - val_loss: 1.0052 - val_accuracy: 0.6380 - val_categorical_accuracy: 0.6380 - lr: 8.6593e-05\n",
      "Epoch 91/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9897 - accuracy: 0.6448 - categorical_accuracy: 0.6448\n",
      "Epoch 91: val_accuracy did not improve from 0.63859\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9897 - accuracy: 0.6448 - categorical_accuracy: 0.6448 - val_loss: 1.0085 - val_accuracy: 0.6348 - val_categorical_accuracy: 0.6348 - lr: 8.6593e-05\n",
      "Epoch 92/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 0.9894 - accuracy: 0.6451 - categorical_accuracy: 0.6451\n",
      "Epoch 92: val_accuracy improved from 0.63859 to 0.63892, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9894 - accuracy: 0.6451 - categorical_accuracy: 0.6451 - val_loss: 1.0044 - val_accuracy: 0.6389 - val_categorical_accuracy: 0.6389 - lr: 8.6593e-05\n",
      "Epoch 93/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 0.9889 - accuracy: 0.6451 - categorical_accuracy: 0.6451\n",
      "Epoch 93: val_accuracy did not improve from 0.63892\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9889 - accuracy: 0.6451 - categorical_accuracy: 0.6451 - val_loss: 1.0066 - val_accuracy: 0.6364 - val_categorical_accuracy: 0.6364 - lr: 8.6593e-05\n",
      "Epoch 94/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9885 - accuracy: 0.6454 - categorical_accuracy: 0.6454\n",
      "Epoch 94: val_accuracy improved from 0.63892 to 0.63967, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 0.9884 - accuracy: 0.6454 - categorical_accuracy: 0.6454 - val_loss: 1.0030 - val_accuracy: 0.6397 - val_categorical_accuracy: 0.6397 - lr: 8.6593e-05\n",
      "Epoch 95/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9878 - accuracy: 0.6458 - categorical_accuracy: 0.6458\n",
      "Epoch 95: val_accuracy did not improve from 0.63967\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9878 - accuracy: 0.6459 - categorical_accuracy: 0.6459 - val_loss: 1.0052 - val_accuracy: 0.6386 - val_categorical_accuracy: 0.6386 - lr: 8.6593e-05\n",
      "Epoch 96/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9873 - accuracy: 0.6463 - categorical_accuracy: 0.6463\n",
      "Epoch 96: val_accuracy did not improve from 0.63967\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9873 - accuracy: 0.6463 - categorical_accuracy: 0.6463 - val_loss: 1.0020 - val_accuracy: 0.6395 - val_categorical_accuracy: 0.6395 - lr: 8.6593e-05\n",
      "Epoch 97/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 0.9870 - accuracy: 0.6460 - categorical_accuracy: 0.6460\n",
      "Epoch 97: val_accuracy did not improve from 0.63967\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9870 - accuracy: 0.6460 - categorical_accuracy: 0.6460 - val_loss: 1.0032 - val_accuracy: 0.6382 - val_categorical_accuracy: 0.6382 - lr: 8.6593e-05\n",
      "Epoch 98/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9870 - accuracy: 0.6463 - categorical_accuracy: 0.6463\n",
      "Epoch 98: val_accuracy improved from 0.63967 to 0.64020, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9869 - accuracy: 0.6463 - categorical_accuracy: 0.6463 - val_loss: 1.0008 - val_accuracy: 0.6402 - val_categorical_accuracy: 0.6402 - lr: 8.6593e-05\n",
      "Epoch 99/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9865 - accuracy: 0.6464 - categorical_accuracy: 0.6464\n",
      "Epoch 99: val_accuracy improved from 0.64020 to 0.64071, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9864 - accuracy: 0.6465 - categorical_accuracy: 0.6465 - val_loss: 1.0006 - val_accuracy: 0.6407 - val_categorical_accuracy: 0.6407 - lr: 8.6593e-05\n",
      "Epoch 100/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9861 - accuracy: 0.6464 - categorical_accuracy: 0.6464\n",
      "Epoch 100: val_accuracy improved from 0.64071 to 0.64090, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9861 - accuracy: 0.6464 - categorical_accuracy: 0.6464 - val_loss: 1.0004 - val_accuracy: 0.6409 - val_categorical_accuracy: 0.6409 - lr: 8.6593e-05\n",
      "Epoch 101/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9857 - accuracy: 0.6465 - categorical_accuracy: 0.6465\n",
      "Epoch 101: val_accuracy did not improve from 0.64090\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9859 - accuracy: 0.6464 - categorical_accuracy: 0.6464 - val_loss: 0.9997 - val_accuracy: 0.6400 - val_categorical_accuracy: 0.6400 - lr: 8.6593e-05\n",
      "Epoch 102/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 0.9856 - accuracy: 0.6468 - categorical_accuracy: 0.6468\n",
      "Epoch 102: val_accuracy did not improve from 0.64090\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9857 - accuracy: 0.6468 - categorical_accuracy: 0.6468 - val_loss: 0.9999 - val_accuracy: 0.6404 - val_categorical_accuracy: 0.6404 - lr: 8.6593e-05\n",
      "Epoch 103/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 0.9852 - accuracy: 0.6470 - categorical_accuracy: 0.6470\n",
      "Epoch 103: val_accuracy did not improve from 0.64090\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9851 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 1.0055 - val_accuracy: 0.6365 - val_categorical_accuracy: 0.6365 - lr: 8.6593e-05\n",
      "Epoch 104/200\n",
      "7459/7514 [============================>.] - ETA: 0s - loss: 0.9843 - accuracy: 0.6477 - categorical_accuracy: 0.6477\n",
      "Epoch 104: val_accuracy did not improve from 0.64090\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9844 - accuracy: 0.6477 - categorical_accuracy: 0.6477 - val_loss: 0.9988 - val_accuracy: 0.6409 - val_categorical_accuracy: 0.6409 - lr: 8.6593e-05\n",
      "Epoch 105/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 0.9841 - accuracy: 0.6475 - categorical_accuracy: 0.6475\n",
      "Epoch 105: val_accuracy improved from 0.64090 to 0.64103, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 0.9841 - accuracy: 0.6475 - categorical_accuracy: 0.6475 - val_loss: 0.9985 - val_accuracy: 0.6410 - val_categorical_accuracy: 0.6410 - lr: 8.6593e-05\n",
      "Epoch 106/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 0.9835 - accuracy: 0.6485 - categorical_accuracy: 0.6485\n",
      "Epoch 106: val_accuracy improved from 0.64103 to 0.64198, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9836 - accuracy: 0.6484 - categorical_accuracy: 0.6484 - val_loss: 0.9973 - val_accuracy: 0.6420 - val_categorical_accuracy: 0.6420 - lr: 8.6593e-05\n",
      "Epoch 107/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9831 - accuracy: 0.6484 - categorical_accuracy: 0.6484\n",
      "Epoch 107: val_accuracy did not improve from 0.64198\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9832 - accuracy: 0.6483 - categorical_accuracy: 0.6483 - val_loss: 0.9995 - val_accuracy: 0.6407 - val_categorical_accuracy: 0.6407 - lr: 8.6593e-05\n",
      "Epoch 108/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9828 - accuracy: 0.6485 - categorical_accuracy: 0.6485\n",
      "Epoch 108: val_accuracy did not improve from 0.64198\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9829 - accuracy: 0.6484 - categorical_accuracy: 0.6484 - val_loss: 0.9970 - val_accuracy: 0.6420 - val_categorical_accuracy: 0.6420 - lr: 8.6593e-05\n",
      "Epoch 109/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9825 - accuracy: 0.6487 - categorical_accuracy: 0.6487\n",
      "Epoch 109: val_accuracy improved from 0.64198 to 0.64231, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9824 - accuracy: 0.6488 - categorical_accuracy: 0.6488 - val_loss: 0.9966 - val_accuracy: 0.6423 - val_categorical_accuracy: 0.6423 - lr: 8.6593e-05\n",
      "Epoch 110/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 0.9819 - accuracy: 0.6488 - categorical_accuracy: 0.6488\n",
      "Epoch 110: val_accuracy did not improve from 0.64231\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9820 - accuracy: 0.6488 - categorical_accuracy: 0.6488 - val_loss: 0.9976 - val_accuracy: 0.6414 - val_categorical_accuracy: 0.6414 - lr: 8.6593e-05\n",
      "Epoch 111/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9819 - accuracy: 0.6487 - categorical_accuracy: 0.6487\n",
      "Epoch 111: val_accuracy did not improve from 0.64231\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9818 - accuracy: 0.6488 - categorical_accuracy: 0.6488 - val_loss: 0.9969 - val_accuracy: 0.6416 - val_categorical_accuracy: 0.6416 - lr: 8.6593e-05\n",
      "Epoch 112/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 0.9819 - accuracy: 0.6490 - categorical_accuracy: 0.6490\n",
      "Epoch 112: val_accuracy improved from 0.64231 to 0.64237, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9818 - accuracy: 0.6490 - categorical_accuracy: 0.6490 - val_loss: 0.9969 - val_accuracy: 0.6424 - val_categorical_accuracy: 0.6424 - lr: 8.6593e-05\n",
      "Epoch 113/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9814 - accuracy: 0.6493 - categorical_accuracy: 0.6493\n",
      "Epoch 113: val_accuracy improved from 0.64237 to 0.64243, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 912us/step - loss: 0.9814 - accuracy: 0.6493 - categorical_accuracy: 0.6493 - val_loss: 0.9948 - val_accuracy: 0.6424 - val_categorical_accuracy: 0.6424 - lr: 8.6593e-05\n",
      "Epoch 114/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9807 - accuracy: 0.6492 - categorical_accuracy: 0.6492\n",
      "Epoch 114: val_accuracy improved from 0.64243 to 0.64253, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9809 - accuracy: 0.6491 - categorical_accuracy: 0.6491 - val_loss: 0.9950 - val_accuracy: 0.6425 - val_categorical_accuracy: 0.6425 - lr: 8.6593e-05\n",
      "Epoch 115/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9807 - accuracy: 0.6491 - categorical_accuracy: 0.6491\n",
      "Epoch 115: val_accuracy did not improve from 0.64253\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9806 - accuracy: 0.6491 - categorical_accuracy: 0.6491 - val_loss: 0.9962 - val_accuracy: 0.6424 - val_categorical_accuracy: 0.6424 - lr: 8.6593e-05\n",
      "Epoch 116/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9801 - accuracy: 0.6498 - categorical_accuracy: 0.6498\n",
      "Epoch 116: val_accuracy did not improve from 0.64253\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9802 - accuracy: 0.6498 - categorical_accuracy: 0.6498 - val_loss: 0.9971 - val_accuracy: 0.6410 - val_categorical_accuracy: 0.6410 - lr: 8.6593e-05\n",
      "Epoch 117/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9797 - accuracy: 0.6497 - categorical_accuracy: 0.6497\n",
      "Epoch 117: val_accuracy did not improve from 0.64253\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9797 - accuracy: 0.6497 - categorical_accuracy: 0.6497 - val_loss: 0.9964 - val_accuracy: 0.6413 - val_categorical_accuracy: 0.6413 - lr: 8.6593e-05\n",
      "Epoch 118/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9796 - accuracy: 0.6502 - categorical_accuracy: 0.6502\n",
      "Epoch 118: val_accuracy improved from 0.64253 to 0.64321, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9797 - accuracy: 0.6501 - categorical_accuracy: 0.6501 - val_loss: 0.9954 - val_accuracy: 0.6432 - val_categorical_accuracy: 0.6432 - lr: 8.6593e-05\n",
      "Epoch 119/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9791 - accuracy: 0.6505 - categorical_accuracy: 0.6505\n",
      "Epoch 119: val_accuracy did not improve from 0.64321\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9793 - accuracy: 0.6504 - categorical_accuracy: 0.6504 - val_loss: 0.9989 - val_accuracy: 0.6407 - val_categorical_accuracy: 0.6407 - lr: 8.6593e-05\n",
      "Epoch 120/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 0.9790 - accuracy: 0.6501 - categorical_accuracy: 0.6501\n",
      "Epoch 120: val_accuracy did not improve from 0.64321\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9789 - accuracy: 0.6502 - categorical_accuracy: 0.6502 - val_loss: 0.9969 - val_accuracy: 0.6411 - val_categorical_accuracy: 0.6411 - lr: 8.6593e-05\n",
      "Epoch 121/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 0.9789 - accuracy: 0.6500 - categorical_accuracy: 0.6500\n",
      "Epoch 121: val_accuracy did not improve from 0.64321\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9788 - accuracy: 0.6501 - categorical_accuracy: 0.6501 - val_loss: 0.9934 - val_accuracy: 0.6431 - val_categorical_accuracy: 0.6431 - lr: 8.6593e-05\n",
      "Epoch 122/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 0.9783 - accuracy: 0.6506 - categorical_accuracy: 0.6506\n",
      "Epoch 122: val_accuracy improved from 0.64321 to 0.64456, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9784 - accuracy: 0.6505 - categorical_accuracy: 0.6505 - val_loss: 0.9930 - val_accuracy: 0.6446 - val_categorical_accuracy: 0.6446 - lr: 8.6593e-05\n",
      "Epoch 123/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9782 - accuracy: 0.6507 - categorical_accuracy: 0.6507\n",
      "Epoch 123: val_accuracy did not improve from 0.64456\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9783 - accuracy: 0.6507 - categorical_accuracy: 0.6507 - val_loss: 0.9952 - val_accuracy: 0.6420 - val_categorical_accuracy: 0.6420 - lr: 8.6593e-05\n",
      "Epoch 124/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 0.9778 - accuracy: 0.6510 - categorical_accuracy: 0.6510\n",
      "Epoch 124: val_accuracy did not improve from 0.64456\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9778 - accuracy: 0.6509 - categorical_accuracy: 0.6509 - val_loss: 0.9951 - val_accuracy: 0.6430 - val_categorical_accuracy: 0.6430 - lr: 8.6593e-05\n",
      "Epoch 125/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 0.9775 - accuracy: 0.6512 - categorical_accuracy: 0.6512\n",
      "Epoch 125: val_accuracy improved from 0.64456 to 0.64464, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9775 - accuracy: 0.6512 - categorical_accuracy: 0.6512 - val_loss: 0.9924 - val_accuracy: 0.6446 - val_categorical_accuracy: 0.6446 - lr: 8.6593e-05\n",
      "Epoch 126/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9773 - accuracy: 0.6514 - categorical_accuracy: 0.6514\n",
      "Epoch 126: val_accuracy did not improve from 0.64464\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9774 - accuracy: 0.6513 - categorical_accuracy: 0.6513 - val_loss: 0.9928 - val_accuracy: 0.6435 - val_categorical_accuracy: 0.6435 - lr: 8.6593e-05\n",
      "Epoch 127/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 0.9774 - accuracy: 0.6504 - categorical_accuracy: 0.6504\n",
      "Epoch 127: val_accuracy did not improve from 0.64464\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9772 - accuracy: 0.6505 - categorical_accuracy: 0.6505 - val_loss: 0.9926 - val_accuracy: 0.6438 - val_categorical_accuracy: 0.6438 - lr: 8.6593e-05\n",
      "Epoch 128/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 0.9766 - accuracy: 0.6513 - categorical_accuracy: 0.6513\n",
      "Epoch 128: val_accuracy improved from 0.64464 to 0.64468, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9768 - accuracy: 0.6512 - categorical_accuracy: 0.6512 - val_loss: 0.9921 - val_accuracy: 0.6447 - val_categorical_accuracy: 0.6447 - lr: 8.6593e-05\n",
      "Epoch 129/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9765 - accuracy: 0.6514 - categorical_accuracy: 0.6514\n",
      "Epoch 129: val_accuracy improved from 0.64468 to 0.64534, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9765 - accuracy: 0.6514 - categorical_accuracy: 0.6514 - val_loss: 0.9904 - val_accuracy: 0.6453 - val_categorical_accuracy: 0.6453 - lr: 8.6593e-05\n",
      "Epoch 130/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 0.9760 - accuracy: 0.6515 - categorical_accuracy: 0.6515\n",
      "Epoch 130: val_accuracy did not improve from 0.64534\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9759 - accuracy: 0.6516 - categorical_accuracy: 0.6516 - val_loss: 0.9940 - val_accuracy: 0.6430 - val_categorical_accuracy: 0.6430 - lr: 8.6593e-05\n",
      "Epoch 131/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9755 - accuracy: 0.6521 - categorical_accuracy: 0.6521\n",
      "Epoch 131: val_accuracy did not improve from 0.64534\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 0.9754 - accuracy: 0.6522 - categorical_accuracy: 0.6522 - val_loss: 0.9898 - val_accuracy: 0.6451 - val_categorical_accuracy: 0.6451 - lr: 8.6593e-05\n",
      "Epoch 132/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9754 - accuracy: 0.6516 - categorical_accuracy: 0.6516\n",
      "Epoch 132: val_accuracy did not improve from 0.64534\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9755 - accuracy: 0.6515 - categorical_accuracy: 0.6515 - val_loss: 0.9903 - val_accuracy: 0.6453 - val_categorical_accuracy: 0.6453 - lr: 8.6593e-05\n",
      "Epoch 133/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9752 - accuracy: 0.6518 - categorical_accuracy: 0.6518\n",
      "Epoch 133: val_accuracy did not improve from 0.64534\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9753 - accuracy: 0.6517 - categorical_accuracy: 0.6517 - val_loss: 0.9951 - val_accuracy: 0.6417 - val_categorical_accuracy: 0.6417 - lr: 8.6593e-05\n",
      "Epoch 134/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9748 - accuracy: 0.6521 - categorical_accuracy: 0.6521\n",
      "Epoch 134: val_accuracy improved from 0.64534 to 0.64584, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9749 - accuracy: 0.6520 - categorical_accuracy: 0.6520 - val_loss: 0.9911 - val_accuracy: 0.6458 - val_categorical_accuracy: 0.6458 - lr: 8.6593e-05\n",
      "Epoch 135/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 0.9750 - accuracy: 0.6522 - categorical_accuracy: 0.6522\n",
      "Epoch 135: val_accuracy did not improve from 0.64584\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 0.9750 - accuracy: 0.6522 - categorical_accuracy: 0.6522 - val_loss: 0.9907 - val_accuracy: 0.6455 - val_categorical_accuracy: 0.6455 - lr: 8.6593e-05\n",
      "Epoch 136/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9742 - accuracy: 0.6526 - categorical_accuracy: 0.6526\n",
      "Epoch 136: val_accuracy did not improve from 0.64584\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9743 - accuracy: 0.6525 - categorical_accuracy: 0.6525 - val_loss: 0.9917 - val_accuracy: 0.6454 - val_categorical_accuracy: 0.6454 - lr: 8.6593e-05\n",
      "Epoch 137/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9741 - accuracy: 0.6525 - categorical_accuracy: 0.6525\n",
      "Epoch 137: val_accuracy did not improve from 0.64584\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 0.9740 - accuracy: 0.6525 - categorical_accuracy: 0.6525 - val_loss: 0.9893 - val_accuracy: 0.6458 - val_categorical_accuracy: 0.6458 - lr: 8.6593e-05\n",
      "Epoch 138/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 0.9739 - accuracy: 0.6526 - categorical_accuracy: 0.6526\n",
      "Epoch 138: val_accuracy did not improve from 0.64584\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9740 - accuracy: 0.6526 - categorical_accuracy: 0.6526 - val_loss: 0.9899 - val_accuracy: 0.6453 - val_categorical_accuracy: 0.6453 - lr: 8.6593e-05\n",
      "Epoch 139/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9734 - accuracy: 0.6524 - categorical_accuracy: 0.6524\n",
      "Epoch 139: val_accuracy did not improve from 0.64584\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9734 - accuracy: 0.6523 - categorical_accuracy: 0.6523 - val_loss: 0.9913 - val_accuracy: 0.6437 - val_categorical_accuracy: 0.6437 - lr: 8.6593e-05\n",
      "Epoch 140/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9733 - accuracy: 0.6530 - categorical_accuracy: 0.6530\n",
      "Epoch 140: val_accuracy improved from 0.64584 to 0.64662, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9733 - accuracy: 0.6530 - categorical_accuracy: 0.6530 - val_loss: 0.9881 - val_accuracy: 0.6466 - val_categorical_accuracy: 0.6466 - lr: 8.6593e-05\n",
      "Epoch 141/200\n",
      "7459/7514 [============================>.] - ETA: 0s - loss: 0.9730 - accuracy: 0.6528 - categorical_accuracy: 0.6528\n",
      "Epoch 141: val_accuracy did not improve from 0.64662\n",
      "7514/7514 [==============================] - 7s 934us/step - loss: 0.9730 - accuracy: 0.6528 - categorical_accuracy: 0.6528 - val_loss: 0.9891 - val_accuracy: 0.6460 - val_categorical_accuracy: 0.6460 - lr: 8.6593e-05\n",
      "Epoch 142/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9728 - accuracy: 0.6531 - categorical_accuracy: 0.6531\n",
      "Epoch 142: val_accuracy did not improve from 0.64662\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9728 - accuracy: 0.6531 - categorical_accuracy: 0.6531 - val_loss: 0.9885 - val_accuracy: 0.6464 - val_categorical_accuracy: 0.6464 - lr: 8.6593e-05\n",
      "Epoch 143/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9729 - accuracy: 0.6532 - categorical_accuracy: 0.6532\n",
      "Epoch 143: val_accuracy improved from 0.64662 to 0.64664, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9728 - accuracy: 0.6532 - categorical_accuracy: 0.6532 - val_loss: 0.9875 - val_accuracy: 0.6466 - val_categorical_accuracy: 0.6466 - lr: 8.6593e-05\n",
      "Epoch 144/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9724 - accuracy: 0.6533 - categorical_accuracy: 0.6533\n",
      "Epoch 144: val_accuracy did not improve from 0.64664\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9724 - accuracy: 0.6533 - categorical_accuracy: 0.6533 - val_loss: 0.9885 - val_accuracy: 0.6465 - val_categorical_accuracy: 0.6465 - lr: 8.6593e-05\n",
      "Epoch 145/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.6536 - categorical_accuracy: 0.6536\n",
      "Epoch 145: val_accuracy did not improve from 0.64664\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9719 - accuracy: 0.6536 - categorical_accuracy: 0.6536 - val_loss: 0.9876 - val_accuracy: 0.6457 - val_categorical_accuracy: 0.6457 - lr: 8.6593e-05\n",
      "Epoch 146/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9717 - accuracy: 0.6534 - categorical_accuracy: 0.6534\n",
      "Epoch 146: val_accuracy improved from 0.64664 to 0.64684, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9717 - accuracy: 0.6534 - categorical_accuracy: 0.6534 - val_loss: 0.9868 - val_accuracy: 0.6468 - val_categorical_accuracy: 0.6468 - lr: 8.6593e-05\n",
      "Epoch 147/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9714 - accuracy: 0.6539 - categorical_accuracy: 0.6539\n",
      "Epoch 147: val_accuracy did not improve from 0.64684\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9715 - accuracy: 0.6539 - categorical_accuracy: 0.6539 - val_loss: 0.9872 - val_accuracy: 0.6459 - val_categorical_accuracy: 0.6459 - lr: 8.6593e-05\n",
      "Epoch 148/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 0.9710 - accuracy: 0.6538 - categorical_accuracy: 0.6538\n",
      "Epoch 148: val_accuracy improved from 0.64684 to 0.64782, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9710 - accuracy: 0.6538 - categorical_accuracy: 0.6538 - val_loss: 0.9854 - val_accuracy: 0.6478 - val_categorical_accuracy: 0.6478 - lr: 8.6593e-05\n",
      "Epoch 149/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9711 - accuracy: 0.6540 - categorical_accuracy: 0.6540\n",
      "Epoch 149: val_accuracy did not improve from 0.64782\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9713 - accuracy: 0.6539 - categorical_accuracy: 0.6539 - val_loss: 0.9858 - val_accuracy: 0.6475 - val_categorical_accuracy: 0.6475 - lr: 8.6593e-05\n",
      "Epoch 150/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 0.9706 - accuracy: 0.6543 - categorical_accuracy: 0.6543\n",
      "Epoch 150: val_accuracy improved from 0.64782 to 0.64792, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9707 - accuracy: 0.6542 - categorical_accuracy: 0.6542 - val_loss: 0.9855 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479 - lr: 8.6593e-05\n",
      "Epoch 151/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9703 - accuracy: 0.6540 - categorical_accuracy: 0.6540\n",
      "Epoch 151: val_accuracy did not improve from 0.64792\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9703 - accuracy: 0.6540 - categorical_accuracy: 0.6540 - val_loss: 0.9860 - val_accuracy: 0.6475 - val_categorical_accuracy: 0.6475 - lr: 8.6593e-05\n",
      "Epoch 152/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9701 - accuracy: 0.6547 - categorical_accuracy: 0.6547\n",
      "Epoch 152: val_accuracy did not improve from 0.64792\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9700 - accuracy: 0.6547 - categorical_accuracy: 0.6547 - val_loss: 0.9854 - val_accuracy: 0.6478 - val_categorical_accuracy: 0.6478 - lr: 8.6593e-05\n",
      "Epoch 153/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9699 - accuracy: 0.6543 - categorical_accuracy: 0.6543\n",
      "Epoch 153: val_accuracy improved from 0.64792 to 0.64880, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9699 - accuracy: 0.6543 - categorical_accuracy: 0.6543 - val_loss: 0.9839 - val_accuracy: 0.6488 - val_categorical_accuracy: 0.6488 - lr: 8.6593e-05\n",
      "Epoch 154/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6546 - categorical_accuracy: 0.6546\n",
      "Epoch 154: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9691 - accuracy: 0.6547 - categorical_accuracy: 0.6547 - val_loss: 0.9871 - val_accuracy: 0.6475 - val_categorical_accuracy: 0.6475 - lr: 8.6593e-05\n",
      "Epoch 155/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9695 - accuracy: 0.6544 - categorical_accuracy: 0.6544\n",
      "Epoch 155: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9696 - accuracy: 0.6543 - categorical_accuracy: 0.6543 - val_loss: 0.9860 - val_accuracy: 0.6468 - val_categorical_accuracy: 0.6468 - lr: 8.6593e-05\n",
      "Epoch 156/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9692 - accuracy: 0.6548 - categorical_accuracy: 0.6548\n",
      "Epoch 156: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9694 - accuracy: 0.6547 - categorical_accuracy: 0.6547 - val_loss: 0.9850 - val_accuracy: 0.6470 - val_categorical_accuracy: 0.6470 - lr: 8.6593e-05\n",
      "Epoch 157/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9693 - accuracy: 0.6543 - categorical_accuracy: 0.6543\n",
      "Epoch 157: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9693 - accuracy: 0.6543 - categorical_accuracy: 0.6543 - val_loss: 0.9897 - val_accuracy: 0.6447 - val_categorical_accuracy: 0.6447 - lr: 8.6593e-05\n",
      "Epoch 158/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6549 - categorical_accuracy: 0.6549\n",
      "Epoch 158: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9691 - accuracy: 0.6550 - categorical_accuracy: 0.6550 - val_loss: 0.9848 - val_accuracy: 0.6464 - val_categorical_accuracy: 0.6464 - lr: 8.6593e-05\n",
      "Epoch 159/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9686 - accuracy: 0.6554 - categorical_accuracy: 0.6554\n",
      "Epoch 159: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9687 - accuracy: 0.6553 - categorical_accuracy: 0.6553 - val_loss: 0.9846 - val_accuracy: 0.6465 - val_categorical_accuracy: 0.6465 - lr: 8.6593e-05\n",
      "Epoch 160/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9685 - accuracy: 0.6551 - categorical_accuracy: 0.6551\n",
      "Epoch 160: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9686 - accuracy: 0.6551 - categorical_accuracy: 0.6551 - val_loss: 0.9842 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 161/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 0.9681 - accuracy: 0.6551 - categorical_accuracy: 0.6551\n",
      "Epoch 161: val_accuracy did not improve from 0.64880\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9682 - accuracy: 0.6550 - categorical_accuracy: 0.6550 - val_loss: 0.9843 - val_accuracy: 0.6478 - val_categorical_accuracy: 0.6478 - lr: 8.6593e-05\n",
      "Epoch 162/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9682 - accuracy: 0.6553 - categorical_accuracy: 0.6553\n",
      "Epoch 162: val_accuracy improved from 0.64880 to 0.64959, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9682 - accuracy: 0.6554 - categorical_accuracy: 0.6554 - val_loss: 0.9827 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496 - lr: 8.6593e-05\n",
      "Epoch 163/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9674 - accuracy: 0.6554 - categorical_accuracy: 0.6554\n",
      "Epoch 163: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9677 - accuracy: 0.6552 - categorical_accuracy: 0.6552 - val_loss: 0.9846 - val_accuracy: 0.6480 - val_categorical_accuracy: 0.6480 - lr: 8.6593e-05\n",
      "Epoch 164/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9676 - accuracy: 0.6557 - categorical_accuracy: 0.6557\n",
      "Epoch 164: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9676 - accuracy: 0.6557 - categorical_accuracy: 0.6557 - val_loss: 0.9835 - val_accuracy: 0.6488 - val_categorical_accuracy: 0.6488 - lr: 8.6593e-05\n",
      "Epoch 165/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.6550 - categorical_accuracy: 0.6550\n",
      "Epoch 165: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9680 - accuracy: 0.6550 - categorical_accuracy: 0.6550 - val_loss: 0.9843 - val_accuracy: 0.6486 - val_categorical_accuracy: 0.6486 - lr: 8.6593e-05\n",
      "Epoch 166/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 0.9677 - accuracy: 0.6557 - categorical_accuracy: 0.6557\n",
      "Epoch 166: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9677 - accuracy: 0.6557 - categorical_accuracy: 0.6557 - val_loss: 0.9823 - val_accuracy: 0.6490 - val_categorical_accuracy: 0.6490 - lr: 8.6593e-05\n",
      "Epoch 167/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 0.9673 - accuracy: 0.6558 - categorical_accuracy: 0.6558\n",
      "Epoch 167: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9674 - accuracy: 0.6557 - categorical_accuracy: 0.6557 - val_loss: 0.9823 - val_accuracy: 0.6484 - val_categorical_accuracy: 0.6484 - lr: 8.6593e-05\n",
      "Epoch 168/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 0.9673 - accuracy: 0.6556 - categorical_accuracy: 0.6556\n",
      "Epoch 168: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 0.9673 - accuracy: 0.6555 - categorical_accuracy: 0.6555 - val_loss: 0.9815 - val_accuracy: 0.6494 - val_categorical_accuracy: 0.6494 - lr: 8.6593e-05\n",
      "Epoch 169/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 0.9670 - accuracy: 0.6559 - categorical_accuracy: 0.6559\n",
      "Epoch 169: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9670 - accuracy: 0.6558 - categorical_accuracy: 0.6558 - val_loss: 0.9816 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 170/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 0.9666 - accuracy: 0.6562 - categorical_accuracy: 0.6562\n",
      "Epoch 170: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9667 - accuracy: 0.6562 - categorical_accuracy: 0.6562 - val_loss: 0.9844 - val_accuracy: 0.6477 - val_categorical_accuracy: 0.6477 - lr: 8.6593e-05\n",
      "Epoch 171/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 0.9670 - accuracy: 0.6560 - categorical_accuracy: 0.6560\n",
      "Epoch 171: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9671 - accuracy: 0.6559 - categorical_accuracy: 0.6559 - val_loss: 0.9828 - val_accuracy: 0.6483 - val_categorical_accuracy: 0.6483 - lr: 8.6593e-05\n",
      "Epoch 172/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9667 - accuracy: 0.6559 - categorical_accuracy: 0.6559\n",
      "Epoch 172: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 0.9667 - accuracy: 0.6559 - categorical_accuracy: 0.6559 - val_loss: 0.9854 - val_accuracy: 0.6463 - val_categorical_accuracy: 0.6463 - lr: 8.6593e-05\n",
      "Epoch 173/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 0.9664 - accuracy: 0.6562 - categorical_accuracy: 0.6562\n",
      "Epoch 173: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9666 - accuracy: 0.6562 - categorical_accuracy: 0.6562 - val_loss: 0.9833 - val_accuracy: 0.6492 - val_categorical_accuracy: 0.6492 - lr: 8.6593e-05\n",
      "Epoch 174/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9665 - accuracy: 0.6561 - categorical_accuracy: 0.6561\n",
      "Epoch 174: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9664 - accuracy: 0.6561 - categorical_accuracy: 0.6561 - val_loss: 0.9822 - val_accuracy: 0.6478 - val_categorical_accuracy: 0.6478 - lr: 8.6593e-05\n",
      "Epoch 175/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9662 - accuracy: 0.6561 - categorical_accuracy: 0.6561\n",
      "Epoch 175: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9662 - accuracy: 0.6561 - categorical_accuracy: 0.6561 - val_loss: 0.9832 - val_accuracy: 0.6480 - val_categorical_accuracy: 0.6480 - lr: 8.6593e-05\n",
      "Epoch 176/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9657 - accuracy: 0.6565 - categorical_accuracy: 0.6565\n",
      "Epoch 176: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9658 - accuracy: 0.6564 - categorical_accuracy: 0.6564 - val_loss: 0.9839 - val_accuracy: 0.6478 - val_categorical_accuracy: 0.6478 - lr: 8.6593e-05\n",
      "Epoch 177/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9658 - accuracy: 0.6563 - categorical_accuracy: 0.6563\n",
      "Epoch 177: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9658 - accuracy: 0.6563 - categorical_accuracy: 0.6563 - val_loss: 0.9863 - val_accuracy: 0.6455 - val_categorical_accuracy: 0.6455 - lr: 8.6593e-05\n",
      "Epoch 178/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9657 - accuracy: 0.6561 - categorical_accuracy: 0.6561\n",
      "Epoch 178: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 0.9657 - accuracy: 0.6561 - categorical_accuracy: 0.6561 - val_loss: 0.9807 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496 - lr: 8.6593e-05\n",
      "Epoch 179/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9653 - accuracy: 0.6567 - categorical_accuracy: 0.6567\n",
      "Epoch 179: val_accuracy did not improve from 0.64959\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9654 - accuracy: 0.6566 - categorical_accuracy: 0.6566 - val_loss: 0.9804 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 180/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9653 - accuracy: 0.6565 - categorical_accuracy: 0.6565\n",
      "Epoch 180: val_accuracy improved from 0.64959 to 0.65054, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 917us/step - loss: 0.9655 - accuracy: 0.6565 - categorical_accuracy: 0.6565 - val_loss: 0.9811 - val_accuracy: 0.6505 - val_categorical_accuracy: 0.6505 - lr: 8.6593e-05\n",
      "Epoch 181/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9653 - accuracy: 0.6565 - categorical_accuracy: 0.6565\n",
      "Epoch 181: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9652 - accuracy: 0.6565 - categorical_accuracy: 0.6565 - val_loss: 0.9847 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479 - lr: 8.6593e-05\n",
      "Epoch 182/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 0.9655 - accuracy: 0.6568 - categorical_accuracy: 0.6568\n",
      "Epoch 182: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9655 - accuracy: 0.6568 - categorical_accuracy: 0.6568 - val_loss: 0.9828 - val_accuracy: 0.6487 - val_categorical_accuracy: 0.6487 - lr: 8.6593e-05\n",
      "Epoch 183/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9652 - accuracy: 0.6567 - categorical_accuracy: 0.6567\n",
      "Epoch 183: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9650 - accuracy: 0.6568 - categorical_accuracy: 0.6568 - val_loss: 0.9854 - val_accuracy: 0.6460 - val_categorical_accuracy: 0.6460 - lr: 8.6593e-05\n",
      "Epoch 184/200\n",
      "7500/7514 [============================>.] - ETA: 0s - loss: 0.9651 - accuracy: 0.6566 - categorical_accuracy: 0.6566\n",
      "Epoch 184: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9651 - accuracy: 0.6566 - categorical_accuracy: 0.6566 - val_loss: 0.9807 - val_accuracy: 0.6498 - val_categorical_accuracy: 0.6498 - lr: 8.6593e-05\n",
      "Epoch 185/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 0.9648 - accuracy: 0.6567 - categorical_accuracy: 0.6567\n",
      "Epoch 185: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9648 - accuracy: 0.6567 - categorical_accuracy: 0.6567 - val_loss: 0.9795 - val_accuracy: 0.6503 - val_categorical_accuracy: 0.6503 - lr: 8.6593e-05\n",
      "Epoch 186/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9647 - accuracy: 0.6569 - categorical_accuracy: 0.6569\n",
      "Epoch 186: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9647 - accuracy: 0.6569 - categorical_accuracy: 0.6569 - val_loss: 0.9798 - val_accuracy: 0.6494 - val_categorical_accuracy: 0.6494 - lr: 8.6593e-05\n",
      "Epoch 187/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9644 - accuracy: 0.6566 - categorical_accuracy: 0.6566\n",
      "Epoch 187: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9645 - accuracy: 0.6566 - categorical_accuracy: 0.6566 - val_loss: 0.9812 - val_accuracy: 0.6502 - val_categorical_accuracy: 0.6502 - lr: 8.6593e-05\n",
      "Epoch 188/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9648 - accuracy: 0.6571 - categorical_accuracy: 0.6571\n",
      "Epoch 188: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9648 - accuracy: 0.6571 - categorical_accuracy: 0.6571 - val_loss: 0.9816 - val_accuracy: 0.6483 - val_categorical_accuracy: 0.6483 - lr: 8.6593e-05\n",
      "Epoch 189/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9646 - accuracy: 0.6573 - categorical_accuracy: 0.6573\n",
      "Epoch 189: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9646 - accuracy: 0.6573 - categorical_accuracy: 0.6573 - val_loss: 0.9827 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 190/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9645 - accuracy: 0.6571 - categorical_accuracy: 0.6571\n",
      "Epoch 190: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 902us/step - loss: 0.9644 - accuracy: 0.6572 - categorical_accuracy: 0.6572 - val_loss: 0.9807 - val_accuracy: 0.6482 - val_categorical_accuracy: 0.6482 - lr: 8.6593e-05\n",
      "Epoch 191/200\n",
      "7502/7514 [============================>.] - ETA: 0s - loss: 0.9645 - accuracy: 0.6577 - categorical_accuracy: 0.6577\n",
      "Epoch 191: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9645 - accuracy: 0.6577 - categorical_accuracy: 0.6577 - val_loss: 0.9791 - val_accuracy: 0.6505 - val_categorical_accuracy: 0.6505 - lr: 8.6593e-05\n",
      "Epoch 192/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9642 - accuracy: 0.6571 - categorical_accuracy: 0.6571\n",
      "Epoch 192: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9642 - accuracy: 0.6570 - categorical_accuracy: 0.6570 - val_loss: 0.9803 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 193/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9641 - accuracy: 0.6570 - categorical_accuracy: 0.6570\n",
      "Epoch 193: val_accuracy did not improve from 0.65054\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9641 - accuracy: 0.6570 - categorical_accuracy: 0.6570 - val_loss: 0.9793 - val_accuracy: 0.6498 - val_categorical_accuracy: 0.6498 - lr: 8.6593e-05\n",
      "Epoch 194/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9636 - accuracy: 0.6571 - categorical_accuracy: 0.6571\n",
      "Epoch 194: val_accuracy improved from 0.65054 to 0.65055, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9637 - accuracy: 0.6571 - categorical_accuracy: 0.6571 - val_loss: 0.9795 - val_accuracy: 0.6506 - val_categorical_accuracy: 0.6506 - lr: 8.6593e-05\n",
      "Epoch 195/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9636 - accuracy: 0.6577 - categorical_accuracy: 0.6577\n",
      "Epoch 195: val_accuracy did not improve from 0.65055\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9637 - accuracy: 0.6577 - categorical_accuracy: 0.6577 - val_loss: 0.9826 - val_accuracy: 0.6475 - val_categorical_accuracy: 0.6475 - lr: 8.6593e-05\n",
      "Epoch 196/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9638 - accuracy: 0.6574 - categorical_accuracy: 0.6574\n",
      "Epoch 196: val_accuracy did not improve from 0.65055\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9638 - accuracy: 0.6573 - categorical_accuracy: 0.6573 - val_loss: 0.9810 - val_accuracy: 0.6480 - val_categorical_accuracy: 0.6480 - lr: 8.6593e-05\n",
      "Epoch 197/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9637 - accuracy: 0.6576 - categorical_accuracy: 0.6576\n",
      "Epoch 197: val_accuracy did not improve from 0.65055\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9637 - accuracy: 0.6576 - categorical_accuracy: 0.6576 - val_loss: 0.9851 - val_accuracy: 0.6451 - val_categorical_accuracy: 0.6451 - lr: 8.6593e-05\n",
      "Epoch 198/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9637 - accuracy: 0.6568 - categorical_accuracy: 0.6568\n",
      "Epoch 198: val_accuracy did not improve from 0.65055\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9637 - accuracy: 0.6568 - categorical_accuracy: 0.6568 - val_loss: 0.9824 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 199/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9635 - accuracy: 0.6569 - categorical_accuracy: 0.6569\n",
      "Epoch 199: val_accuracy did not improve from 0.65055\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9635 - accuracy: 0.6569 - categorical_accuracy: 0.6569 - val_loss: 0.9806 - val_accuracy: 0.6483 - val_categorical_accuracy: 0.6483 - lr: 8.6593e-05\n",
      "Epoch 200/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9632 - accuracy: 0.6575 - categorical_accuracy: 0.6575\n",
      "Epoch 200: val_accuracy improved from 0.65055 to 0.65117, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_3.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9633 - accuracy: 0.6575 - categorical_accuracy: 0.6575 - val_loss: 0.9785 - val_accuracy: 0.6512 - val_categorical_accuracy: 0.6512 - lr: 8.6593e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train kfold num: 4\n",
      "\n",
      "----------------\n",
      "Data loading complete:\n",
      "File name: None\n",
      "Training data size: 480,840\n",
      "Test data size: 120,210\n",
      "Number of constituents: 32\n",
      "Number of features: 3\n",
      "----------------\n",
      "\n",
      "(480840, 32, 3)\n",
      "(480840, 96) (120210, 96) (480840, 5) (120210, 5)\n",
      "number of G jets for training/validation: 96168/24042\n",
      "number of Q jets for training/validation: 96168/24042\n",
      "number of W jets for training/validation: 96168/24042\n",
      "number of Z jets for training/validation: 96168/24042\n",
      "number of T jets for training/validation: 96168/24042\n",
      "number of G jets for testing: 24042\n",
      "number of Q jets for testing: 24042\n",
      "number of W jets for testing: 24042\n",
      "number of Z jets for testing: 24042\n",
      "number of T jets for testing: 24042\n",
      "Epoch 1/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 1.7374 - accuracy: 0.3486 - categorical_accuracy: 0.3486\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41259, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 8s 961us/step - loss: 1.7374 - accuracy: 0.3486 - categorical_accuracy: 0.3486 - val_loss: 1.6058 - val_accuracy: 0.4126 - val_categorical_accuracy: 0.4126 - lr: 8.6593e-05\n",
      "Epoch 2/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 1.5394 - accuracy: 0.4416 - categorical_accuracy: 0.4416\n",
      "Epoch 2: val_accuracy improved from 0.41259 to 0.45759, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.5392 - accuracy: 0.4417 - categorical_accuracy: 0.4417 - val_loss: 1.4943 - val_accuracy: 0.4576 - val_categorical_accuracy: 0.4576 - lr: 8.6593e-05\n",
      "Epoch 3/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 1.4581 - accuracy: 0.4720 - categorical_accuracy: 0.4720\n",
      "Epoch 3: val_accuracy improved from 0.45759 to 0.47553, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.4580 - accuracy: 0.4720 - categorical_accuracy: 0.4720 - val_loss: 1.4411 - val_accuracy: 0.4755 - val_categorical_accuracy: 0.4755 - lr: 8.6593e-05\n",
      "Epoch 4/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 1.4093 - accuracy: 0.4871 - categorical_accuracy: 0.4871\n",
      "Epoch 4: val_accuracy improved from 0.47553 to 0.48925, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.4093 - accuracy: 0.4871 - categorical_accuracy: 0.4871 - val_loss: 1.3993 - val_accuracy: 0.4893 - val_categorical_accuracy: 0.4893 - lr: 8.6593e-05\n",
      "Epoch 5/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.3719 - accuracy: 0.4995 - categorical_accuracy: 0.4995\n",
      "Epoch 5: val_accuracy improved from 0.48925 to 0.50031, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.3716 - accuracy: 0.4996 - categorical_accuracy: 0.4996 - val_loss: 1.3665 - val_accuracy: 0.5003 - val_categorical_accuracy: 0.5003 - lr: 8.6593e-05\n",
      "Epoch 6/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.3404 - accuracy: 0.5088 - categorical_accuracy: 0.5088\n",
      "Epoch 6: val_accuracy improved from 0.50031 to 0.50872, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.3403 - accuracy: 0.5089 - categorical_accuracy: 0.5089 - val_loss: 1.3380 - val_accuracy: 0.5087 - val_categorical_accuracy: 0.5087 - lr: 8.6593e-05\n",
      "Epoch 7/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.3116 - accuracy: 0.5180 - categorical_accuracy: 0.5180\n",
      "Epoch 7: val_accuracy improved from 0.50872 to 0.51873, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.3116 - accuracy: 0.5180 - categorical_accuracy: 0.5180 - val_loss: 1.3081 - val_accuracy: 0.5187 - val_categorical_accuracy: 0.5187 - lr: 8.6593e-05\n",
      "Epoch 8/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 1.2842 - accuracy: 0.5264 - categorical_accuracy: 0.5264\n",
      "Epoch 8: val_accuracy improved from 0.51873 to 0.52338, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.2841 - accuracy: 0.5265 - categorical_accuracy: 0.5265 - val_loss: 1.2840 - val_accuracy: 0.5234 - val_categorical_accuracy: 0.5234 - lr: 8.6593e-05\n",
      "Epoch 9/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.2576 - accuracy: 0.5370 - categorical_accuracy: 0.5370\n",
      "Epoch 9: val_accuracy improved from 0.52338 to 0.53791, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.2576 - accuracy: 0.5370 - categorical_accuracy: 0.5370 - val_loss: 1.2550 - val_accuracy: 0.5379 - val_categorical_accuracy: 0.5379 - lr: 8.6593e-05\n",
      "Epoch 10/200\n",
      "7495/7514 [============================>.] - ETA: 0s - loss: 1.2352 - accuracy: 0.5452 - categorical_accuracy: 0.5452\n",
      "Epoch 10: val_accuracy improved from 0.53791 to 0.54144, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 1.2351 - accuracy: 0.5452 - categorical_accuracy: 0.5452 - val_loss: 1.2379 - val_accuracy: 0.5414 - val_categorical_accuracy: 0.5414 - lr: 8.6593e-05\n",
      "Epoch 11/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.2178 - accuracy: 0.5511 - categorical_accuracy: 0.5511\n",
      "Epoch 11: val_accuracy improved from 0.54144 to 0.54795, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.2178 - accuracy: 0.5511 - categorical_accuracy: 0.5511 - val_loss: 1.2217 - val_accuracy: 0.5479 - val_categorical_accuracy: 0.5479 - lr: 8.6593e-05\n",
      "Epoch 12/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.2038 - accuracy: 0.5556 - categorical_accuracy: 0.5556\n",
      "Epoch 12: val_accuracy improved from 0.54795 to 0.55028, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.2038 - accuracy: 0.5556 - categorical_accuracy: 0.5556 - val_loss: 1.2097 - val_accuracy: 0.5503 - val_categorical_accuracy: 0.5503 - lr: 8.6593e-05\n",
      "Epoch 13/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.1923 - accuracy: 0.5590 - categorical_accuracy: 0.5590\n",
      "Epoch 13: val_accuracy improved from 0.55028 to 0.55480, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1923 - accuracy: 0.5591 - categorical_accuracy: 0.5591 - val_loss: 1.1991 - val_accuracy: 0.5548 - val_categorical_accuracy: 0.5548 - lr: 8.6593e-05\n",
      "Epoch 14/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 1.1817 - accuracy: 0.5627 - categorical_accuracy: 0.5627\n",
      "Epoch 14: val_accuracy improved from 0.55480 to 0.55762, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.1816 - accuracy: 0.5627 - categorical_accuracy: 0.5627 - val_loss: 1.1870 - val_accuracy: 0.5576 - val_categorical_accuracy: 0.5576 - lr: 8.6593e-05\n",
      "Epoch 15/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 1.1713 - accuracy: 0.5661 - categorical_accuracy: 0.5661\n",
      "Epoch 15: val_accuracy improved from 0.55762 to 0.56207, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.1714 - accuracy: 0.5660 - categorical_accuracy: 0.5660 - val_loss: 1.1760 - val_accuracy: 0.5621 - val_categorical_accuracy: 0.5621 - lr: 8.6593e-05\n",
      "Epoch 16/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 1.1613 - accuracy: 0.5695 - categorical_accuracy: 0.5695\n",
      "Epoch 16: val_accuracy improved from 0.56207 to 0.56538, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1612 - accuracy: 0.5696 - categorical_accuracy: 0.5696 - val_loss: 1.1660 - val_accuracy: 0.5654 - val_categorical_accuracy: 0.5654 - lr: 8.6593e-05\n",
      "Epoch 17/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 1.1509 - accuracy: 0.5735 - categorical_accuracy: 0.5735\n",
      "Epoch 17: val_accuracy improved from 0.56538 to 0.57047, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1509 - accuracy: 0.5735 - categorical_accuracy: 0.5735 - val_loss: 1.1553 - val_accuracy: 0.5705 - val_categorical_accuracy: 0.5705 - lr: 8.6593e-05\n",
      "Epoch 18/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.1408 - accuracy: 0.5780 - categorical_accuracy: 0.5780\n",
      "Epoch 18: val_accuracy improved from 0.57047 to 0.57396, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.1408 - accuracy: 0.5780 - categorical_accuracy: 0.5780 - val_loss: 1.1473 - val_accuracy: 0.5740 - val_categorical_accuracy: 0.5740 - lr: 8.6593e-05\n",
      "Epoch 19/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.1310 - accuracy: 0.5818 - categorical_accuracy: 0.5818\n",
      "Epoch 19: val_accuracy improved from 0.57396 to 0.57906, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1310 - accuracy: 0.5818 - categorical_accuracy: 0.5818 - val_loss: 1.1353 - val_accuracy: 0.5791 - val_categorical_accuracy: 0.5791 - lr: 8.6593e-05\n",
      "Epoch 20/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 1.1217 - accuracy: 0.5860 - categorical_accuracy: 0.5860\n",
      "Epoch 20: val_accuracy improved from 0.57906 to 0.58266, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.1217 - accuracy: 0.5860 - categorical_accuracy: 0.5860 - val_loss: 1.1257 - val_accuracy: 0.5827 - val_categorical_accuracy: 0.5827 - lr: 8.6593e-05\n",
      "Epoch 21/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.1129 - accuracy: 0.5892 - categorical_accuracy: 0.5892\n",
      "Epoch 21: val_accuracy improved from 0.58266 to 0.58710, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.1129 - accuracy: 0.5892 - categorical_accuracy: 0.5892 - val_loss: 1.1170 - val_accuracy: 0.5871 - val_categorical_accuracy: 0.5871 - lr: 8.6593e-05\n",
      "Epoch 22/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.1050 - accuracy: 0.5927 - categorical_accuracy: 0.5927\n",
      "Epoch 22: val_accuracy did not improve from 0.58710\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.1050 - accuracy: 0.5928 - categorical_accuracy: 0.5928 - val_loss: 1.1134 - val_accuracy: 0.5870 - val_categorical_accuracy: 0.5870 - lr: 8.6593e-05\n",
      "Epoch 23/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 1.0974 - accuracy: 0.5959 - categorical_accuracy: 0.5959\n",
      "Epoch 23: val_accuracy improved from 0.58710 to 0.59257, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.0973 - accuracy: 0.5959 - categorical_accuracy: 0.5959 - val_loss: 1.1026 - val_accuracy: 0.5926 - val_categorical_accuracy: 0.5926 - lr: 8.6593e-05\n",
      "Epoch 24/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 1.0905 - accuracy: 0.5987 - categorical_accuracy: 0.5987\n",
      "Epoch 24: val_accuracy improved from 0.59257 to 0.59654, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0906 - accuracy: 0.5986 - categorical_accuracy: 0.5986 - val_loss: 1.0963 - val_accuracy: 0.5965 - val_categorical_accuracy: 0.5965 - lr: 8.6593e-05\n",
      "Epoch 25/200\n",
      "7453/7514 [============================>.] - ETA: 0s - loss: 1.0847 - accuracy: 0.6009 - categorical_accuracy: 0.6009\n",
      "Epoch 25: val_accuracy improved from 0.59654 to 0.59823, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 1.0845 - accuracy: 0.6010 - categorical_accuracy: 0.6010 - val_loss: 1.0916 - val_accuracy: 0.5982 - val_categorical_accuracy: 0.5982 - lr: 8.6593e-05\n",
      "Epoch 26/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 1.0793 - accuracy: 0.6033 - categorical_accuracy: 0.6033\n",
      "Epoch 26: val_accuracy improved from 0.59823 to 0.60088, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0792 - accuracy: 0.6033 - categorical_accuracy: 0.6033 - val_loss: 1.0855 - val_accuracy: 0.6009 - val_categorical_accuracy: 0.6009 - lr: 8.6593e-05\n",
      "Epoch 27/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0744 - accuracy: 0.6057 - categorical_accuracy: 0.6057\n",
      "Epoch 27: val_accuracy improved from 0.60088 to 0.60287, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0745 - accuracy: 0.6056 - categorical_accuracy: 0.6056 - val_loss: 1.0800 - val_accuracy: 0.6029 - val_categorical_accuracy: 0.6029 - lr: 8.6593e-05\n",
      "Epoch 28/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 1.0702 - accuracy: 0.6073 - categorical_accuracy: 0.6073\n",
      "Epoch 28: val_accuracy improved from 0.60287 to 0.60496, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0702 - accuracy: 0.6073 - categorical_accuracy: 0.6073 - val_loss: 1.0763 - val_accuracy: 0.6050 - val_categorical_accuracy: 0.6050 - lr: 8.6593e-05\n",
      "Epoch 29/200\n",
      "7462/7514 [============================>.] - ETA: 0s - loss: 1.0661 - accuracy: 0.6085 - categorical_accuracy: 0.6085\n",
      "Epoch 29: val_accuracy improved from 0.60496 to 0.60585, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0662 - accuracy: 0.6085 - categorical_accuracy: 0.6085 - val_loss: 1.0739 - val_accuracy: 0.6058 - val_categorical_accuracy: 0.6058 - lr: 8.6593e-05\n",
      "Epoch 30/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 1.0624 - accuracy: 0.6101 - categorical_accuracy: 0.6101\n",
      "Epoch 30: val_accuracy did not improve from 0.60585\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0624 - accuracy: 0.6100 - categorical_accuracy: 0.6100 - val_loss: 1.0724 - val_accuracy: 0.6057 - val_categorical_accuracy: 0.6057 - lr: 8.6593e-05\n",
      "Epoch 31/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 1.0592 - accuracy: 0.6113 - categorical_accuracy: 0.6113\n",
      "Epoch 31: val_accuracy improved from 0.60585 to 0.60859, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0591 - accuracy: 0.6114 - categorical_accuracy: 0.6114 - val_loss: 1.0668 - val_accuracy: 0.6086 - val_categorical_accuracy: 0.6086 - lr: 8.6593e-05\n",
      "Epoch 32/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0559 - accuracy: 0.6133 - categorical_accuracy: 0.6133\n",
      "Epoch 32: val_accuracy improved from 0.60859 to 0.61003, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0559 - accuracy: 0.6133 - categorical_accuracy: 0.6133 - val_loss: 1.0630 - val_accuracy: 0.6100 - val_categorical_accuracy: 0.6100 - lr: 8.6593e-05\n",
      "Epoch 33/200\n",
      "7453/7514 [============================>.] - ETA: 0s - loss: 1.0528 - accuracy: 0.6144 - categorical_accuracy: 0.6144\n",
      "Epoch 33: val_accuracy improved from 0.61003 to 0.61064, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 1.0530 - accuracy: 0.6143 - categorical_accuracy: 0.6143 - val_loss: 1.0615 - val_accuracy: 0.6106 - val_categorical_accuracy: 0.6106 - lr: 8.6593e-05\n",
      "Epoch 34/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 1.0503 - accuracy: 0.6155 - categorical_accuracy: 0.6155\n",
      "Epoch 34: val_accuracy improved from 0.61064 to 0.61123, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0501 - accuracy: 0.6155 - categorical_accuracy: 0.6155 - val_loss: 1.0583 - val_accuracy: 0.6112 - val_categorical_accuracy: 0.6112 - lr: 8.6593e-05\n",
      "Epoch 35/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0475 - accuracy: 0.6169 - categorical_accuracy: 0.6169\n",
      "Epoch 35: val_accuracy improved from 0.61123 to 0.61279, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0475 - accuracy: 0.6169 - categorical_accuracy: 0.6169 - val_loss: 1.0568 - val_accuracy: 0.6128 - val_categorical_accuracy: 0.6128 - lr: 8.6593e-05\n",
      "Epoch 36/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 1.0450 - accuracy: 0.6176 - categorical_accuracy: 0.6176\n",
      "Epoch 36: val_accuracy did not improve from 0.61279\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0452 - accuracy: 0.6175 - categorical_accuracy: 0.6175 - val_loss: 1.0559 - val_accuracy: 0.6113 - val_categorical_accuracy: 0.6113 - lr: 8.6593e-05\n",
      "Epoch 37/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 1.0429 - accuracy: 0.6189 - categorical_accuracy: 0.6189\n",
      "Epoch 37: val_accuracy improved from 0.61279 to 0.61324, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0429 - accuracy: 0.6189 - categorical_accuracy: 0.6189 - val_loss: 1.0544 - val_accuracy: 0.6132 - val_categorical_accuracy: 0.6132 - lr: 8.6593e-05\n",
      "Epoch 38/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0410 - accuracy: 0.6199 - categorical_accuracy: 0.6199\n",
      "Epoch 38: val_accuracy improved from 0.61324 to 0.61604, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0409 - accuracy: 0.6199 - categorical_accuracy: 0.6199 - val_loss: 1.0504 - val_accuracy: 0.6160 - val_categorical_accuracy: 0.6160 - lr: 8.6593e-05\n",
      "Epoch 39/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 1.0386 - accuracy: 0.6208 - categorical_accuracy: 0.6208\n",
      "Epoch 39: val_accuracy did not improve from 0.61604\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0385 - accuracy: 0.6208 - categorical_accuracy: 0.6208 - val_loss: 1.0495 - val_accuracy: 0.6157 - val_categorical_accuracy: 0.6157 - lr: 8.6593e-05\n",
      "Epoch 40/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 1.0365 - accuracy: 0.6214 - categorical_accuracy: 0.6214\n",
      "Epoch 40: val_accuracy improved from 0.61604 to 0.61700, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0365 - accuracy: 0.6216 - categorical_accuracy: 0.6216 - val_loss: 1.0451 - val_accuracy: 0.6170 - val_categorical_accuracy: 0.6170 - lr: 8.6593e-05\n",
      "Epoch 41/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0343 - accuracy: 0.6232 - categorical_accuracy: 0.6232\n",
      "Epoch 41: val_accuracy improved from 0.61700 to 0.61852, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0342 - accuracy: 0.6232 - categorical_accuracy: 0.6232 - val_loss: 1.0441 - val_accuracy: 0.6185 - val_categorical_accuracy: 0.6185 - lr: 8.6593e-05\n",
      "Epoch 42/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 1.0324 - accuracy: 0.6240 - categorical_accuracy: 0.6240\n",
      "Epoch 42: val_accuracy did not improve from 0.61852\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0323 - accuracy: 0.6240 - categorical_accuracy: 0.6240 - val_loss: 1.0443 - val_accuracy: 0.6171 - val_categorical_accuracy: 0.6171 - lr: 8.6593e-05\n",
      "Epoch 43/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0303 - accuracy: 0.6252 - categorical_accuracy: 0.6252\n",
      "Epoch 43: val_accuracy improved from 0.61852 to 0.61976, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0304 - accuracy: 0.6252 - categorical_accuracy: 0.6252 - val_loss: 1.0407 - val_accuracy: 0.6198 - val_categorical_accuracy: 0.6198 - lr: 8.6593e-05\n",
      "Epoch 44/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 1.0288 - accuracy: 0.6259 - categorical_accuracy: 0.6259\n",
      "Epoch 44: val_accuracy improved from 0.61976 to 0.62134, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0286 - accuracy: 0.6260 - categorical_accuracy: 0.6260 - val_loss: 1.0381 - val_accuracy: 0.6213 - val_categorical_accuracy: 0.6213 - lr: 8.6593e-05\n",
      "Epoch 45/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 1.0269 - accuracy: 0.6265 - categorical_accuracy: 0.6265\n",
      "Epoch 45: val_accuracy did not improve from 0.62134\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.0268 - accuracy: 0.6265 - categorical_accuracy: 0.6265 - val_loss: 1.0386 - val_accuracy: 0.6198 - val_categorical_accuracy: 0.6198 - lr: 8.6593e-05\n",
      "Epoch 46/200\n",
      "7454/7514 [============================>.] - ETA: 0s - loss: 1.0252 - accuracy: 0.6275 - categorical_accuracy: 0.6275\n",
      "Epoch 46: val_accuracy improved from 0.62134 to 0.62278, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0253 - accuracy: 0.6275 - categorical_accuracy: 0.6275 - val_loss: 1.0351 - val_accuracy: 0.6228 - val_categorical_accuracy: 0.6228 - lr: 8.6593e-05\n",
      "Epoch 47/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 1.0232 - accuracy: 0.6288 - categorical_accuracy: 0.6288\n",
      "Epoch 47: val_accuracy improved from 0.62278 to 0.62305, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0233 - accuracy: 0.6288 - categorical_accuracy: 0.6288 - val_loss: 1.0357 - val_accuracy: 0.6231 - val_categorical_accuracy: 0.6231 - lr: 8.6593e-05\n",
      "Epoch 48/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0219 - accuracy: 0.6294 - categorical_accuracy: 0.6294\n",
      "Epoch 48: val_accuracy improved from 0.62305 to 0.62355, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0218 - accuracy: 0.6295 - categorical_accuracy: 0.6295 - val_loss: 1.0326 - val_accuracy: 0.6236 - val_categorical_accuracy: 0.6236 - lr: 8.6593e-05\n",
      "Epoch 49/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0207 - accuracy: 0.6299 - categorical_accuracy: 0.6299\n",
      "Epoch 49: val_accuracy improved from 0.62355 to 0.62400, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0207 - accuracy: 0.6300 - categorical_accuracy: 0.6300 - val_loss: 1.0317 - val_accuracy: 0.6240 - val_categorical_accuracy: 0.6240 - lr: 8.6593e-05\n",
      "Epoch 50/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 1.0190 - accuracy: 0.6306 - categorical_accuracy: 0.6306\n",
      "Epoch 50: val_accuracy improved from 0.62400 to 0.62476, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0191 - accuracy: 0.6306 - categorical_accuracy: 0.6306 - val_loss: 1.0294 - val_accuracy: 0.6248 - val_categorical_accuracy: 0.6248 - lr: 8.6593e-05\n",
      "Epoch 51/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 1.0173 - accuracy: 0.6317 - categorical_accuracy: 0.6317\n",
      "Epoch 51: val_accuracy did not improve from 0.62476\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0173 - accuracy: 0.6316 - categorical_accuracy: 0.6316 - val_loss: 1.0307 - val_accuracy: 0.6244 - val_categorical_accuracy: 0.6244 - lr: 8.6593e-05\n",
      "Epoch 52/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 1.0161 - accuracy: 0.6319 - categorical_accuracy: 0.6319\n",
      "Epoch 52: val_accuracy improved from 0.62476 to 0.62624, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0160 - accuracy: 0.6319 - categorical_accuracy: 0.6319 - val_loss: 1.0277 - val_accuracy: 0.6262 - val_categorical_accuracy: 0.6262 - lr: 8.6593e-05\n",
      "Epoch 53/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 1.0149 - accuracy: 0.6328 - categorical_accuracy: 0.6328\n",
      "Epoch 53: val_accuracy did not improve from 0.62624\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0148 - accuracy: 0.6328 - categorical_accuracy: 0.6328 - val_loss: 1.0287 - val_accuracy: 0.6255 - val_categorical_accuracy: 0.6255 - lr: 8.6593e-05\n",
      "Epoch 54/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 1.0138 - accuracy: 0.6332 - categorical_accuracy: 0.6332\n",
      "Epoch 54: val_accuracy improved from 0.62624 to 0.62769, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0137 - accuracy: 0.6333 - categorical_accuracy: 0.6333 - val_loss: 1.0260 - val_accuracy: 0.6277 - val_categorical_accuracy: 0.6277 - lr: 8.6593e-05\n",
      "Epoch 55/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 1.0124 - accuracy: 0.6338 - categorical_accuracy: 0.6338\n",
      "Epoch 55: val_accuracy did not improve from 0.62769\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0124 - accuracy: 0.6339 - categorical_accuracy: 0.6339 - val_loss: 1.0255 - val_accuracy: 0.6272 - val_categorical_accuracy: 0.6272 - lr: 8.6593e-05\n",
      "Epoch 56/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 1.0109 - accuracy: 0.6351 - categorical_accuracy: 0.6351\n",
      "Epoch 56: val_accuracy improved from 0.62769 to 0.62816, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0110 - accuracy: 0.6350 - categorical_accuracy: 0.6350 - val_loss: 1.0236 - val_accuracy: 0.6282 - val_categorical_accuracy: 0.6282 - lr: 8.6593e-05\n",
      "Epoch 57/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 1.0100 - accuracy: 0.6354 - categorical_accuracy: 0.6354\n",
      "Epoch 57: val_accuracy did not improve from 0.62816\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 1.0099 - accuracy: 0.6354 - categorical_accuracy: 0.6354 - val_loss: 1.0238 - val_accuracy: 0.6278 - val_categorical_accuracy: 0.6278 - lr: 8.6593e-05\n",
      "Epoch 58/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 1.0087 - accuracy: 0.6357 - categorical_accuracy: 0.6357\n",
      "Epoch 58: val_accuracy improved from 0.62816 to 0.62956, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0087 - accuracy: 0.6357 - categorical_accuracy: 0.6357 - val_loss: 1.0226 - val_accuracy: 0.6296 - val_categorical_accuracy: 0.6296 - lr: 8.6593e-05\n",
      "Epoch 59/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 1.0072 - accuracy: 0.6365 - categorical_accuracy: 0.6365\n",
      "Epoch 59: val_accuracy did not improve from 0.62956\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0073 - accuracy: 0.6365 - categorical_accuracy: 0.6365 - val_loss: 1.0206 - val_accuracy: 0.6294 - val_categorical_accuracy: 0.6294 - lr: 8.6593e-05\n",
      "Epoch 60/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 1.0064 - accuracy: 0.6371 - categorical_accuracy: 0.6371\n",
      "Epoch 60: val_accuracy improved from 0.62956 to 0.63186, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 1.0062 - accuracy: 0.6371 - categorical_accuracy: 0.6371 - val_loss: 1.0180 - val_accuracy: 0.6319 - val_categorical_accuracy: 0.6319 - lr: 8.6593e-05\n",
      "Epoch 61/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 1.0052 - accuracy: 0.6373 - categorical_accuracy: 0.6373\n",
      "Epoch 61: val_accuracy did not improve from 0.63186\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 1.0052 - accuracy: 0.6373 - categorical_accuracy: 0.6373 - val_loss: 1.0184 - val_accuracy: 0.6315 - val_categorical_accuracy: 0.6315 - lr: 8.6593e-05\n",
      "Epoch 62/200\n",
      "7454/7514 [============================>.] - ETA: 0s - loss: 1.0037 - accuracy: 0.6386 - categorical_accuracy: 0.6386\n",
      "Epoch 62: val_accuracy improved from 0.63186 to 0.63200, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 1.0038 - accuracy: 0.6386 - categorical_accuracy: 0.6386 - val_loss: 1.0163 - val_accuracy: 0.6320 - val_categorical_accuracy: 0.6320 - lr: 8.6593e-05\n",
      "Epoch 63/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 1.0029 - accuracy: 0.6387 - categorical_accuracy: 0.6387\n",
      "Epoch 63: val_accuracy improved from 0.63200 to 0.63254, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 1.0029 - accuracy: 0.6387 - categorical_accuracy: 0.6387 - val_loss: 1.0164 - val_accuracy: 0.6325 - val_categorical_accuracy: 0.6325 - lr: 8.6593e-05\n",
      "Epoch 64/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 1.0019 - accuracy: 0.6395 - categorical_accuracy: 0.6395\n",
      "Epoch 64: val_accuracy did not improve from 0.63254\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 1.0019 - accuracy: 0.6395 - categorical_accuracy: 0.6395 - val_loss: 1.0156 - val_accuracy: 0.6324 - val_categorical_accuracy: 0.6324 - lr: 8.6593e-05\n",
      "Epoch 65/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 1.0008 - accuracy: 0.6399 - categorical_accuracy: 0.6399\n",
      "Epoch 65: val_accuracy improved from 0.63254 to 0.63322, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 1.0008 - accuracy: 0.6399 - categorical_accuracy: 0.6399 - val_loss: 1.0147 - val_accuracy: 0.6332 - val_categorical_accuracy: 0.6332 - lr: 8.6593e-05\n",
      "Epoch 66/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 0.9999 - accuracy: 0.6404 - categorical_accuracy: 0.6404\n",
      "Epoch 66: val_accuracy did not improve from 0.63322\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9998 - accuracy: 0.6404 - categorical_accuracy: 0.6404 - val_loss: 1.0157 - val_accuracy: 0.6323 - val_categorical_accuracy: 0.6323 - lr: 8.6593e-05\n",
      "Epoch 67/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9987 - accuracy: 0.6414 - categorical_accuracy: 0.6414\n",
      "Epoch 67: val_accuracy improved from 0.63322 to 0.63554, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9987 - accuracy: 0.6414 - categorical_accuracy: 0.6414 - val_loss: 1.0109 - val_accuracy: 0.6355 - val_categorical_accuracy: 0.6355 - lr: 8.6593e-05\n",
      "Epoch 68/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9981 - accuracy: 0.6414 - categorical_accuracy: 0.6414\n",
      "Epoch 68: val_accuracy did not improve from 0.63554\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 0.9981 - accuracy: 0.6414 - categorical_accuracy: 0.6414 - val_loss: 1.0114 - val_accuracy: 0.6343 - val_categorical_accuracy: 0.6343 - lr: 8.6593e-05\n",
      "Epoch 69/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9971 - accuracy: 0.6422 - categorical_accuracy: 0.6422\n",
      "Epoch 69: val_accuracy did not improve from 0.63554\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9972 - accuracy: 0.6422 - categorical_accuracy: 0.6422 - val_loss: 1.0095 - val_accuracy: 0.6354 - val_categorical_accuracy: 0.6354 - lr: 8.6593e-05\n",
      "Epoch 70/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 0.9964 - accuracy: 0.6426 - categorical_accuracy: 0.6426\n",
      "Epoch 70: val_accuracy did not improve from 0.63554\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9964 - accuracy: 0.6426 - categorical_accuracy: 0.6426 - val_loss: 1.0101 - val_accuracy: 0.6345 - val_categorical_accuracy: 0.6345 - lr: 8.6593e-05\n",
      "Epoch 71/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9956 - accuracy: 0.6430 - categorical_accuracy: 0.6430\n",
      "Epoch 71: val_accuracy improved from 0.63554 to 0.63633, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9953 - accuracy: 0.6431 - categorical_accuracy: 0.6431 - val_loss: 1.0082 - val_accuracy: 0.6363 - val_categorical_accuracy: 0.6363 - lr: 8.6593e-05\n",
      "Epoch 72/200\n",
      "7454/7514 [============================>.] - ETA: 0s - loss: 0.9950 - accuracy: 0.6435 - categorical_accuracy: 0.6435\n",
      "Epoch 72: val_accuracy did not improve from 0.63633\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9948 - accuracy: 0.6436 - categorical_accuracy: 0.6436 - val_loss: 1.0085 - val_accuracy: 0.6359 - val_categorical_accuracy: 0.6359 - lr: 8.6593e-05\n",
      "Epoch 73/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9936 - accuracy: 0.6438 - categorical_accuracy: 0.6438\n",
      "Epoch 73: val_accuracy improved from 0.63633 to 0.63643, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9936 - accuracy: 0.6438 - categorical_accuracy: 0.6438 - val_loss: 1.0066 - val_accuracy: 0.6364 - val_categorical_accuracy: 0.6364 - lr: 8.6593e-05\n",
      "Epoch 74/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 0.9935 - accuracy: 0.6436 - categorical_accuracy: 0.6436\n",
      "Epoch 74: val_accuracy improved from 0.63643 to 0.63740, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9935 - accuracy: 0.6435 - categorical_accuracy: 0.6435 - val_loss: 1.0071 - val_accuracy: 0.6374 - val_categorical_accuracy: 0.6374 - lr: 8.6593e-05\n",
      "Epoch 75/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 0.9926 - accuracy: 0.6442 - categorical_accuracy: 0.6442\n",
      "Epoch 75: val_accuracy did not improve from 0.63740\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9926 - accuracy: 0.6442 - categorical_accuracy: 0.6442 - val_loss: 1.0099 - val_accuracy: 0.6336 - val_categorical_accuracy: 0.6336 - lr: 8.6593e-05\n",
      "Epoch 76/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 0.9919 - accuracy: 0.6448 - categorical_accuracy: 0.6448\n",
      "Epoch 76: val_accuracy did not improve from 0.63740\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9919 - accuracy: 0.6448 - categorical_accuracy: 0.6448 - val_loss: 1.0066 - val_accuracy: 0.6371 - val_categorical_accuracy: 0.6371 - lr: 8.6593e-05\n",
      "Epoch 77/200\n",
      "7470/7514 [============================>.] - ETA: 0s - loss: 0.9914 - accuracy: 0.6449 - categorical_accuracy: 0.6449\n",
      "Epoch 77: val_accuracy did not improve from 0.63740\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9914 - accuracy: 0.6449 - categorical_accuracy: 0.6449 - val_loss: 1.0080 - val_accuracy: 0.6363 - val_categorical_accuracy: 0.6363 - lr: 8.6593e-05\n",
      "Epoch 78/200\n",
      "7503/7514 [============================>.] - ETA: 0s - loss: 0.9907 - accuracy: 0.6452 - categorical_accuracy: 0.6452\n",
      "Epoch 78: val_accuracy did not improve from 0.63740\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9907 - accuracy: 0.6452 - categorical_accuracy: 0.6452 - val_loss: 1.0049 - val_accuracy: 0.6374 - val_categorical_accuracy: 0.6374 - lr: 8.6593e-05\n",
      "Epoch 79/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9903 - accuracy: 0.6457 - categorical_accuracy: 0.6457\n",
      "Epoch 79: val_accuracy did not improve from 0.63740\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9903 - accuracy: 0.6457 - categorical_accuracy: 0.6457 - val_loss: 1.0069 - val_accuracy: 0.6373 - val_categorical_accuracy: 0.6373 - lr: 8.6593e-05\n",
      "Epoch 80/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9897 - accuracy: 0.6456 - categorical_accuracy: 0.6456\n",
      "Epoch 80: val_accuracy did not improve from 0.63740\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9897 - accuracy: 0.6457 - categorical_accuracy: 0.6457 - val_loss: 1.0047 - val_accuracy: 0.6372 - val_categorical_accuracy: 0.6372 - lr: 8.6593e-05\n",
      "Epoch 81/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9894 - accuracy: 0.6459 - categorical_accuracy: 0.6459\n",
      "Epoch 81: val_accuracy improved from 0.63740 to 0.63971, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 0.9893 - accuracy: 0.6459 - categorical_accuracy: 0.6459 - val_loss: 1.0025 - val_accuracy: 0.6397 - val_categorical_accuracy: 0.6397 - lr: 8.6593e-05\n",
      "Epoch 82/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 0.9884 - accuracy: 0.6461 - categorical_accuracy: 0.6461\n",
      "Epoch 82: val_accuracy did not improve from 0.63971\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 0.9885 - accuracy: 0.6460 - categorical_accuracy: 0.6460 - val_loss: 1.0032 - val_accuracy: 0.6381 - val_categorical_accuracy: 0.6381 - lr: 8.6593e-05\n",
      "Epoch 83/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9881 - accuracy: 0.6468 - categorical_accuracy: 0.6468\n",
      "Epoch 83: val_accuracy improved from 0.63971 to 0.64001, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9881 - accuracy: 0.6468 - categorical_accuracy: 0.6468 - val_loss: 1.0018 - val_accuracy: 0.6400 - val_categorical_accuracy: 0.6400 - lr: 8.6593e-05\n",
      "Epoch 84/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9874 - accuracy: 0.6471 - categorical_accuracy: 0.6471\n",
      "Epoch 84: val_accuracy did not improve from 0.64001\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9875 - accuracy: 0.6471 - categorical_accuracy: 0.6471 - val_loss: 1.0025 - val_accuracy: 0.6393 - val_categorical_accuracy: 0.6393 - lr: 8.6593e-05\n",
      "Epoch 85/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9870 - accuracy: 0.6469 - categorical_accuracy: 0.6469\n",
      "Epoch 85: val_accuracy did not improve from 0.64001\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9871 - accuracy: 0.6468 - categorical_accuracy: 0.6468 - val_loss: 1.0024 - val_accuracy: 0.6394 - val_categorical_accuracy: 0.6394 - lr: 8.6593e-05\n",
      "Epoch 86/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9863 - accuracy: 0.6475 - categorical_accuracy: 0.6475\n",
      "Epoch 86: val_accuracy improved from 0.64001 to 0.64051, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9863 - accuracy: 0.6474 - categorical_accuracy: 0.6474 - val_loss: 1.0013 - val_accuracy: 0.6405 - val_categorical_accuracy: 0.6405 - lr: 8.6593e-05\n",
      "Epoch 87/200\n",
      "7463/7514 [============================>.] - ETA: 0s - loss: 0.9859 - accuracy: 0.6474 - categorical_accuracy: 0.6474\n",
      "Epoch 87: val_accuracy improved from 0.64051 to 0.64122, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9859 - accuracy: 0.6473 - categorical_accuracy: 0.6473 - val_loss: 0.9989 - val_accuracy: 0.6412 - val_categorical_accuracy: 0.6412 - lr: 8.6593e-05\n",
      "Epoch 88/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9852 - accuracy: 0.6480 - categorical_accuracy: 0.6480\n",
      "Epoch 88: val_accuracy did not improve from 0.64122\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9853 - accuracy: 0.6479 - categorical_accuracy: 0.6479 - val_loss: 1.0007 - val_accuracy: 0.6401 - val_categorical_accuracy: 0.6401 - lr: 8.6593e-05\n",
      "Epoch 89/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9851 - accuracy: 0.6478 - categorical_accuracy: 0.6478\n",
      "Epoch 89: val_accuracy did not improve from 0.64122\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9851 - accuracy: 0.6478 - categorical_accuracy: 0.6478 - val_loss: 0.9987 - val_accuracy: 0.6407 - val_categorical_accuracy: 0.6407 - lr: 8.6593e-05\n",
      "Epoch 90/200\n",
      "7509/7514 [============================>.] - ETA: 0s - loss: 0.9843 - accuracy: 0.6480 - categorical_accuracy: 0.6480\n",
      "Epoch 90: val_accuracy did not improve from 0.64122\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9843 - accuracy: 0.6480 - categorical_accuracy: 0.6480 - val_loss: 1.0017 - val_accuracy: 0.6382 - val_categorical_accuracy: 0.6382 - lr: 8.6593e-05\n",
      "Epoch 91/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 0.9842 - accuracy: 0.6485 - categorical_accuracy: 0.6485\n",
      "Epoch 91: val_accuracy did not improve from 0.64122\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9842 - accuracy: 0.6485 - categorical_accuracy: 0.6485 - val_loss: 1.0005 - val_accuracy: 0.6392 - val_categorical_accuracy: 0.6392 - lr: 8.6593e-05\n",
      "Epoch 92/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 0.9838 - accuracy: 0.6481 - categorical_accuracy: 0.6481\n",
      "Epoch 92: val_accuracy did not improve from 0.64122\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9839 - accuracy: 0.6480 - categorical_accuracy: 0.6480 - val_loss: 0.9989 - val_accuracy: 0.6411 - val_categorical_accuracy: 0.6411 - lr: 8.6593e-05\n",
      "Epoch 93/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9834 - accuracy: 0.6485 - categorical_accuracy: 0.6485\n",
      "Epoch 93: val_accuracy did not improve from 0.64122\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9834 - accuracy: 0.6485 - categorical_accuracy: 0.6485 - val_loss: 1.0009 - val_accuracy: 0.6405 - val_categorical_accuracy: 0.6405 - lr: 8.6593e-05\n",
      "Epoch 94/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9830 - accuracy: 0.6492 - categorical_accuracy: 0.6492\n",
      "Epoch 94: val_accuracy improved from 0.64122 to 0.64145, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9829 - accuracy: 0.6492 - categorical_accuracy: 0.6492 - val_loss: 0.9983 - val_accuracy: 0.6415 - val_categorical_accuracy: 0.6415 - lr: 8.6593e-05\n",
      "Epoch 95/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9823 - accuracy: 0.6494 - categorical_accuracy: 0.6494\n",
      "Epoch 95: val_accuracy improved from 0.64145 to 0.64154, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9822 - accuracy: 0.6494 - categorical_accuracy: 0.6494 - val_loss: 0.9979 - val_accuracy: 0.6415 - val_categorical_accuracy: 0.6415 - lr: 8.6593e-05\n",
      "Epoch 96/200\n",
      "7457/7514 [============================>.] - ETA: 0s - loss: 0.9819 - accuracy: 0.6499 - categorical_accuracy: 0.6499\n",
      "Epoch 96: val_accuracy improved from 0.64154 to 0.64179, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9818 - accuracy: 0.6499 - categorical_accuracy: 0.6499 - val_loss: 0.9978 - val_accuracy: 0.6418 - val_categorical_accuracy: 0.6418 - lr: 8.6593e-05\n",
      "Epoch 97/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9814 - accuracy: 0.6496 - categorical_accuracy: 0.6496\n",
      "Epoch 97: val_accuracy did not improve from 0.64179\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9814 - accuracy: 0.6496 - categorical_accuracy: 0.6496 - val_loss: 0.9972 - val_accuracy: 0.6414 - val_categorical_accuracy: 0.6414 - lr: 8.6593e-05\n",
      "Epoch 98/200\n",
      "7479/7514 [============================>.] - ETA: 0s - loss: 0.9811 - accuracy: 0.6498 - categorical_accuracy: 0.6498\n",
      "Epoch 98: val_accuracy did not improve from 0.64179\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9811 - accuracy: 0.6498 - categorical_accuracy: 0.6498 - val_loss: 0.9973 - val_accuracy: 0.6416 - val_categorical_accuracy: 0.6416 - lr: 8.6593e-05\n",
      "Epoch 99/200\n",
      "7454/7514 [============================>.] - ETA: 0s - loss: 0.9811 - accuracy: 0.6500 - categorical_accuracy: 0.6500\n",
      "Epoch 99: val_accuracy improved from 0.64179 to 0.64271, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9810 - accuracy: 0.6501 - categorical_accuracy: 0.6501 - val_loss: 0.9954 - val_accuracy: 0.6427 - val_categorical_accuracy: 0.6427 - lr: 8.6593e-05\n",
      "Epoch 100/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9805 - accuracy: 0.6502 - categorical_accuracy: 0.6502\n",
      "Epoch 100: val_accuracy improved from 0.64271 to 0.64372, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9806 - accuracy: 0.6502 - categorical_accuracy: 0.6502 - val_loss: 0.9946 - val_accuracy: 0.6437 - val_categorical_accuracy: 0.6437 - lr: 8.6593e-05\n",
      "Epoch 101/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9804 - accuracy: 0.6500 - categorical_accuracy: 0.6500\n",
      "Epoch 101: val_accuracy did not improve from 0.64372\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9805 - accuracy: 0.6499 - categorical_accuracy: 0.6499 - val_loss: 0.9957 - val_accuracy: 0.6417 - val_categorical_accuracy: 0.6417 - lr: 8.6593e-05\n",
      "Epoch 102/200\n",
      "7471/7514 [============================>.] - ETA: 0s - loss: 0.9797 - accuracy: 0.6502 - categorical_accuracy: 0.6502\n",
      "Epoch 102: val_accuracy did not improve from 0.64372\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9799 - accuracy: 0.6502 - categorical_accuracy: 0.6502 - val_loss: 0.9946 - val_accuracy: 0.6431 - val_categorical_accuracy: 0.6431 - lr: 8.6593e-05\n",
      "Epoch 103/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 0.9794 - accuracy: 0.6505 - categorical_accuracy: 0.6505\n",
      "Epoch 103: val_accuracy did not improve from 0.64372\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9793 - accuracy: 0.6506 - categorical_accuracy: 0.6506 - val_loss: 1.0012 - val_accuracy: 0.6379 - val_categorical_accuracy: 0.6379 - lr: 8.6593e-05\n",
      "Epoch 104/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9791 - accuracy: 0.6507 - categorical_accuracy: 0.6507\n",
      "Epoch 104: val_accuracy did not improve from 0.64372\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9792 - accuracy: 0.6507 - categorical_accuracy: 0.6507 - val_loss: 0.9942 - val_accuracy: 0.6422 - val_categorical_accuracy: 0.6422 - lr: 8.6593e-05\n",
      "Epoch 105/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 0.9782 - accuracy: 0.6515 - categorical_accuracy: 0.6515\n",
      "Epoch 105: val_accuracy did not improve from 0.64372\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9783 - accuracy: 0.6514 - categorical_accuracy: 0.6514 - val_loss: 0.9939 - val_accuracy: 0.6424 - val_categorical_accuracy: 0.6424 - lr: 8.6593e-05\n",
      "Epoch 106/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9780 - accuracy: 0.6514 - categorical_accuracy: 0.6514\n",
      "Epoch 106: val_accuracy did not improve from 0.64372\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9782 - accuracy: 0.6512 - categorical_accuracy: 0.6512 - val_loss: 0.9926 - val_accuracy: 0.6430 - val_categorical_accuracy: 0.6430 - lr: 8.6593e-05\n",
      "Epoch 107/200\n",
      "7512/7514 [============================>.] - ETA: 0s - loss: 0.9776 - accuracy: 0.6515 - categorical_accuracy: 0.6515\n",
      "Epoch 107: val_accuracy improved from 0.64372 to 0.64518, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9776 - accuracy: 0.6515 - categorical_accuracy: 0.6515 - val_loss: 0.9924 - val_accuracy: 0.6452 - val_categorical_accuracy: 0.6452 - lr: 8.6593e-05\n",
      "Epoch 108/200\n",
      "7465/7514 [============================>.] - ETA: 0s - loss: 0.9775 - accuracy: 0.6519 - categorical_accuracy: 0.6519\n",
      "Epoch 108: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9775 - accuracy: 0.6519 - categorical_accuracy: 0.6519 - val_loss: 0.9919 - val_accuracy: 0.6441 - val_categorical_accuracy: 0.6441 - lr: 8.6593e-05\n",
      "Epoch 109/200\n",
      "7509/7514 [============================>.] - ETA: 0s - loss: 0.9772 - accuracy: 0.6520 - categorical_accuracy: 0.6520\n",
      "Epoch 109: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9772 - accuracy: 0.6520 - categorical_accuracy: 0.6520 - val_loss: 0.9922 - val_accuracy: 0.6431 - val_categorical_accuracy: 0.6431 - lr: 8.6593e-05\n",
      "Epoch 110/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9763 - accuracy: 0.6518 - categorical_accuracy: 0.6518\n",
      "Epoch 110: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9763 - accuracy: 0.6518 - categorical_accuracy: 0.6518 - val_loss: 0.9914 - val_accuracy: 0.6439 - val_categorical_accuracy: 0.6439 - lr: 8.6593e-05\n",
      "Epoch 111/200\n",
      "7469/7514 [============================>.] - ETA: 0s - loss: 0.9759 - accuracy: 0.6523 - categorical_accuracy: 0.6523\n",
      "Epoch 111: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9760 - accuracy: 0.6523 - categorical_accuracy: 0.6523 - val_loss: 0.9909 - val_accuracy: 0.6448 - val_categorical_accuracy: 0.6448 - lr: 8.6593e-05\n",
      "Epoch 112/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9761 - accuracy: 0.6522 - categorical_accuracy: 0.6522\n",
      "Epoch 112: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9760 - accuracy: 0.6523 - categorical_accuracy: 0.6523 - val_loss: 0.9906 - val_accuracy: 0.6433 - val_categorical_accuracy: 0.6433 - lr: 8.6593e-05\n",
      "Epoch 113/200\n",
      "7475/7514 [============================>.] - ETA: 0s - loss: 0.9753 - accuracy: 0.6522 - categorical_accuracy: 0.6522\n",
      "Epoch 113: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9753 - accuracy: 0.6522 - categorical_accuracy: 0.6522 - val_loss: 0.9918 - val_accuracy: 0.6433 - val_categorical_accuracy: 0.6433 - lr: 8.6593e-05\n",
      "Epoch 114/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9747 - accuracy: 0.6531 - categorical_accuracy: 0.6531\n",
      "Epoch 114: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9749 - accuracy: 0.6530 - categorical_accuracy: 0.6530 - val_loss: 0.9908 - val_accuracy: 0.6448 - val_categorical_accuracy: 0.6448 - lr: 8.6593e-05\n",
      "Epoch 115/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9745 - accuracy: 0.6530 - categorical_accuracy: 0.6530\n",
      "Epoch 115: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9745 - accuracy: 0.6530 - categorical_accuracy: 0.6530 - val_loss: 0.9907 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444 - lr: 8.6593e-05\n",
      "Epoch 116/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 0.9743 - accuracy: 0.6533 - categorical_accuracy: 0.6533\n",
      "Epoch 116: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9743 - accuracy: 0.6533 - categorical_accuracy: 0.6533 - val_loss: 0.9909 - val_accuracy: 0.6442 - val_categorical_accuracy: 0.6442 - lr: 8.6593e-05\n",
      "Epoch 117/200\n",
      "7458/7514 [============================>.] - ETA: 0s - loss: 0.9738 - accuracy: 0.6531 - categorical_accuracy: 0.6531\n",
      "Epoch 117: val_accuracy did not improve from 0.64518\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9737 - accuracy: 0.6531 - categorical_accuracy: 0.6531 - val_loss: 0.9873 - val_accuracy: 0.6451 - val_categorical_accuracy: 0.6451 - lr: 8.6593e-05\n",
      "Epoch 118/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 0.9733 - accuracy: 0.6538 - categorical_accuracy: 0.6538\n",
      "Epoch 118: val_accuracy improved from 0.64518 to 0.64661, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9734 - accuracy: 0.6537 - categorical_accuracy: 0.6537 - val_loss: 0.9868 - val_accuracy: 0.6466 - val_categorical_accuracy: 0.6466 - lr: 8.6593e-05\n",
      "Epoch 119/200\n",
      "7456/7514 [============================>.] - ETA: 0s - loss: 0.9732 - accuracy: 0.6535 - categorical_accuracy: 0.6535\n",
      "Epoch 119: val_accuracy did not improve from 0.64661\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9732 - accuracy: 0.6535 - categorical_accuracy: 0.6535 - val_loss: 0.9889 - val_accuracy: 0.6456 - val_categorical_accuracy: 0.6456 - lr: 8.6593e-05\n",
      "Epoch 120/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9726 - accuracy: 0.6535 - categorical_accuracy: 0.6535\n",
      "Epoch 120: val_accuracy did not improve from 0.64661\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9726 - accuracy: 0.6536 - categorical_accuracy: 0.6536 - val_loss: 0.9888 - val_accuracy: 0.6458 - val_categorical_accuracy: 0.6458 - lr: 8.6593e-05\n",
      "Epoch 121/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9721 - accuracy: 0.6541 - categorical_accuracy: 0.6541\n",
      "Epoch 121: val_accuracy did not improve from 0.64661\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9721 - accuracy: 0.6541 - categorical_accuracy: 0.6541 - val_loss: 0.9875 - val_accuracy: 0.6461 - val_categorical_accuracy: 0.6461 - lr: 8.6593e-05\n",
      "Epoch 122/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 0.9719 - accuracy: 0.6539 - categorical_accuracy: 0.6539\n",
      "Epoch 122: val_accuracy improved from 0.64661 to 0.64743, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9720 - accuracy: 0.6538 - categorical_accuracy: 0.6538 - val_loss: 0.9863 - val_accuracy: 0.6474 - val_categorical_accuracy: 0.6474 - lr: 8.6593e-05\n",
      "Epoch 123/200\n",
      "7466/7514 [============================>.] - ETA: 0s - loss: 0.9714 - accuracy: 0.6546 - categorical_accuracy: 0.6546\n",
      "Epoch 123: val_accuracy did not improve from 0.64743\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9714 - accuracy: 0.6545 - categorical_accuracy: 0.6545 - val_loss: 0.9866 - val_accuracy: 0.6466 - val_categorical_accuracy: 0.6466 - lr: 8.6593e-05\n",
      "Epoch 124/200\n",
      "7508/7514 [============================>.] - ETA: 0s - loss: 0.9713 - accuracy: 0.6543 - categorical_accuracy: 0.6543\n",
      "Epoch 124: val_accuracy did not improve from 0.64743\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9713 - accuracy: 0.6543 - categorical_accuracy: 0.6543 - val_loss: 0.9882 - val_accuracy: 0.6468 - val_categorical_accuracy: 0.6468 - lr: 8.6593e-05\n",
      "Epoch 125/200\n",
      "7514/7514 [==============================] - ETA: 0s - loss: 0.9713 - accuracy: 0.6546 - categorical_accuracy: 0.6546\n",
      "Epoch 125: val_accuracy improved from 0.64743 to 0.64856, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9713 - accuracy: 0.6546 - categorical_accuracy: 0.6546 - val_loss: 0.9852 - val_accuracy: 0.6486 - val_categorical_accuracy: 0.6486 - lr: 8.6593e-05\n",
      "Epoch 126/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9709 - accuracy: 0.6545 - categorical_accuracy: 0.6545\n",
      "Epoch 126: val_accuracy did not improve from 0.64856\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9709 - accuracy: 0.6545 - categorical_accuracy: 0.6545 - val_loss: 0.9854 - val_accuracy: 0.6470 - val_categorical_accuracy: 0.6470 - lr: 8.6593e-05\n",
      "Epoch 127/200\n",
      "7461/7514 [============================>.] - ETA: 0s - loss: 0.9708 - accuracy: 0.6543 - categorical_accuracy: 0.6543\n",
      "Epoch 127: val_accuracy did not improve from 0.64856\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9707 - accuracy: 0.6543 - categorical_accuracy: 0.6543 - val_loss: 0.9849 - val_accuracy: 0.6477 - val_categorical_accuracy: 0.6477 - lr: 8.6593e-05\n",
      "Epoch 128/200\n",
      "7455/7514 [============================>.] - ETA: 0s - loss: 0.9702 - accuracy: 0.6553 - categorical_accuracy: 0.6553\n",
      "Epoch 128: val_accuracy did not improve from 0.64856\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9702 - accuracy: 0.6553 - categorical_accuracy: 0.6553 - val_loss: 0.9843 - val_accuracy: 0.6469 - val_categorical_accuracy: 0.6469 - lr: 8.6593e-05\n",
      "Epoch 129/200\n",
      "7452/7514 [============================>.] - ETA: 0s - loss: 0.9700 - accuracy: 0.6549 - categorical_accuracy: 0.6549\n",
      "Epoch 129: val_accuracy did not improve from 0.64856\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9700 - accuracy: 0.6549 - categorical_accuracy: 0.6549 - val_loss: 0.9848 - val_accuracy: 0.6473 - val_categorical_accuracy: 0.6473 - lr: 8.6593e-05\n",
      "Epoch 130/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 0.9698 - accuracy: 0.6548 - categorical_accuracy: 0.6548\n",
      "Epoch 130: val_accuracy did not improve from 0.64856\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9698 - accuracy: 0.6548 - categorical_accuracy: 0.6548 - val_loss: 0.9846 - val_accuracy: 0.6474 - val_categorical_accuracy: 0.6474 - lr: 8.6593e-05\n",
      "Epoch 131/200\n",
      "7467/7514 [============================>.] - ETA: 0s - loss: 0.9695 - accuracy: 0.6553 - categorical_accuracy: 0.6553\n",
      "Epoch 131: val_accuracy did not improve from 0.64856\n",
      "7514/7514 [==============================] - 7s 918us/step - loss: 0.9696 - accuracy: 0.6554 - categorical_accuracy: 0.6554 - val_loss: 0.9854 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 132/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 0.9692 - accuracy: 0.6548 - categorical_accuracy: 0.6548\n",
      "Epoch 132: val_accuracy did not improve from 0.64856\n",
      "7514/7514 [==============================] - 7s 910us/step - loss: 0.9692 - accuracy: 0.6548 - categorical_accuracy: 0.6548 - val_loss: 0.9854 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 133/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9691 - accuracy: 0.6549 - categorical_accuracy: 0.6549\n",
      "Epoch 133: val_accuracy improved from 0.64856 to 0.64896, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9692 - accuracy: 0.6549 - categorical_accuracy: 0.6549 - val_loss: 0.9827 - val_accuracy: 0.6490 - val_categorical_accuracy: 0.6490 - lr: 8.6593e-05\n",
      "Epoch 134/200\n",
      "7510/7514 [============================>.] - ETA: 0s - loss: 0.9685 - accuracy: 0.6554 - categorical_accuracy: 0.6554\n",
      "Epoch 134: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9686 - accuracy: 0.6554 - categorical_accuracy: 0.6554 - val_loss: 0.9881 - val_accuracy: 0.6453 - val_categorical_accuracy: 0.6453 - lr: 8.6593e-05\n",
      "Epoch 135/200\n",
      "7511/7514 [============================>.] - ETA: 0s - loss: 0.9684 - accuracy: 0.6559 - categorical_accuracy: 0.6559\n",
      "Epoch 135: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 911us/step - loss: 0.9684 - accuracy: 0.6559 - categorical_accuracy: 0.6559 - val_loss: 0.9846 - val_accuracy: 0.6475 - val_categorical_accuracy: 0.6475 - lr: 8.6593e-05\n",
      "Epoch 136/200\n",
      "7468/7514 [============================>.] - ETA: 0s - loss: 0.9681 - accuracy: 0.6556 - categorical_accuracy: 0.6556\n",
      "Epoch 136: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9682 - accuracy: 0.6556 - categorical_accuracy: 0.6556 - val_loss: 0.9834 - val_accuracy: 0.6479 - val_categorical_accuracy: 0.6479 - lr: 8.6593e-05\n",
      "Epoch 137/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 0.9682 - accuracy: 0.6556 - categorical_accuracy: 0.6556\n",
      "Epoch 137: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9682 - accuracy: 0.6556 - categorical_accuracy: 0.6556 - val_loss: 0.9824 - val_accuracy: 0.6487 - val_categorical_accuracy: 0.6487 - lr: 8.6593e-05\n",
      "Epoch 138/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9676 - accuracy: 0.6559 - categorical_accuracy: 0.6559\n",
      "Epoch 138: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9677 - accuracy: 0.6559 - categorical_accuracy: 0.6559 - val_loss: 0.9864 - val_accuracy: 0.6460 - val_categorical_accuracy: 0.6460 - lr: 8.6593e-05\n",
      "Epoch 139/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9675 - accuracy: 0.6558 - categorical_accuracy: 0.6558\n",
      "Epoch 139: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9676 - accuracy: 0.6558 - categorical_accuracy: 0.6558 - val_loss: 0.9827 - val_accuracy: 0.6483 - val_categorical_accuracy: 0.6483 - lr: 8.6593e-05\n",
      "Epoch 140/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9676 - accuracy: 0.6562 - categorical_accuracy: 0.6562\n",
      "Epoch 140: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9675 - accuracy: 0.6563 - categorical_accuracy: 0.6563 - val_loss: 0.9842 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 141/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 0.9672 - accuracy: 0.6561 - categorical_accuracy: 0.6561\n",
      "Epoch 141: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9673 - accuracy: 0.6561 - categorical_accuracy: 0.6561 - val_loss: 0.9836 - val_accuracy: 0.6461 - val_categorical_accuracy: 0.6461 - lr: 8.6593e-05\n",
      "Epoch 142/200\n",
      "7492/7514 [============================>.] - ETA: 0s - loss: 0.9671 - accuracy: 0.6566 - categorical_accuracy: 0.6566\n",
      "Epoch 142: val_accuracy did not improve from 0.64896\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9671 - accuracy: 0.6565 - categorical_accuracy: 0.6565 - val_loss: 0.9837 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 143/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 0.9668 - accuracy: 0.6563 - categorical_accuracy: 0.6563\n",
      "Epoch 143: val_accuracy improved from 0.64896 to 0.64927, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9668 - accuracy: 0.6563 - categorical_accuracy: 0.6563 - val_loss: 0.9813 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 144/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 0.9666 - accuracy: 0.6569 - categorical_accuracy: 0.6569\n",
      "Epoch 144: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9666 - accuracy: 0.6569 - categorical_accuracy: 0.6569 - val_loss: 0.9825 - val_accuracy: 0.6480 - val_categorical_accuracy: 0.6480 - lr: 8.6593e-05\n",
      "Epoch 145/200\n",
      "7491/7514 [============================>.] - ETA: 0s - loss: 0.9664 - accuracy: 0.6573 - categorical_accuracy: 0.6573\n",
      "Epoch 145: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 900us/step - loss: 0.9665 - accuracy: 0.6572 - categorical_accuracy: 0.6572 - val_loss: 0.9825 - val_accuracy: 0.6476 - val_categorical_accuracy: 0.6476 - lr: 8.6593e-05\n",
      "Epoch 146/200\n",
      "7478/7514 [============================>.] - ETA: 0s - loss: 0.9660 - accuracy: 0.6565 - categorical_accuracy: 0.6565\n",
      "Epoch 146: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 893us/step - loss: 0.9661 - accuracy: 0.6564 - categorical_accuracy: 0.6564 - val_loss: 0.9821 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 147/200\n",
      "7460/7514 [============================>.] - ETA: 0s - loss: 0.9659 - accuracy: 0.6569 - categorical_accuracy: 0.6569\n",
      "Epoch 147: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 895us/step - loss: 0.9660 - accuracy: 0.6569 - categorical_accuracy: 0.6569 - val_loss: 0.9820 - val_accuracy: 0.6491 - val_categorical_accuracy: 0.6491 - lr: 8.6593e-05\n",
      "Epoch 148/200\n",
      "7473/7514 [============================>.] - ETA: 0s - loss: 0.9657 - accuracy: 0.6566 - categorical_accuracy: 0.6566\n",
      "Epoch 148: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 890us/step - loss: 0.9656 - accuracy: 0.6567 - categorical_accuracy: 0.6567 - val_loss: 0.9806 - val_accuracy: 0.6490 - val_categorical_accuracy: 0.6490 - lr: 8.6593e-05\n",
      "Epoch 149/200\n",
      "7472/7514 [============================>.] - ETA: 0s - loss: 0.9653 - accuracy: 0.6569 - categorical_accuracy: 0.6569\n",
      "Epoch 149: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 889us/step - loss: 0.9656 - accuracy: 0.6568 - categorical_accuracy: 0.6568 - val_loss: 0.9806 - val_accuracy: 0.6490 - val_categorical_accuracy: 0.6490 - lr: 8.6593e-05\n",
      "Epoch 150/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9650 - accuracy: 0.6572 - categorical_accuracy: 0.6572\n",
      "Epoch 150: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9650 - accuracy: 0.6572 - categorical_accuracy: 0.6572 - val_loss: 0.9824 - val_accuracy: 0.6492 - val_categorical_accuracy: 0.6492 - lr: 8.6593e-05\n",
      "Epoch 151/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 0.9650 - accuracy: 0.6574 - categorical_accuracy: 0.6574\n",
      "Epoch 151: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9650 - accuracy: 0.6573 - categorical_accuracy: 0.6573 - val_loss: 0.9807 - val_accuracy: 0.6481 - val_categorical_accuracy: 0.6481 - lr: 8.6593e-05\n",
      "Epoch 152/200\n",
      "7476/7514 [============================>.] - ETA: 0s - loss: 0.9650 - accuracy: 0.6573 - categorical_accuracy: 0.6573\n",
      "Epoch 152: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 901us/step - loss: 0.9650 - accuracy: 0.6573 - categorical_accuracy: 0.6573 - val_loss: 0.9813 - val_accuracy: 0.6483 - val_categorical_accuracy: 0.6483 - lr: 8.6593e-05\n",
      "Epoch 153/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9647 - accuracy: 0.6574 - categorical_accuracy: 0.6574\n",
      "Epoch 153: val_accuracy did not improve from 0.64927\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9647 - accuracy: 0.6574 - categorical_accuracy: 0.6574 - val_loss: 0.9839 - val_accuracy: 0.6463 - val_categorical_accuracy: 0.6463 - lr: 8.6593e-05\n",
      "Epoch 154/200\n",
      "7464/7514 [============================>.] - ETA: 0s - loss: 0.9644 - accuracy: 0.6574 - categorical_accuracy: 0.6574\n",
      "Epoch 154: val_accuracy improved from 0.64927 to 0.64961, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 903us/step - loss: 0.9645 - accuracy: 0.6573 - categorical_accuracy: 0.6573 - val_loss: 0.9796 - val_accuracy: 0.6496 - val_categorical_accuracy: 0.6496 - lr: 8.6593e-05\n",
      "Epoch 155/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9644 - accuracy: 0.6573 - categorical_accuracy: 0.6573\n",
      "Epoch 155: val_accuracy did not improve from 0.64961\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9644 - accuracy: 0.6573 - categorical_accuracy: 0.6573 - val_loss: 0.9800 - val_accuracy: 0.6481 - val_categorical_accuracy: 0.6481 - lr: 8.6593e-05\n",
      "Epoch 156/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9636 - accuracy: 0.6578 - categorical_accuracy: 0.6578\n",
      "Epoch 156: val_accuracy improved from 0.64961 to 0.64987, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9638 - accuracy: 0.6578 - categorical_accuracy: 0.6578 - val_loss: 0.9802 - val_accuracy: 0.6499 - val_categorical_accuracy: 0.6499 - lr: 8.6593e-05\n",
      "Epoch 157/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9636 - accuracy: 0.6581 - categorical_accuracy: 0.6581\n",
      "Epoch 157: val_accuracy did not improve from 0.64987\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9636 - accuracy: 0.6580 - categorical_accuracy: 0.6580 - val_loss: 0.9826 - val_accuracy: 0.6472 - val_categorical_accuracy: 0.6472 - lr: 8.6593e-05\n",
      "Epoch 158/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9634 - accuracy: 0.6579 - categorical_accuracy: 0.6579\n",
      "Epoch 158: val_accuracy improved from 0.64987 to 0.65050, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9634 - accuracy: 0.6579 - categorical_accuracy: 0.6579 - val_loss: 0.9794 - val_accuracy: 0.6505 - val_categorical_accuracy: 0.6505 - lr: 8.6593e-05\n",
      "Epoch 159/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 0.9634 - accuracy: 0.6582 - categorical_accuracy: 0.6582\n",
      "Epoch 159: val_accuracy did not improve from 0.65050\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9634 - accuracy: 0.6582 - categorical_accuracy: 0.6582 - val_loss: 0.9797 - val_accuracy: 0.6487 - val_categorical_accuracy: 0.6487 - lr: 8.6593e-05\n",
      "Epoch 160/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9632 - accuracy: 0.6577 - categorical_accuracy: 0.6577\n",
      "Epoch 160: val_accuracy did not improve from 0.65050\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9633 - accuracy: 0.6577 - categorical_accuracy: 0.6577 - val_loss: 0.9776 - val_accuracy: 0.6503 - val_categorical_accuracy: 0.6503 - lr: 8.6593e-05\n",
      "Epoch 161/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9633 - accuracy: 0.6583 - categorical_accuracy: 0.6583\n",
      "Epoch 161: val_accuracy did not improve from 0.65050\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9633 - accuracy: 0.6583 - categorical_accuracy: 0.6583 - val_loss: 0.9796 - val_accuracy: 0.6489 - val_categorical_accuracy: 0.6489 - lr: 8.6593e-05\n",
      "Epoch 162/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9628 - accuracy: 0.6579 - categorical_accuracy: 0.6579\n",
      "Epoch 162: val_accuracy did not improve from 0.65050\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9629 - accuracy: 0.6579 - categorical_accuracy: 0.6579 - val_loss: 0.9781 - val_accuracy: 0.6490 - val_categorical_accuracy: 0.6490 - lr: 8.6593e-05\n",
      "Epoch 163/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 0.9625 - accuracy: 0.6583 - categorical_accuracy: 0.6583\n",
      "Epoch 163: val_accuracy did not improve from 0.65050\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9627 - accuracy: 0.6582 - categorical_accuracy: 0.6582 - val_loss: 0.9799 - val_accuracy: 0.6489 - val_categorical_accuracy: 0.6489 - lr: 8.6593e-05\n",
      "Epoch 164/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9625 - accuracy: 0.6587 - categorical_accuracy: 0.6587\n",
      "Epoch 164: val_accuracy did not improve from 0.65050\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9625 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.9781 - val_accuracy: 0.6493 - val_categorical_accuracy: 0.6493 - lr: 8.6593e-05\n",
      "Epoch 165/200\n",
      "7497/7514 [============================>.] - ETA: 0s - loss: 0.9626 - accuracy: 0.6579 - categorical_accuracy: 0.6579\n",
      "Epoch 165: val_accuracy did not improve from 0.65050\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9627 - accuracy: 0.6580 - categorical_accuracy: 0.6580 - val_loss: 0.9785 - val_accuracy: 0.6500 - val_categorical_accuracy: 0.6500 - lr: 8.6593e-05\n",
      "Epoch 166/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9629 - accuracy: 0.6584 - categorical_accuracy: 0.6584\n",
      "Epoch 166: val_accuracy improved from 0.65050 to 0.65069, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9629 - accuracy: 0.6583 - categorical_accuracy: 0.6583 - val_loss: 0.9785 - val_accuracy: 0.6507 - val_categorical_accuracy: 0.6507 - lr: 8.6593e-05\n",
      "Epoch 167/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 0.9627 - accuracy: 0.6583 - categorical_accuracy: 0.6583\n",
      "Epoch 167: val_accuracy did not improve from 0.65069\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9627 - accuracy: 0.6583 - categorical_accuracy: 0.6583 - val_loss: 0.9771 - val_accuracy: 0.6506 - val_categorical_accuracy: 0.6506 - lr: 8.6593e-05\n",
      "Epoch 168/200\n",
      "7480/7514 [============================>.] - ETA: 0s - loss: 0.9624 - accuracy: 0.6582 - categorical_accuracy: 0.6582\n",
      "Epoch 168: val_accuracy did not improve from 0.65069\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9625 - accuracy: 0.6582 - categorical_accuracy: 0.6582 - val_loss: 0.9780 - val_accuracy: 0.6504 - val_categorical_accuracy: 0.6504 - lr: 8.6593e-05\n",
      "Epoch 169/200\n",
      "7474/7514 [============================>.] - ETA: 0s - loss: 0.9622 - accuracy: 0.6585 - categorical_accuracy: 0.6585\n",
      "Epoch 169: val_accuracy improved from 0.65069 to 0.65105, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 909us/step - loss: 0.9623 - accuracy: 0.6584 - categorical_accuracy: 0.6584 - val_loss: 0.9766 - val_accuracy: 0.6511 - val_categorical_accuracy: 0.6511 - lr: 8.6593e-05\n",
      "Epoch 170/200\n",
      "7477/7514 [============================>.] - ETA: 0s - loss: 0.9618 - accuracy: 0.6592 - categorical_accuracy: 0.6592\n",
      "Epoch 170: val_accuracy improved from 0.65105 to 0.65125, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9619 - accuracy: 0.6591 - categorical_accuracy: 0.6591 - val_loss: 0.9775 - val_accuracy: 0.6513 - val_categorical_accuracy: 0.6513 - lr: 8.6593e-05\n",
      "Epoch 171/200\n",
      "7487/7514 [============================>.] - ETA: 0s - loss: 0.9617 - accuracy: 0.6588 - categorical_accuracy: 0.6588\n",
      "Epoch 171: val_accuracy did not improve from 0.65125\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9618 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.9771 - val_accuracy: 0.6508 - val_categorical_accuracy: 0.6508 - lr: 8.6593e-05\n",
      "Epoch 172/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9620 - accuracy: 0.6590 - categorical_accuracy: 0.6590\n",
      "Epoch 172: val_accuracy did not improve from 0.65125\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9620 - accuracy: 0.6590 - categorical_accuracy: 0.6590 - val_loss: 0.9780 - val_accuracy: 0.6509 - val_categorical_accuracy: 0.6509 - lr: 8.6593e-05\n",
      "Epoch 173/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9616 - accuracy: 0.6588 - categorical_accuracy: 0.6588\n",
      "Epoch 173: val_accuracy improved from 0.65125 to 0.65145, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9617 - accuracy: 0.6587 - categorical_accuracy: 0.6587 - val_loss: 0.9766 - val_accuracy: 0.6515 - val_categorical_accuracy: 0.6515 - lr: 8.6593e-05\n",
      "Epoch 174/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 0.9616 - accuracy: 0.6588 - categorical_accuracy: 0.6588\n",
      "Epoch 174: val_accuracy did not improve from 0.65145\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9615 - accuracy: 0.6588 - categorical_accuracy: 0.6588 - val_loss: 0.9769 - val_accuracy: 0.6501 - val_categorical_accuracy: 0.6501 - lr: 8.6593e-05\n",
      "Epoch 175/200\n",
      "7493/7514 [============================>.] - ETA: 0s - loss: 0.9609 - accuracy: 0.6593 - categorical_accuracy: 0.6593\n",
      "Epoch 175: val_accuracy improved from 0.65145 to 0.65214, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9610 - accuracy: 0.6593 - categorical_accuracy: 0.6593 - val_loss: 0.9761 - val_accuracy: 0.6521 - val_categorical_accuracy: 0.6521 - lr: 8.6593e-05\n",
      "Epoch 176/200\n",
      "7485/7514 [============================>.] - ETA: 0s - loss: 0.9611 - accuracy: 0.6592 - categorical_accuracy: 0.6592\n",
      "Epoch 176: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9612 - accuracy: 0.6592 - categorical_accuracy: 0.6592 - val_loss: 0.9778 - val_accuracy: 0.6503 - val_categorical_accuracy: 0.6503 - lr: 8.6593e-05\n",
      "Epoch 177/200\n",
      "7505/7514 [============================>.] - ETA: 0s - loss: 0.9610 - accuracy: 0.6590 - categorical_accuracy: 0.6590\n",
      "Epoch 177: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9610 - accuracy: 0.6590 - categorical_accuracy: 0.6590 - val_loss: 0.9777 - val_accuracy: 0.6490 - val_categorical_accuracy: 0.6490 - lr: 8.6593e-05\n",
      "Epoch 178/200\n",
      "7496/7514 [============================>.] - ETA: 0s - loss: 0.9607 - accuracy: 0.6591 - categorical_accuracy: 0.6591\n",
      "Epoch 178: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9607 - accuracy: 0.6591 - categorical_accuracy: 0.6591 - val_loss: 0.9753 - val_accuracy: 0.6511 - val_categorical_accuracy: 0.6511 - lr: 8.6593e-05\n",
      "Epoch 179/200\n",
      "7490/7514 [============================>.] - ETA: 0s - loss: 0.9605 - accuracy: 0.6591 - categorical_accuracy: 0.6591\n",
      "Epoch 179: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9606 - accuracy: 0.6591 - categorical_accuracy: 0.6591 - val_loss: 0.9766 - val_accuracy: 0.6508 - val_categorical_accuracy: 0.6508 - lr: 8.6593e-05\n",
      "Epoch 180/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 0.9607 - accuracy: 0.6594 - categorical_accuracy: 0.6594\n",
      "Epoch 180: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9608 - accuracy: 0.6594 - categorical_accuracy: 0.6594 - val_loss: 0.9777 - val_accuracy: 0.6500 - val_categorical_accuracy: 0.6500 - lr: 8.6593e-05\n",
      "Epoch 181/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9605 - accuracy: 0.6591 - categorical_accuracy: 0.6591\n",
      "Epoch 181: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9605 - accuracy: 0.6591 - categorical_accuracy: 0.6591 - val_loss: 0.9792 - val_accuracy: 0.6485 - val_categorical_accuracy: 0.6485 - lr: 8.6593e-05\n",
      "Epoch 182/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9606 - accuracy: 0.6597 - categorical_accuracy: 0.6597\n",
      "Epoch 182: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9605 - accuracy: 0.6598 - categorical_accuracy: 0.6598 - val_loss: 0.9771 - val_accuracy: 0.6505 - val_categorical_accuracy: 0.6505 - lr: 8.6593e-05\n",
      "Epoch 183/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9604 - accuracy: 0.6602 - categorical_accuracy: 0.6602\n",
      "Epoch 183: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9603 - accuracy: 0.6602 - categorical_accuracy: 0.6602 - val_loss: 0.9788 - val_accuracy: 0.6482 - val_categorical_accuracy: 0.6482 - lr: 8.6593e-05\n",
      "Epoch 184/200\n",
      "7504/7514 [============================>.] - ETA: 0s - loss: 0.9604 - accuracy: 0.6594 - categorical_accuracy: 0.6594\n",
      "Epoch 184: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9604 - accuracy: 0.6594 - categorical_accuracy: 0.6594 - val_loss: 0.9750 - val_accuracy: 0.6521 - val_categorical_accuracy: 0.6521 - lr: 8.6593e-05\n",
      "Epoch 185/200\n",
      "7489/7514 [============================>.] - ETA: 0s - loss: 0.9599 - accuracy: 0.6600 - categorical_accuracy: 0.6600\n",
      "Epoch 185: val_accuracy did not improve from 0.65214\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9601 - accuracy: 0.6599 - categorical_accuracy: 0.6599 - val_loss: 0.9749 - val_accuracy: 0.6515 - val_categorical_accuracy: 0.6515 - lr: 8.6593e-05\n",
      "Epoch 186/200\n",
      "7486/7514 [============================>.] - ETA: 0s - loss: 0.9599 - accuracy: 0.6597 - categorical_accuracy: 0.6597\n",
      "Epoch 186: val_accuracy improved from 0.65214 to 0.65242, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 908us/step - loss: 0.9599 - accuracy: 0.6596 - categorical_accuracy: 0.6596 - val_loss: 0.9750 - val_accuracy: 0.6524 - val_categorical_accuracy: 0.6524 - lr: 8.6593e-05\n",
      "Epoch 187/200\n",
      "7483/7514 [============================>.] - ETA: 0s - loss: 0.9599 - accuracy: 0.6595 - categorical_accuracy: 0.6595\n",
      "Epoch 187: val_accuracy did not improve from 0.65242\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9600 - accuracy: 0.6595 - categorical_accuracy: 0.6595 - val_loss: 0.9743 - val_accuracy: 0.6520 - val_categorical_accuracy: 0.6520 - lr: 8.6593e-05\n",
      "Epoch 188/200\n",
      "7488/7514 [============================>.] - ETA: 0s - loss: 0.9598 - accuracy: 0.6596 - categorical_accuracy: 0.6596\n",
      "Epoch 188: val_accuracy did not improve from 0.65242\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9598 - accuracy: 0.6596 - categorical_accuracy: 0.6596 - val_loss: 0.9750 - val_accuracy: 0.6510 - val_categorical_accuracy: 0.6510 - lr: 8.6593e-05\n",
      "Epoch 189/200\n",
      "7507/7514 [============================>.] - ETA: 0s - loss: 0.9594 - accuracy: 0.6601 - categorical_accuracy: 0.6601\n",
      "Epoch 189: val_accuracy did not improve from 0.65242\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 0.9594 - accuracy: 0.6601 - categorical_accuracy: 0.6601 - val_loss: 0.9752 - val_accuracy: 0.6517 - val_categorical_accuracy: 0.6517 - lr: 8.6593e-05\n",
      "Epoch 190/200\n",
      "7499/7514 [============================>.] - ETA: 0s - loss: 0.9595 - accuracy: 0.6597 - categorical_accuracy: 0.6597\n",
      "Epoch 190: val_accuracy did not improve from 0.65242\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9594 - accuracy: 0.6597 - categorical_accuracy: 0.6597 - val_loss: 0.9744 - val_accuracy: 0.6520 - val_categorical_accuracy: 0.6520 - lr: 8.6593e-05\n",
      "Epoch 191/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9593 - accuracy: 0.6600 - categorical_accuracy: 0.6600\n",
      "Epoch 191: val_accuracy did not improve from 0.65242\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9593 - accuracy: 0.6600 - categorical_accuracy: 0.6600 - val_loss: 0.9737 - val_accuracy: 0.6521 - val_categorical_accuracy: 0.6521 - lr: 8.6593e-05\n",
      "Epoch 192/200\n",
      "7484/7514 [============================>.] - ETA: 0s - loss: 0.9591 - accuracy: 0.6602 - categorical_accuracy: 0.6602\n",
      "Epoch 192: val_accuracy did not improve from 0.65242\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9591 - accuracy: 0.6601 - categorical_accuracy: 0.6601 - val_loss: 0.9738 - val_accuracy: 0.6517 - val_categorical_accuracy: 0.6517 - lr: 8.6593e-05\n",
      "Epoch 193/200\n",
      "7482/7514 [============================>.] - ETA: 0s - loss: 0.9586 - accuracy: 0.6608 - categorical_accuracy: 0.6608\n",
      "Epoch 193: val_accuracy improved from 0.65242 to 0.65288, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 901us/step - loss: 0.9588 - accuracy: 0.6607 - categorical_accuracy: 0.6607 - val_loss: 0.9736 - val_accuracy: 0.6529 - val_categorical_accuracy: 0.6529 - lr: 8.6593e-05\n",
      "Epoch 194/200\n",
      "7498/7514 [============================>.] - ETA: 0s - loss: 0.9588 - accuracy: 0.6599 - categorical_accuracy: 0.6599\n",
      "Epoch 194: val_accuracy did not improve from 0.65288\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9589 - accuracy: 0.6599 - categorical_accuracy: 0.6599 - val_loss: 0.9750 - val_accuracy: 0.6524 - val_categorical_accuracy: 0.6524 - lr: 8.6593e-05\n",
      "Epoch 195/200\n",
      "7494/7514 [============================>.] - ETA: 0s - loss: 0.9586 - accuracy: 0.6611 - categorical_accuracy: 0.6611\n",
      "Epoch 195: val_accuracy did not improve from 0.65288\n",
      "7514/7514 [==============================] - 7s 906us/step - loss: 0.9585 - accuracy: 0.6612 - categorical_accuracy: 0.6612 - val_loss: 0.9761 - val_accuracy: 0.6500 - val_categorical_accuracy: 0.6500 - lr: 8.6593e-05\n",
      "Epoch 196/200\n",
      "7513/7514 [============================>.] - ETA: 0s - loss: 0.9585 - accuracy: 0.6603 - categorical_accuracy: 0.6603\n",
      "Epoch 196: val_accuracy did not improve from 0.65288\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9585 - accuracy: 0.6603 - categorical_accuracy: 0.6603 - val_loss: 0.9757 - val_accuracy: 0.6515 - val_categorical_accuracy: 0.6515 - lr: 8.6593e-05\n",
      "Epoch 197/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9584 - accuracy: 0.6605 - categorical_accuracy: 0.6605\n",
      "Epoch 197: val_accuracy did not improve from 0.65288\n",
      "7514/7514 [==============================] - 7s 907us/step - loss: 0.9585 - accuracy: 0.6604 - categorical_accuracy: 0.6604 - val_loss: 0.9785 - val_accuracy: 0.6491 - val_categorical_accuracy: 0.6491 - lr: 8.6593e-05\n",
      "Epoch 198/200\n",
      "7506/7514 [============================>.] - ETA: 0s - loss: 0.9585 - accuracy: 0.6610 - categorical_accuracy: 0.6610\n",
      "Epoch 198: val_accuracy did not improve from 0.65288\n",
      "7514/7514 [==============================] - 7s 904us/step - loss: 0.9585 - accuracy: 0.6610 - categorical_accuracy: 0.6610 - val_loss: 0.9767 - val_accuracy: 0.6503 - val_categorical_accuracy: 0.6503 - lr: 8.6593e-05\n",
      "Epoch 199/200\n",
      "7501/7514 [============================>.] - ETA: 0s - loss: 0.9582 - accuracy: 0.6608 - categorical_accuracy: 0.6608\n",
      "Epoch 199: val_accuracy did not improve from 0.65288\n",
      "7514/7514 [==============================] - 7s 905us/step - loss: 0.9582 - accuracy: 0.6608 - categorical_accuracy: 0.6608 - val_loss: 0.9741 - val_accuracy: 0.6513 - val_categorical_accuracy: 0.6513 - lr: 8.6593e-05\n",
      "Epoch 200/200\n",
      "7481/7514 [============================>.] - ETA: 0s - loss: 0.9583 - accuracy: 0.6606 - categorical_accuracy: 0.6606\n",
      "Epoch 200: val_accuracy improved from 0.65288 to 0.65307, saving model to model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509/model_QMLP_nconst_32_nbits_8_kfold_4.h5\n",
      "7514/7514 [==============================] - 7s 913us/step - loss: 0.9584 - accuracy: 0.6606 - categorical_accuracy: 0.6606 - val_loss: 0.9722 - val_accuracy: 0.6531 - val_categorical_accuracy: 0.6531 - lr: 8.6593e-05\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import util.data\n",
    "import util.plots\n",
    "import util.util\n",
    "from util.terminal_colors import tcols\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "nmax = nconstit\n",
    "accuracy_keras = []\n",
    "\n",
    "\n",
    "\n",
    "# Loop of training folds\n",
    "with tf.device('CPU: 0'):   # disable M1 metal GPU \n",
    "  for i in range (kfolds):\n",
    "  \n",
    "    # Load random weights initialization before any training to reset weights. Otherwise Keras starts from last trained model weights ...\n",
    "    model.load_weights('model.h5')\n",
    "    \n",
    "    print(\"train kfold num:\", i)\n",
    "    val_kfold = i \n",
    "\n",
    "    #test_kfold = args.TK\n",
    "    train_kfolds = [kfold for kfold in range(kfolds) if kfold != val_kfold]\n",
    "\n",
    "    \n",
    "    fpath = f'./data_kfold/jets_{nmax}constituents_ptetaphi_nonorm'\n",
    "    fnames_train = [f'jet_images_c{nmax}_minpt2.0_ptetaphi_nonorm_{train_kfold}'\n",
    "                     for train_kfold in train_kfolds]\n",
    "    fname_val = f'jet_images_c{nmax}_minpt2.0_ptetaphi_nonorm_{val_kfold}'\n",
    "\n",
    "    data = util.data.Data.load_kfolds(fpath, fnames_train, fname_val)\n",
    "    print (data.train_data.shape)\n",
    "\n",
    "\n",
    "    X_train = data.train_data\n",
    "    X_val = data.test_data\n",
    "    X_test = data.test_data\n",
    "\n",
    "    Y_train = data.train_target\n",
    "    Y_val = data.test_target\n",
    "    Y_test = data.test_target    \n",
    "  \n",
    "\n",
    "    # Nomalization\n",
    "    interquantile_range_32 = [120, 0.27, 0.27]\n",
    "    interquantile_range_16 = [166, 0.24, 0.24]\n",
    "    interquantile_range_8  = [219, 0.20, 0.20]\n",
    "    \n",
    "    if nmax == 8:\n",
    "        X_train = X_train / interquantile_range_8\n",
    "        X_val   = X_val   / interquantile_range_8\n",
    "        X_test  = X_test  / interquantile_range_8\n",
    "    elif nmax == 16:\n",
    "        X_train = X_train / interquantile_range_16\n",
    "        X_val   = X_val   / interquantile_range_16\n",
    "        X_test  = X_test  / interquantile_range_16\n",
    "    elif nmax == 32:\n",
    "        X_train = X_train / interquantile_range_32\n",
    "        X_val   = X_val   / interquantile_range_32\n",
    "        X_test  = X_test  / interquantile_range_32\n",
    "\n",
    "    # Flatten data for MLP input\n",
    "    if (arch!='QGCN'):        \n",
    "        X_train = X_train.reshape(-1, NINPUT)\n",
    "        X_val   = X_val.reshape(-1, NINPUT)\n",
    "        X_test  = X_test.reshape(-1, NINPUT)\n",
    "    \n",
    "    \n",
    "    print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "\n",
    "    print( f\"number of G jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 0)}/{np.sum(np.argmax(Y_val, axis=1) == 0)}\")\n",
    "    print( f\"number of Q jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 1)}/{np.sum(np.argmax(Y_val, axis=1) == 1)}\")\n",
    "    print( f\"number of W jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 2)}/{np.sum(np.argmax(Y_val, axis=1) == 2)}\")\n",
    "    print( f\"number of Z jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 3)}/{np.sum(np.argmax(Y_val, axis=1) == 3)}\")\n",
    "    print( f\"number of T jets for training/validation: {np.sum(np.argmax(Y_train, axis=1) == 4)}/{np.sum(np.argmax(Y_val, axis=1) == 4)}\")\n",
    "\n",
    "    \n",
    "    print(\"number of G jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 0))\n",
    "    print(\"number of Q jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 1))\n",
    "    print(\"number of W jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 2))\n",
    "    print(\"number of Z jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 3))\n",
    "    print(\"number of T jets for testing: %i\" % np.sum(np.argmax(Y_test, axis=1) == 4))\n",
    "    \n",
    "#######################################################################################\n",
    "\n",
    "    mname = \"model_{}_nconst_{}_nbits_{}_kfold_{}\".format(arch,nmax,nbits,val_kfold)\n",
    "\n",
    "    if(i==0):\n",
    "        outputdir = \"model_{}_nconst{}_nbits{}_Seed{}_Kfold_{}\".format(\n",
    "            arch,\n",
    "            nconstit,\n",
    "            nbits,\n",
    "            seed,\n",
    "            time.strftime(\"%Y%m%d-%H%M%S\"),\n",
    "        )\n",
    "        print(\"output dir: \", outputdir)\n",
    "        os.mkdir(outputdir)\n",
    "\n",
    "        # early stopping callback\n",
    "        es = EarlyStopping(monitor=MTR, patience=patience)\n",
    "        # Learning rate scheduler\n",
    "        ls = ReduceLROnPlateau(monitor=MTR, factor=0.2, patience=patience)\n",
    "        #\n",
    "        pr = pruning_callbacks.UpdatePruningStep() \n",
    "\n",
    "        \n",
    "    \n",
    "    # Define model checkpoint ( mname changes with folding number !!! ) \n",
    "    chkp = ModelCheckpoint(outputdir+\"/\"+mname+\".h5\", monitor=MTR, verbose=1, save_best_only=True, save_weights_only=False, mode=\"auto\", save_freq=\"epoch\")\n",
    "\n",
    "    # Train classifier\n",
    "    history = model.fit(\n",
    "                        X_train,\n",
    "                        Y_train,\n",
    "                        epochs=nepochs,\n",
    "                        batch_size=batch,  # small batch\n",
    "                        verbose=1,\n",
    "                        callbacks=[es, ls, chkp, pr],\n",
    "                        #validation_split=0.2,\n",
    "                        validation_data=(X_val, Y_val),\n",
    "                        shuffle=True\n",
    "                        )\n",
    "\n",
    "\n",
    "    # Plot loss vs epoch\n",
    "    plt.figure(figsize=(15,10))\n",
    "    ax = plt.subplot(2, 2, 1)\n",
    "    ax.plot(history.history['loss'], label='loss')\n",
    "    ax.plot(history.history['val_loss'], label='val loss')\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "\n",
    "    # Plot training accuracy vs epoch\n",
    "    ax = plt.subplot(2, 2, 2)\n",
    "    #ax.plot(history.history['accuracy'], label='accuracy')\n",
    "    #ax.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "    ax.plot(history.history['categorical_accuracy'], label='categorical_accuracy')\n",
    "    ax.plot(history.history['val_categorical_accuracy'], label='val categorical accuracy')\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('acc')\n",
    "\n",
    "    # Display plots\n",
    "    fig = plt.gcf()\n",
    "    plt.show()\n",
    "#    fig.savefig(fname+'.pdf')\n",
    "\n",
    "\n",
    "    \n",
    "    # Retrieve the best model\n",
    "    model = tf.keras.models.load_model(\n",
    "        \"{}/{}.h5\".format(outputdir, mname),\n",
    "        custom_objects={\n",
    "            \"QDense\": QDense,\n",
    "            \"QActivation\": QActivation,\n",
    "            \"QConv1D\": QConv1D,\n",
    "            \"QConv2D\": QConv2D,\n",
    "            \"quantized_bits\": quantized_bits,\n",
    "#            \"NodeEdgeProjection\": NodeEdgeProjection,\n",
    "            \"PruneLowMagnitude\": pruning_wrapper.PruneLowMagnitude,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    '''\n",
    "    # Get predictions for the best model\n",
    "    y_keras = model.predict(X_test)    \n",
    "    # Store best model predictions\n",
    "    accuracy_keras.append(float( accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "    '''\n",
    "    \n",
    "    # Store the accuracy for a given fold\n",
    "    Y_pred = model.predict(X_test)\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    accuracy.update_state(Y_test, Y_pred)\n",
    "    accuracy_keras.append( accuracy.result().numpy() )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c3e32-6edc-4c67-b4b7-f8a043d83c4c",
   "metadata": {},
   "source": [
    "## Saves accuracy and errors for paper plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a15a8a-fa81-440d-a6b0-4494796d5b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras:\n",
      " [0.63218534, 0.63924795, 0.6514017, 0.65116876, 0.65306544]\n",
      "output dir:  model_QMLP_nconst32_nbits8_Seed175_Kfold_20231112-220509\n"
     ]
    }
   ],
   "source": [
    "#        kfold_metrics = {\n",
    "#            \"fprs\": [],\n",
    "#            \"aucs\": [],\n",
    "#            \"fats\": [],\n",
    "#            \"accs\": [],\n",
    "#            \"loss\": []\n",
    "#        }\n",
    "\n",
    "#plots_dir = outputdir\n",
    "#\n",
    "#roc_metrics = util.plots.roc_curves(plots_dir, y_keras, data.test_target)\n",
    "#util.plots.dnn_output(plots_dir, y_keras)\n",
    "\n",
    "accuracy_average = np.mean(np.array(accuracy_keras))\n",
    "accuracy_errs = np.std(np.array(accuracy_keras))\n",
    "\n",
    "\n",
    "accs = np.zeros(3)\n",
    "accs[0] = accuracy_average\n",
    "accs[2] = accuracy_errs\n",
    "\n",
    "np.savetxt(\"{}/acc.txt\".format(outputdir), accs, fmt=\"%.6f\")\n",
    "print(\"Keras:\\n\", accuracy_keras)\n",
    "\n",
    "print(\"output dir: \", outputdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9e41c-d3c3-4758-811d-0d67e186b48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7833c9-cc89-4cff-a563-822075bbdd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52061e4a-562d-44f3-8a4b-9f85c7be6ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be774cea-7ff6-456f-8fa1-a8410b6d806d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0810dc-b01c-4a98-9699-24c3a017bcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d668a31-8a5f-4cf9-85f5-09f0667f344a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
