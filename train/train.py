import numpy as np
import os
import time
import argparse

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Concatenate, Flatten, BatchNormalization, Activation
from tensorflow.keras.optimizers import Adam
from qkeras import QDense, QConv1D, QActivation

from node_edge_projection import NodeEdgeProjection

# Initiate the parser
parser = argparse.ArgumentParser()
parser.add_argument("-nmax", type=int, default=8, help="number of particle")
parser.add_argument("-De", type=int, default=8, help="De")
parser.add_argument("-NL", type=int, default=0, help="number of layer for the MLP_e")
parser.add_argument("-SE", type=int, default=0, help="scale_e")
parser.add_argument("-SN", type=int, default=2, help="scale_n")
parser.add_argument("-batch", type=int, default=512, help="batch")
parser.add_argument("-epochs", type=int, default=200, help="epochs")
parser.add_argument("-patience", type=int, default=20, help="patience")
parser.add_argument("-acc", type=int, default=0, help="accuracy or loss")
args = parser.parse_args()

jetConstituent = np.load('data/jetConstituent_150_3f.npy')
target = np.load('data/jetConstituent_target_150_3f.npy')


# Restrict the number of constituents to a maximum of NMAX
nmax = args.nmax
jetConstituent = jetConstituent[:,0:nmax,:]

# The dataset is N_jets x N_constituents x N_features
njet     = jetConstituent.shape[0]
nconstit = jetConstituent.shape[1]
nfeat    = jetConstituent.shape[2]


print('Number of jets =',njet)
print('Number of constituents =',nconstit)
print('Number of features =',nfeat)


# Shuffles jet constituents
print("Before --->> jetConstituent[0,0:4,0] = ",jetConstituent[0,0:4,0])
for i in range(jetConstituent.shape[0]):
  jetConstituent[i] = jetConstituent[i, np.random.permutation(nconstit), :]
print("After --->> jetConstituent[0,0:4,0] = ",jetConstituent[0,0:4,0])


from sklearn.model_selection import train_test_split

X = jetConstituent
Y = target
del jetConstituent , target

X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.33, random_state=7)

print(X_train_val.shape, X_test.shape, Y_train_val.shape, Y_test.shape)

print('number of G jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==0 ))
print('number of Q jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==1 ))
print('number of W jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==2 ))
print('number of Z jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==3 ))
print('number of T jets for training/validation: %i'%np.sum( np.argmax(Y_train_val, axis=1)==4 ))


print('number of G jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==0 ))
print('number of Q jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==1 ))
print('number of W jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==2 ))
print('number of Z jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==3 ))
print('number of T jets for testing: %i'%np.sum( np.argmax(Y_test, axis=1)==4 ))

# baseline keras model

njet     = X_train_val.shape[0]
nconstit = X_train_val.shape[1]
ntargets =  Y_train_val.shape[1]
nfeat =  X_train_val.shape[2]


print("#jets = ",njet)
print("#constituents = ",nconstit)
print("#targets = ",ntargets)
print("#features = ",nfeat)

# Params for 8 constituents - try
De=args.De                  # size of latent edges features representations
Do=6                  # size of latent nodes features representations
scale_e = args.SE           # multiplicative factor for # hidden neurons in Edges MLP 
scale_n = args.SN           # multiplicative factor for # hidden neurons in Nodes MLP 

if(nmax==32):
    scale_g = 0.12
elif(nmax==20):
    scale_g = 0.25
elif(nmax==16):
    scale_g = 0.35        # multiplicative factor for # hidden neurons in Graph MLP 
elif(nmax==8):
    scale_g = 1           # multiplicative factor for # hidden neurons in Graph MLP 
    

NL=args.NL


# Interaction Network model parameters
N = nconstit
P = nfeat
Nr = N*(N-1) # number of relations ( edges )
Dr = 0                     
Dx = 0

# Quantized bits
nbits=8
integ=0

# Set QKeras quantizer and activation 
if nbits == 1:
    qbits = 'binary(alpha=1)'
elif nbits == 2:
    qbits = 'ternary(alpha=1)'
else:
    qbits = 'quantized_bits({},0,alpha=1)'.format(nbits)

qact = 'quantized_relu({},0)'.format(nbits)

# Print
print("Training with max # of contituents = ", nconstit)
print("Number of node features = ", nfeat)
print("Quantization with nbits=",nbits)
print("Quantization of integer part=",integ)

# Input shape
inp = Input(shape=(nconstit, nfeat), name="in_layer")
       
# Batch normalize the inputs
x = BatchNormalization(name='batchnorm')(inp)

# Project to edges
ORr = NodeEdgeProjection(name="proj_1", receiving=True, node_to_edge=True)(x)
ORs = NodeEdgeProjection(name="proj_2", receiving=False, node_to_edge=True)(x)

inp_e = Concatenate(axis=-1)([ORr, ORs])  # Concatenates Or and Os  ( no relations features Ra matrix )

# Edges MLP ( takes as inputs nodes features of a fully conected graph edges )

# Define the Edges MLP layers
nhidden_e = int( (2 * P + Dr)*scale_e )
if (NL==2): 
    h = QConv1D(nhidden_e, kernel_size=1, kernel_quantizer=qbits, bias_quantizer=qbits , name='conv1D_e1')(inp_e)
    h = QActivation(qact, name='qrelu_e1')(h)
    h = QConv1D(int(nhidden_e/2), kernel_size=1, kernel_quantizer=qbits, bias_quantizer=qbits, name='conv1D_e2' )(h)
    h = QActivation(qact, name='qrelu_e2')(h)
    h = QConv1D(De, kernel_size=1,kernel_quantizer=qbits, bias_quantizer=qbits, name='conv1D_e3' )(h)
if (NL==1): 
    h = QConv1D(nhidden_e, kernel_size=1, kernel_quantizer=qbits, bias_quantizer=qbits , name='conv1D_e1')(inp_e)
    h = QActivation(qact, name='qrelu_e1')(h)
    h = QConv1D(De, kernel_size=1,kernel_quantizer=qbits, bias_quantizer=qbits, name='conv1D_e3' )(h)
elif(NL==0):
    h = QConv1D(De, kernel_size=1,kernel_quantizer=qbits, bias_quantizer=qbits, name='conv1D_e3' )(inp_e)

out_e = QActivation(qact, name='qrelu_e3')(h)

# Project to nodes
out_e = NodeEdgeProjection(name="proj_3", receiving=True, node_to_edge=False)(out_e)

# Nodes MLP ( takes as inputs node features and embeding from edges MLP )

# Concatenate input Node features and Edges MLP output for the Nodes MLP input
inp_n = Concatenate(axis=-1)([x, out_e])   #  Original IN was C = tf.concat([N,x,E], axis=1) 

# Define the Nodes MLP layers
nhidden_n = int( (P + Dx + De)*scale_n ) # number of neurons in Nodes MLP hidden layer 
h = QConv1D(nhidden_n, kernel_size=1, kernel_quantizer=qbits, bias_quantizer=qbits, name='conv1D_n1')(inp_n)
h = QActivation(qact, name='qrelu_n1')(h)
h = QConv1D(int(nhidden_n/2), kernel_size=1, kernel_quantizer=qbits, bias_quantizer=qbits, name='conv1D_n2')(h)
h = QActivation(qact, name='qrelu_n2')(h)
h = QConv1D(Do, kernel_size=1, kernel_quantizer=qbits, bias_quantizer=qbits, name='conv1D_n3' )(h)
out_n = QActivation(qact, name='qrelu_n3')(h)

#  Graph classification MLP

# Flatten input for the Graph classifier MLP
inp_g = Flatten()(out_n)

# Define Graph classifier MLP  layers
nhidden_g = int( (Do * N)*scale_g )  # Number of nodes in graph MLP hidden layer
h = QDense(nhidden_g, kernel_quantizer=qbits, bias_quantizer=qbits,name='dense_g1' )(inp_g)
h = QActivation(qact,name='qrelu_g1')(h)
h = QDense(ntargets,kernel_quantizer=qbits, bias_quantizer=qbits ,name='dense_g2')(h)
out = Activation('softmax',name='softmax_g2')(h)

# create the model
model = Model(inputs=inp, outputs=out)

# Define the optimizer ( minimization algorithm )
optim = Adam(learning_rate=0.0005)

# Compile the Model
model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=['categorical_accuracy'])

# Model Summary
model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau


outputdir = 'nconst{}_nbits{}_De{}_NL{}_SE{}_SN{}_batch{}_acc{}_{}'.format(nmax, nbits, De, NL, scale_e, scale_n, args.batch, args.acc, time.strftime("%Y%m%d-%H%M%S"))

print('output dir: ', outputdir)
os.mkdir(outputdir)

patience = args.patience

if args.acc:
    # early stopping callback
    es = EarlyStopping(monitor='val_categorical_accuracy', patience=patience)
    # Learning rate scheduler 
    ls = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.2, patience=patience)

    chkp = ModelCheckpoint(outputdir+'/model_QInteractionNetwork_nconst_'+str(nmax)+'_nbits_'+str(nbits)+'.h5', 
        monitor='val_loss', 
        verbose=1, save_best_only=True, 
        save_weights_only=False, mode='auto', 
        save_freq='epoch')
else:
    # early stopping callback
    es = EarlyStopping(monitor='val_loss', patience=patience)
    # Learning rate scheduler 
    ls = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=patience)
    
    # model checkpoint callback
    # this saves our model architecture + parameters into mlp_model.h5
    chkp = ModelCheckpoint(outputdir+'/model_QInteractionNetwork_nconst_'+str(nmax)+'_nbits_'+str(nbits)+'.h5', 
        monitor='val_loss', 
        verbose=1, save_best_only=True, 
        save_weights_only=False, mode='auto', 
        save_freq='epoch')

# Train classifier
history = model.fit( X_train_val , Y_train_val,
                    epochs=args.epochs,
                    batch_size=args.batch, #small batch
                    verbose=1,
                    callbacks=[es,ls,chkp],
                    validation_split=0.3 )

from sklearn.metrics import accuracy_score

y_keras = model.predict(X_test)
accuracy_keras  = float(accuracy_score (np.argmax(Y_test,axis=1), np.argmax(y_keras,axis=1)))

accs = np.zeros(2)
accs[0] = accuracy_keras
np.savetxt('{}/acc.txt'.format(outputdir), accs, fmt='%.6f')
print('Keras:\n', accuracy_keras)

print('output dir: ', outputdir)